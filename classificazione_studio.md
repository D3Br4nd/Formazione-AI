# ğŸ“˜ La Classificazione â€” Guida Completa di Studio

> **Corso**: Fondamenti di Machine Learning â€” ProfessionAI  
> **Docente**: Giuseppe Gullo  
> **Argomento**: La Classificazione (Binaria, Multiclasse, Metriche)

---

## Indice

1. [Cos'Ã¨ la Classificazione](#1-cosÃ¨-la-classificazione)
2. [La Regressione Logistica](#2-la-regressione-logistica)
   - [Dal problema al modello matematico](#21-dal-problema-al-modello-matematico)
   - [Il Decision Boundary](#22-il-decision-boundary)
   - [La funzione di attivazione](#23-la-funzione-di-attivazione)
   - [La funzione Sigmoide](#24-la-funzione-sigmoide-logistica)
   - [La funzione di costo (Log Loss)](#25-la-funzione-di-costo)
3. [La Classificazione Multiclasse](#3-la-classificazione-multiclasse)
   - [One vs Rest (OvR)](#31-metodo-one-vs-rest-ovr)
   - [One vs One (OvO)](#32-metodo-one-vs-one-ovo)
   - [Classi vs Label (Multilabel)](#33-classi-vs-label-multilabel)
4. [Metriche per la Classificazione](#4-metriche-per-la-classificazione)
   - [Matrice di Confusione](#41-matrice-di-confusione)
   - [Accuracy](#42-accuracy)
   - [Precision](#43-precision)
   - [Recall / Sensitivity](#44-recall-sensitivity)
   - [Specificity](#45-specificity)
   - [ROC Curve e AUC](#46-curva-roc-e-auc)
   - [F1 Score](#47-f1-score)
   - [Log Loss](#48-log-loss-cross-entropy)
5. [Riepilogo Formule](#5-riepilogo-formule)

---

## 1. Cos'Ã¨ la Classificazione

La **classificazione** Ã¨ un task dell'**apprendimento supervisionato** in cui l'obiettivo Ã¨ prevedere una **classe** (variabile categorica), non un valore numerico continuo (come nella regressione).

### Differenza chiave: Regressione vs Classificazione

| Aspetto | Regressione | Classificazione |
|---|---|---|
| **Output** | Valore numerico continuo | Classe / Categoria |
| **Esempio** | Prevedere il prezzo di una casa | Diagnosticare un tumore come benigno/maligno |
| **Funzione** | Regressione lineare | Regressione logistica |

### Tipologie di Classificazione

```mermaid
graph TD
    A[Classificazione] --> B[Binaria]
    A --> C[Multiclasse]
    A --> D[Multilabel]
    B --> B1["2 classi<br/>Es: Maligno/Benigno"]
    C --> C1["3+ classi mutuamente esclusive<br/>Es: Riconoscimento cifre 0-9"]
    D --> D1["PiÃ¹ label contemporaneamente<br/>Es: Tag di un articolo"]
```

---

## 2. La Regressione Logistica

### 2.1 Dal problema al modello matematico

Prendiamo un esempio concreto dal corso: **classificare un tumore come maligno o benigno** usando due feature: *raggio medio* e *punti di concavitÃ *.

#### Step 1 â€” I dati grezzi

| Raggio medio | Punti di concavitÃ  | Diagnosi |
|---|---|---|
| 17.99 | 0.14710 | maligno |
| 13.54 | 0.04781 | benigno |
| 20.57 | 0.07017 | maligno |
| 9.504 | 0.02076 | benigno |

#### Step 2 â€” Standardizzazione (scaling)

Normalizziamo le feature con media 0 e deviazione standard 1 (StandardScaler):

$$\Large z_i = \frac{x_i - \mu}{\sigma}$$

dove:
- $z_i$ = valore standardizzato della feature per l'osservazione *i*
- $x_i$ = valore originale della feature
- $\mu$ = **media** di tutti i valori della feature nel dataset
- $\sigma$ = **deviazione standard** di tutti i valori della feature nel dataset

| Raggio medio (scaled) | Punti di concavitÃ  (scaled) | Diagnosi |
|---|---|---|
| 1.097 | 2.532 | maligno |
| âˆ’0.167 | âˆ’0.029 | benigno |
| 1.830 | 0.548 | maligno |
| âˆ’1.313 | âˆ’0.726 | benigno |

#### Step 3 â€” Codifica della variabile target

Trasformiamo la variabile categorica in numerica:

- **Maligno** = Classe Positiva = **1**
- **Benigno** = Classe Negativa = **0**

> [!IMPORTANT]
> La scelta di quale classe sia "positiva" (1) e quale "negativa" (0) Ã¨ convenzionale, ma ha impatto diretto su come interpretiamo tutte le metriche successive (precision, recall, ecc.).

---

### 2.2 Il Decision Boundary

Il **Decision Boundary** (soglia di decisione) Ã¨ la **retta** (o iperpiano, in piÃ¹ dimensioni) che separa quanto meglio le due classi nello spazio delle feature.

#### Il modello lineare sottostante

La regressione logistica parte dalla stessa equazione lineare della regressione:

$$\Large z = w_1 x_1 + w_2 x_2 + b$$

dove:
- `xâ‚, xâ‚‚` sono le feature (es. raggio medio, punti di concavitÃ )
- `wâ‚, wâ‚‚` sono i **pesi** (weights) â€” il modello li apprende durante l'addestramento
- `b` Ã¨ il **bias** (intercetta)

Il valore di `z` determina da che parte del boundary cade un'osservazione:

| Valore di z | Interpretazione |
|---|---|
| **z > 0** | Il punto sta dal lato della **classe positiva** (maligno) |
| **z < 0** | Il punto sta dal lato della **classe negativa** (benigno) |
| **z = 0** | Il punto sta esattamente **sul boundary** |

#### Esempio numerico

Supponiamo che dopo l'addestramento il modello abbia imparato:
- wâ‚ = 0.8 (peso per raggio medio)
- wâ‚‚ = 1.2 (peso per punti di concavitÃ )
- b = âˆ’0.5

Per un tumore con raggio medio (scaled) = 1.097 e punti di concavitÃ  (scaled) = 2.532:

$$\Large z = 0.8 \times 1.097 + 1.2 \times 2.532 + (-0.5) = 0.878 + 3.038 - 0.5 = 3.416$$

Dato che **z = 3.416 > 0** â†’ il modello classifica come **maligno** âœ“

Per un tumore con raggio (scaled) = âˆ’1.313 e concavitÃ  (scaled) = âˆ’0.726:

$$\Large z = 0.8 \times (-1.313) + 1.2 \times (-0.726) + (-0.5) = -1.050 - 0.871 - 0.5 = -2.421$$

Dato che **z = âˆ’2.421 < 0** â†’ il modello classifica come **benigno** âœ“

---

### 2.3 La Funzione di Attivazione

Nella classificazione, non ci basta il valore grezzo `z`. Vogliamo un **output discreto** (0 o 1) o una **probabilitÃ ** (tra 0 e 1). Per questo si usa una **funzione di attivazione** che trasforma `z` nell'output finale.

#### Binary Step (la piÃ¹ semplice)

La funzione a gradino converte direttamente `z` in 0 o 1:

$$\Large \text{BinaryStep}(z) = \begin{cases} 1 & \text{se } z \geq 0 \\ 0 & \text{se } z < 0 \end{cases}$$

**Problema**: non fornisce una probabilitÃ , solo una decisione secca. Non Ã¨ derivabile in z = 0, quindi non possiamo usare il gradiente per ottimizzare i pesi.

---

### 2.4 La Funzione Sigmoide (Logistica)

Qui entra in gioco la vera protagonista della regressione logistica: la **funzione sigmoide** (detta anche funzione logistica).

$$\Large \sigma(z) = \frac{1}{1 + e^{-z}}$$

dove:
- $\sigma(z)$ = output della funzione sigmoide (probabilitÃ  prevista, tra 0 e 1)
- $z$ = valore di input (output del modello lineare: $w_1 x_1 + w_2 x_2 + b$)
- $e$ = costante di Eulero (â‰ˆ 2.718)

#### ProprietÃ  fondamentali

| ProprietÃ  | Descrizione |
|---|---|
| **Range** | Output sempre tra 0 e 1 â†’ interpretabile come probabilitÃ  |
| **Ïƒ(0) = 0.5** | Quando z = 0, la probabilitÃ  Ã¨ esattamente 50% |
| **z â†’ +âˆ â‡’ Ïƒ(z) â†’ 1** | Valori grandi di z danno probabilitÃ  vicine a 1 |
| **z â†’ âˆ’âˆ â‡’ Ïƒ(z) â†’ 0** | Valori molto negativi danno probabilitÃ  vicine a 0 |
| **Derivabile ovunque** | Permette l'uso della discesa del gradiente |
| **Simmetria** | Ïƒ(âˆ’z) = 1 âˆ’ Ïƒ(z) |

#### Calcolo passo-passo

Riprendiamo l'esempio precedente con z = 3.416:

$$\Large \sigma(3.416) = \frac{1}{1 + e^{-3.416}} = \frac{1}{1 + 0.0327} = \frac{1}{1.0327} = 0.968$$

**Interpretazione**: il modello prevede una probabilitÃ  del **96.8%** che il tumore sia maligno.

Ora con z = âˆ’2.421:

$$\Large \sigma(-2.421) = \frac{1}{1 + e^{2.421}} = \frac{1}{1 + 11.257} = \frac{1}{12.257} = 0.082$$

**Interpretazione**: probabilitÃ  dell'**8.2%** che sia maligno â†’ quindi probabilitÃ  del **91.8%** che sia benigno.

#### La soglia (threshold)

Di default il threshold Ã¨ **0.5**:

$$\Large \hat{y} = \begin{cases} 1 \text{ (positivo)} & \text{se } \sigma(z) \geq 0.5 \\ 0 \text{ (negativo)} & \text{se } \sigma(z) < 0.5 \end{cases}$$

dove:
- $\hat{y}$ = classe prevista dal modello (0 o 1)
- $\sigma(z)$ = probabilitÃ  stimata dalla funzione sigmoide
- $0.5$ = soglia (threshold) di default

> [!TIP]
> Il threshold puÃ² essere modificato in base al contesto. In campo medico, potremmo abbassarlo a 0.3 per essere piÃ¹ conservativi: meglio un falso allarme che un tumore non diagnosticato.

---

### 2.5 La Funzione di Costo

Come si addestra un modello di regressione logistica? **Minimizzando una funzione di costo** tramite un algoritmo di ottimizzazione iterativo (tipicamente la **discesa del gradiente**).

#### Step 1 â€” Likelihood (Verosimiglianza)

La domanda fondamentale Ã¨: *qual Ã¨ la probabilitÃ  di ottenere il target Y, avendo le feature X e i parametri W?*

Per una singola osservazione, la likelihood Ã¨:

$$\Large P(y_i | x_i, W) = \hat{y}_i^{y_i} \cdot (1 - \hat{y}_i)^{(1 - y_i)}$$

dove:
- `Å·áµ¢ = Ïƒ(z)` Ã¨ la probabilitÃ  prevista dal modello
- `yáµ¢` Ã¨ il valore reale (0 o 1)

**PerchÃ© funziona?** Vediamo i due casi:

| Caso | y = 1 (positivo) | y = 0 (negativo) |
|---|---|---|
| **Formula diventa** | Å·Â¹ Â· (1âˆ’Å·)â° = **Å·** | Å·â° Â· (1âˆ’Å·)Â¹ = **1âˆ’Å·** |
| **Interpretazione** | Vogliamo Å· vicino a 1 | Vogliamo Å· vicino a 0 (cioÃ¨ 1âˆ’Å· vicino a 1) |

Per tutto il dataset (assumendo osservazioni indipendenti):

$$\Large L(W) = \prod_{i=1}^{n} P(y_i | x_i, W)$$

dove:
- $L(W)$ = likelihood (verosimiglianza) complessiva del modello
- $\prod$ = produttoria (prodotto di tutti i termini)
- $n$ = numero totale di osservazioni nel dataset
- $P(y_i | x_i, W)$ = probabilitÃ  dell'osservazione *i* dato il modello

#### Step 2 â€” Log Likelihood

Il prodotto di tanti numeri piccoli causa problemi numerici (underflow). Soluzione: usiamo il **logaritmo** â€” che trasforma il prodotto in somma.

$$\Large \log L(W) = \sum_{i=1}^{n} \left[ y_i \cdot \log(\hat{y}_i) + (1 - y_i) \cdot \log(1 - \hat{y}_i) \right]$$

dove:
- $\log L(W)$ = logaritmo della likelihood
- $\sum$ = sommatoria su tutte le *n* osservazioni
- $y_i$ = valore reale della classe (0 o 1) per l'osservazione *i*
- $\hat{y}_i$ = probabilitÃ  prevista dal modello per l'osservazione *i*
- $\log$ = logaritmo naturale

> [!NOTE]
> Il logaritmo Ã¨ una funzione **monotona crescente**: massimizzare L(W) equivale a massimizzare log L(W). Ma il logaritmo rende i calcoli molto piÃ¹ semplici.

#### Step 3 â€” Log Loss (Cross Entropy)

Nella pratica, preferiamo **minimizzare** una funzione di costo anzichÃ© massimizzare la verosimiglianza. Basta cambiare il segno:

$$\Large \text{LogLoss} = -\frac{1}{n} \sum_{i=1}^{n} \left[ y_i \cdot \log(\hat{y}_i) + (1 - y_i) \cdot \log(1 - \hat{y}_i) \right]$$

dove:
- $n$ = numero totale di osservazioni
- $y_i$ = classe reale (0 o 1)
- $\hat{y}_i$ = probabilitÃ  prevista dal modello
- il segno $-$ trasforma la massimizzazione della likelihood in minimizzazione del costo
- $\frac{1}{n}$ = media su tutte le osservazioni

#### Esempio numerico completo

Supponiamo 3 osservazioni:

| Osservaz. | y (reale) | Å· (previsto) | Termine |
|---|---|---|---|
| 1 | 1 | 0.968 | 1Â·log(0.968) + 0Â·log(0.032) = **âˆ’0.033** |
| 2 | 0 | 0.082 | 0Â·log(0.082) + 1Â·log(0.918) = **âˆ’0.086** |
| 3 | 1 | 0.750 | 1Â·log(0.750) + 0Â·log(0.250) = **âˆ’0.288** |

$$\Large \text{LogLoss} = -\frac{1}{3}(-0.033 - 0.086 - 0.288) = -\frac{-0.407}{3} = 0.136$$

**Interpretazione**: piÃ¹ la Log Loss Ã¨ vicina a 0, migliore Ã¨ il modello.

---

## 3. La Classificazione Multiclasse

Quando le classi da prevedere sono **piÃ¹ di due**, abbiamo un problema di classificazione multiclasse.

> Esempio: riconoscere cifre scritte a mano â†’ 10 classi (0, 1, 2, â€¦, 9)

### 3.1 Metodo One vs Rest (OvR)

*Detto anche One vs All (OvA).*

L'idea Ã¨ semplice: **scomporre un problema multiclasse in piÃ¹ problemi binari**.

#### Come funziona, passo per passo

Supponiamo di avere 3 classi: ğŸ”´, ğŸŸ¢, ğŸ”µ

```mermaid
graph LR
    subgraph "Modello 1"
        A1["ğŸ”´ vs (ğŸŸ¢+ğŸ”µ)"]
    end
    subgraph "Modello 2"
        A2["ğŸŸ¢ vs (ğŸ”´+ğŸ”µ)"]
    end
    subgraph "Modello 3"
        A3["ğŸ”µ vs (ğŸ”´+ğŸŸ¢)"]
    end
```

**Procedimento:**

1. **Per ogni classe**, addestra un modello di regressione logistica binaria
2. In ogni modello, la classe scelta Ã¨ quella **positiva**, tutte le altre diventano **negative**
3. Per classificare una nuova osservazione, **esegui tutti i modelli**
4. Assegna la classe del modello che restituisce la **probabilitÃ  piÃ¹ alta**

#### Esempio numerico

Per una nuova osservazione x, i tre modelli restituiscono:

| Modello | Classe positiva | ProbabilitÃ  stimata |
|---|---|---|
| Modello 1 | ğŸ”´ | 0.72 |
| Modello 2 | ğŸŸ¢ | 0.15 |
| Modello 3 | ğŸ”µ | 0.58 |

**Classificazione finale**: ğŸ”´ (probabilitÃ  piÃ¹ alta = 0.72)

#### Numero di modelli

$$\Large \text{Modelli OvR} = K$$

dove K Ã¨ il numero di classi. Con 10 classi â†’ **10 modelli**.

---

### 3.2 Metodo One vs One (OvO)

Addestra un modello per ogni **coppia** di classi.

#### Come funziona

Sempre con 3 classi: ğŸ”´, ğŸŸ¢, ğŸ”µ

| Modello | Confronto |
|---|---|
| Modello 1 | ğŸ”´ vs ğŸŸ¢ |
| Modello 2 | ğŸ”´ vs ğŸ”µ |
| Modello 3 | ğŸŸ¢ vs ğŸ”µ |

Ogni modello "vota" per una classe. La classe con piÃ¹ voti vince.

#### Numero di modelli

$$\Large \text{Modelli OvO} = \frac{K \times (K - 1)}{2}$$

dove:
- $K$ = numero totale di classi nel problema
- $K - 1$ = le altre classi con cui confrontare ciascuna classe
- si divide per $2$ perchÃ© ogni coppia (A vs B) Ã¨ uguale a (B vs A)

| K (classi) | Modelli OvR | Modelli OvO |
|---|---|---|
| 3 | 3 | 3 |
| 5 | 5 | 10 |
| 10 | 10 | 45 |
| 26 | 26 | 325 |

> [!WARNING]
> All'aumentare del numero di classi, il numero di modelli nel OvO **cresce molto piÃ¹ velocemente** rispetto all'OvR. Per molte classi, OvR Ã¨ generalmente preferibile.

---

### 3.3 Classi vs Label (Multilabel)

| Concetto | Definizione | Esempio |
|---|---|---|
| **Classe** | Un'osservazione puÃ² appartenere a **una sola classe** (mutuamente esclusiva) | Paese di nascita: se sei nato in Italia, non sei nato negli USA |
| **Label** | Un'osservazione puÃ² avere **piÃ¹ label** contemporaneamente | Cittadinanza: puoi avere sia quella italiana che quella statunitense |

Quando la variabile target Ã¨ un insieme di label, si parla di **classificazione multilabel**.

```
Classificazione Multiclasse:   y âˆˆ {A, B, C}         â†’ una sola classe
Classificazione Multilabel:    y âŠ† {tag1, tag2, tag3} â†’ una o piÃ¹ label
```

---

## 4. Metriche per la Classificazione

Le metriche ci permettono di **quantificare la bontÃ ** di un modello di classificazione.

### 4.1 Matrice di Confusione

Ãˆ lo strumento fondamentale: ci dice **non solo quanti errori** ha commesso il modello, ma **anche quali**.

#### Struttura

| | **Previsto: Positivo** | **Previsto: Negativo** |
|---|---|---|
| **Reale: Positivo** | âœ… **TP** (True Positive) | âŒ **FN** (False Negative) |
| **Reale: Negativo** | âŒ **FP** (False Positive) | âœ… **TN** (True Negative) |

#### Definizioni

| Sigla | Nome | Significato |
|---|---|---|
| **TP** | True Positive | Osservazioni positive classificate **correttamente** come positive |
| **FP** | False Positive | Osservazioni negative classificate **erroneamente** come positive |
| **FN** | False Negative | Osservazioni positive classificate **erroneamente** come negative |
| **TN** | True Negative | Osservazioni negative classificate **correttamente** come negative |

#### Esempio concreto (tumori)

Supponiamo un modello testato su 100 pazienti:

| | **Previsto: Maligno** | **Previsto: Benigno** |
|---|---|---|
| **Reale: Maligno** | TP = **40** | FN = **10** |
| **Reale: Benigno** | FP = **5** | TN = **45** |

- **40** tumori maligni diagnosticati correttamente âœ…
- **10** tumori maligni **non diagnosticati** (pericoloso!) âŒ
- **5** tumori benigni classificati maligni (falsi allarmi) âŒ
- **45** tumori benigni diagnosticati correttamente âœ…

> [!CAUTION]
> I **False Negative** (FN = 10) sono l'errore piÃ¹ pericoloso in campo medico: sono tumori maligni che il modello ha classificato come benigni. Un paziente potrebbe non ricevere il trattamento necessario.

Useremo questi numeri per tutte le metriche che seguono.

---

### 4.2 Accuracy

**Definizione**: la percentuale di classificazioni corrette sul totale.

$$\Large \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$

dove:
- $TP$ = True Positive (positivi classificati correttamente)
- $TN$ = True Negative (negativi classificati correttamente)
- $FP$ = False Positive (negativi classificati erroneamente come positivi)
- $FN$ = False Negative (positivi classificati erroneamente come negativi)

#### Calcolo con il nostro esempio

$$\Large \text{Accuracy} = \frac{40 + 45}{40 + 45 + 5 + 10} = \frac{85}{100} = 0.85 = 85\%$$

Il modello classifica correttamente l'85% dei pazienti.

> [!WARNING]
> L'accuracy puÃ² essere **ingannevole** con dataset sbilanciati. Se il 95% dei pazienti Ã¨ sano, un modello che dice sempre "benigno" avrebbe accuracy del 95% pur essendo inutile!

---

### 4.3 Precision

**Definizione**: delle osservazioni che il modello ha classificato come **positive**, quante lo erano davvero?

$$\Large \text{Precision} = \frac{TP}{TP + FP}$$

dove:
- $TP$ = True Positive (positivi classificati correttamente)
- $FP$ = False Positive (negativi classificati erroneamente come positivi)
- $TP + FP$ = tutte le osservazioni che il modello ha **previsto** come positive

#### Calcolo

$$\Large \text{Precision} = \frac{40}{40 + 5} = \frac{40}{45} = 0.889 = 88.9\%$$

**Interpretazione**: quando il modello dice "maligno", ha ragione l'88.9% delle volte.

**Quando Ã¨ importante?** Quando i **falsi positivi** sono costosi (es: filtro anti-spam â†’ non vogliamo che email importanti finiscano nello spam).

---

### 4.4 Recall (Sensitivity)

**Definizione**: delle osservazioni **realmente positive**, quante sono state individuate dal modello?

$$\Large \text{Recall} = \frac{TP}{TP + FN}$$

dove:
- $TP$ = True Positive (positivi classificati correttamente)
- $FN$ = False Negative (positivi classificati erroneamente come negativi)
- $TP + FN$ = tutte le osservazioni che sono **realmente** positive

*Detta anche SensibilitÃ  (Sensitivity) o True Positive Rate (TPR).*

#### Calcolo

$$\Large \text{Recall} = \frac{40}{40 + 10} = \frac{40}{50} = 0.80 = 80\%$$

**Interpretazione**: il modello riesce a individuare l'80% dei tumori maligni.

**Quando Ã¨ importante?** Quando i **falsi negativi** sono pericolosi (es: diagnosi medica â†’ non vogliamo perdere nemmeno un tumore maligno).

#### Precision vs Recall: il trade-off

Esiste un **compromesso** tra le due metriche. Abbassando il threshold (soglia):

| Threshold | Precision | Recall | Effetto |
|---|---|---|---|
| Alto (0.8) | **Alta** â†‘ | **Bassa** â†“ | Pochi FP, ma molti FN |
| Default (0.5) | Media | Media | Equilibrio |
| Basso (0.2) | **Bassa** â†“ | **Alta** â†‘ | Pochi FN, ma molti FP |

---

### 4.5 Specificity

**Definizione**: delle osservazioni **realmente negative**, quante sono state classificate correttamente come negative?

$$\Large \text{Specificity} = \frac{TN}{TN + FP}$$

dove:
- $TN$ = True Negative (negativi classificati correttamente)
- $FP$ = False Positive (negativi classificati erroneamente come positivi)
- $TN + FP$ = tutte le osservazioni che sono **realmente** negative

#### Calcolo

$$\Large \text{Specificity} = \frac{45}{45 + 5} = \frac{45}{50} = 0.90 = 90\%$$

**Interpretazione**: il modello identifica correttamente il 90% dei tumori benigni.

> [!NOTE]
> La Specificity Ã¨ la "Recall per la classe negativa". Recall misura quanto bene individui i positivi, Specificity misura quanto bene individui i negativi.

---

### 4.6 Curva ROC e AUC

#### La Curva ROC (Receiver Operating Characteristic)

Ci permette di valutare le **performance del modello al variare del threshold**.

**Assi del grafico:**
- **Asse Y**: Sensitivity (Recall) = TPR = TP / (TP + FN)
- **Asse X**: 1 âˆ’ Specificity = FPR = FP / (FP + TN)

```
1.0 â”¤         â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â”‚       â•­â”€â•¯
    â”‚     â•­â”€â•¯
    â”‚   â•­â”€â•¯              â† Curva ROC (buon modello)
TPR â”‚  â•­â•¯
    â”‚ â•­â•¯
    â”‚â•­â•¯   â•± â† Linea diagonale (modello casuale)
    â”œâ•¯  â•±
    â”‚ â•±
0.0 â”¼â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    0.0                  1.0
              FPR
```

**Come leggerlo:**
- **Curva vicina all'angolo in alto a sinistra** â†’ modello eccellente (alta Sensitivity, basso FPR)
- **Curva sulla diagonale** â†’ modello casuale (inutile)
- **Curva sotto la diagonale** â†’ modello peggiore del caso (invertire le previsioni!)

#### AUC (Area Under the ROC Curve)

Un unico numero che riassume la curva ROC:

$$\Large \text{AUC} \in [0, 1]$$

| AUC | QualitÃ  del modello |
|---|---|
| 1.0 | Perfetto |
| 0.9 â€“ 1.0 | Eccellente |
| 0.8 â€“ 0.9 | Buono |
| 0.7 â€“ 0.8 | Discreto |
| 0.5 | Casuale (inutile) |
| < 0.5 | Peggiore del caso |

**Interpretazione intuitiva**: l'AUC rappresenta la probabilitÃ  che il modello assegni uno score piÃ¹ alto a un esempio positivo scelto a caso rispetto a un esempio negativo scelto a caso.

---

### 4.7 F1 Score

**Definizione**: la **media armonica** tra Precision e Recall. Sintetizza entrambe le metriche in un unico valore.

$$\Large F1 = 2 \cdot \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$$

dove:
- $\text{Precision}$ = percentuale di previsioni positive corrette
- $\text{Recall}$ = percentuale di positivi reali individuati
- il fattore $2$ bilancia la formula della media armonica

#### Calcolo

$$\Large F1 = 2 \cdot \frac{0.889 \times 0.80}{0.889 + 0.80} = 2 \cdot \frac{0.711}{1.689} = 2 \cdot 0.421 = 0.842$$

#### PerchÃ© la media armonica e non quella aritmetica?

La **media armonica penalizza i valori estremi**:

| Precision | Recall | Media aritmetica | Media armonica (F1) |
|---|---|---|---|
| 1.0 | 0.0 | 0.50 | **0.00** |
| 0.9 | 0.1 | 0.50 | **0.18** |
| 0.8 | 0.8 | 0.80 | **0.80** |

Se una delle due metriche Ã¨ molto bassa, la media aritmetica potrebbe comunque dare un valore accettabile, ma l'F1 crollerÃ  â€” ed Ã¨ giusto cosÃ¬, perchÃ© un modello con Recall pari a 0 Ã¨ inutile anche se ha Precision perfetta.

---

### 4.8 Log Loss (Cross Entropy)

La **Log Loss** Ã¨ la funzione di costo della regressione logistica, ma viene usata anche come **metrica di valutazione**.

$$\Large \text{LogLoss} = -\frac{1}{n} \sum_{i=1}^{n} \left[ y_i \cdot \log(\hat{y}_i) + (1 - y_i) \cdot \log(1 - \hat{y}_i) \right]$$

dove:
- $n$ = numero totale di osservazioni
- $y_i$ = classe reale (0 o 1) per l'osservazione *i*
- $\hat{y}_i$ = probabilitÃ  prevista dal modello per l'osservazione *i*
- $\log$ = logaritmo naturale

A differenza di Accuracy, Precision e Recall, la Log Loss tiene conto non solo della **correttezza** ma anche della **confidenza** (probabilitÃ ) della previsione.

#### Esempio: perchÃ© la confidenza conta

| Modello | Previsione | RealtÃ  | Accuracy | Log Loss |
|---|---|---|---|---|
| A | Å· = 0.99 â†’ 1 | y = 1 | âœ… Corretta | âˆ’log(0.99) = **0.01** (ottimo) |
| B | Å· = 0.51 â†’ 1 | y = 1 | âœ… Corretta | âˆ’log(0.51) = **0.67** (alto) |

Entrambi i modelli classificano correttamente, ma il **Modello A** Ã¨ molto piÃ¹ sicuro della sua previsione. La Log Loss cattura questa differenza; l'Accuracy no.

> [!TIP]
> **Log Loss = 0** significa previsioni perfette. PiÃ¹ Ã¨ bassa, meglio Ã¨.

---

## 5. Riepilogo Formule

| Metrica | Formula | Range | Obiettivo |
|---|---|---|---|
| **Accuracy** | (TP + TN) / (TP + TN + FP + FN) | [0, 1] | Massimizzare |
| **Precision** | TP / (TP + FP) | [0, 1] | Massimizzare |
| **Recall** | TP / (TP + FN) | [0, 1] | Massimizzare |
| **Specificity** | TN / (TN + FP) | [0, 1] | Massimizzare |
| **F1 Score** | 2 Â· (Precision Ã— Recall) / (Precision + Recall) | [0, 1] | Massimizzare |
| **AUC** | Area sotto la curva ROC | [0, 1] | Massimizzare |
| **Log Loss** | âˆ’(1/n) Î£ [yáµ¢ log(Å·áµ¢) + (1âˆ’yáµ¢) log(1âˆ’Å·áµ¢)] | [0, +âˆ) | Minimizzare |

### Quando usare quale metrica?

```mermaid
graph TD
    A[Che metrica uso?] --> B{Dataset bilanciato?}
    B -- SÃ¬ --> C[Accuracy Ã¨ ok]
    B -- No --> D{Cosa Ã¨ piÃ¹ costoso?}
    D -- "FP costosi<br/>(falsi allarmi)" --> E[Precision]
    D -- "FN costosi<br/>(mancata diagnosi)" --> F[Recall]
    D -- "Entrambi" --> G[F1 Score]
    A --> H{Serve valutare<br/>la probabilitÃ ?}
    H -- SÃ¬ --> I[Log Loss / AUC]
    H -- No --> J[Accuracy/F1]
```

---

> **âœ¨ Consiglio finale**: ogni metrica racconta una parte della storia. Non affidarti mai a una sola metrica. Usa la **matrice di confusione** per capire dove sbaglia il modello, e poi scegli la metrica piÃ¹ adatta al tuo specifico problema.
