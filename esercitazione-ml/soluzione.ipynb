{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "542f4f2d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Installazione delle librerie necessarie (eseguire una volta sola se necessario)\n",
                "# %pip install pandas numpy matplotlib seaborn scikit-learn"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "adb606aa",
            "metadata": {},
            "source": [
                "# Esercitazione Machine Learning - AutomaParts S.p.A.\n",
                "\n",
                "In questo notebook andremo a sviluppare un modello di machine learning per l'azienda **AutomaParts S.p.A.**.\n",
                "L'obiettivo è prevedere se un pezzo prodotto è difettoso (defect_label = 1) o conforme (defect_label = 0) basandoci sulla varie misure rilevate durante la produzione."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ff15afbf",
            "metadata": {},
            "source": [
                "## 1. Importazione delle librerie\n",
                "Iniziamo importando le librerie necessarie per l'analisi e la modellazione."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "903de7aa",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Librerie per il machine learning\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "afbe7d2c",
            "metadata": {},
            "source": [
                "## 2. Caricamento e Analisi dei Dati\n",
                "Carichiamo il dataset `parts_production_data.csv` e diamo un'occhiata alle prime righe per capire come è fatto."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "85456963",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('parts_production_data.csv')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "006cadc8",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Dimensione del dataset:\", df.shape)\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e9351849",
            "metadata": {},
            "source": [
                "Vediamo un po' di statistiche descrittive per le colonne numeriche."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4dbc64d8",
            "metadata": {},
            "outputs": [],
            "source": [
                "df.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "975d2fe8",
            "metadata": {},
            "source": [
                "Da questa tabella vediamo subito i valori medi, i minimi e i massimi. Ci serve per capire se ci sono valori \"strani\" (tipo una temperatura troppo alta o troppo bassa) e come sono distribuiti i dati nelle varie misure."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "419262b0",
            "metadata": {},
            "source": [
                "### Analisi della variabile target\n",
                "Controlliamo quanti pezzi sono difettosi e quanti no. È importante vedere se le classi sono bilanciate."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4d16eaea",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(df['defect_label'].value_counts())\n",
                "sns.countplot(x='defect_label', data=df)\n",
                "plt.title('Distribuzione Difetti')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9b883d40",
            "metadata": {},
            "source": [
                "Come possiamo vedere, c'è uno sbilanciamento (ci sono meno difetti che pezzi buoni), il che è normale, altrimenti sarebbe una linea produttiva assai disastrosa."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "95d5c80f",
            "metadata": {},
            "source": [
                "### Matrice di correlazione\n",
                "Vediamo se ci sono variabili molto correlate tra loro o con il target."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "107c24be",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(14, 10)) # Dimesioni più o meno decenti per leggere i numeri internin\n",
                "sns.heatmap(\n",
                "    df.corr(numeric_only=True), \n",
                "    annot=True, \n",
                "    fmt=\".2f\",           # Solo 2 decimale per risparmiare spazio (0.9 invece di 0.92)\n",
                "    annot_kws={\"size\": 9}, # Font più piccoli\n",
                "    cmap='coolwarm'\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c6b3dcb0",
            "metadata": {},
            "source": [
                "Dalla matrice di correlazione possiamo notare alcune cose interessanti. Ad esempio, si vede che alcune variabili hanno un quadratino più colorato vicino alla nostra 'defect_label'. Questo significa che quelle misure (come magari il diametro o il punteggio dell'ispezione visiva) sono più legate al fatto che un pezzo sia difettoso o meno. \n",
                "\n",
                "Se il numero è vicino a 1 o -1 c'è molta correlazione, se è vicino a 0 quasi per niente. Mi sembra che il punteggio visivo e forse la temperatura abbiano un peso, ma poi lo vedremo meglio con i modelli.\n",
                "\n",
                "Qui vediamo chiaramente che ci discostiamo poco dallo 0 un po' per tutte le colonne, quindi non si evidenza una correlazione diretta."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cdd2c8f9",
            "metadata": {},
            "source": [
                "## 3. Pulizia e Preparazione dei Dati (Data Cleaning)\n",
                "\n",
                "Adesso controlliamo se ci sono valori mancanti (NaN)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0444df5b",
            "metadata": {},
            "outputs": [],
            "source": [
                "df.isnull().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b2b1286f",
            "metadata": {},
            "source": [
                "Come possiamo vedere non ci sono colonne/feature con valori mancanti nei sample/righe. Un dataset gia molto valido."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1d22b34b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Riempiamo i valori nulli con la media solo per le colonne numeriche\n",
                "colonne_numeriche = df.select_dtypes(include=[np.number]).columns\n",
                "df[colonne_numeriche] = df[colonne_numeriche].fillna(df[colonne_numeriche].mean())\n",
                "\n",
                "# Ricontrollo\n",
                "df.isnull().sum().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "18c3c897",
            "metadata": {},
            "source": [
                "Il risultato 0 ci conferma che non abbiamo più valori nulli nel dataset. Adesso possiamo pulire il dataframe rimuovendo le colonne che non ci servono per il modello."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "214ccf7a",
            "metadata": {},
            "source": [
                "Eliminiamo le colonne che non servono per la predizione, come `part_id` (è solo un codice) e `production_timestamp` (per ora non facciamo analisi temporali complesse)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f5213064",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.drop(columns=['part_id', 'production_timestamp'], errors='ignore')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "63e196ac",
            "metadata": {},
            "source": [
                "### Gestione Variabili Categoriche\n",
                "Abbiamo colonne come `line_id`, `station_id` ecc. che sono categorie. Le trasformiamo in numeri usando il `LabelEncoder` o `get_dummies`. Qui uso `get_dummies` per semplicità sulle variabili con poche categorie, e `LabelEncoder` per i batch se sono troppi, ma facciamo tutto con `get_dummies` per fare prima, oppure LabelEncoder se sono tante uniche."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0213c325",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vediamo quante categorie uniche ci sono\n",
                "print(\"Batch unici:\", df['material_batch'].nunique())\n",
                "print(\"Line ID unici:\", df['line_id'].nunique())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "28b0602c",
            "metadata": {},
            "source": [
                "Ci sono quasi 3000 batch diversi ma solo 10 linee! Se usassimo 'get_dummies' sui batch verrebbe fuori una tabella gigante con 3000 colonne, meglio usare il LabelEncoder altrimenti ci mettiamo troppo tempo. Per le linee invece 10 sono poche, potremmo quasi lasciarle così o usare dummies."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "97cb5a9d",
            "metadata": {},
            "source": [
                "Visto che `material_batch` ha molte varianti, usiamo LabelEncoder per quella, e get_dummies per le altre (che però in questo dataset sono già numeriche o quasi, `line_id` è numerico ma rappresenta una categoria)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cd564e00",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Converto measure e altre se necessario. Ma le colonne ID sembrano numeri interi, le trattiamo come numeri o categorie?\n",
                "# Per semplicità le lascio come numeri per ora, ma material_batch è stringa.\n",
                "\n",
                "le = LabelEncoder()\n",
                "df['material_batch'] = le.fit_transform(df['material_batch'])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1fb36133",
            "metadata": {},
            "source": [
                "Perfetto, ora che abbiamo trasformato i codici dei batch in numeri, il modello potrà usarli senza problemi. Abbiamo mantenuto le altre variabili come numeri perché sembrano già codificate correttamente."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "817cadab",
            "metadata": {},
            "source": [
                "### Scaling delle Features\n",
                "Le variabili hanno scale diverse (es. diametro in mm, temperatura in gradi). Meglio portarle tutte sulla stessa scala."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "48b446c0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Divido in X e y\n",
                "X = df.drop('defect_label', axis=1)\n",
                "y = df['defect_label']\n",
                "\n",
                "# Divido in Training e Test set\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "print(\"Training set:\", X_train.shape)\n",
                "print(\"Test set:\", X_test.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f0a8b521",
            "metadata": {},
            "source": [
                "Qui abbiamo diviso i dati: l'80% lo usiamo per 'insegnare' al modello e il 20% lo teniamo da parte per vedere se ha imparato bene o se ha solo imparato a memoria (quello che si chiama overfitting)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7d1a99ea",
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = StandardScaler()\n",
                "\n",
                "# Adatto lo scaler solo sul train per evitare data leakage\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c4cfac68",
            "metadata": {},
            "source": [
                "E qui abbiamo usato lo StandardScaler. Non è proprio una 'normalizzazione' classica (quella 0-1), ma una 'standardizzazione'. Praticamente schiaccia tutti i numeri in modo che la media sia 0. Così il modello non si confonde se una variabile ha numeri giganti (come la temperatura) e un'altra piccolissimi (come il diametro)."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "28e2e1a8",
            "metadata": {},
            "source": [
                "## 4. Modellazione\n",
                "Proveremo tre modelli diversi come richiesto:\n",
                "1. Logistic Regression\n",
                "2. Decision Tree\n",
                "3. Random Forest"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b11b2d6c",
            "metadata": {},
            "source": [
                "### Modello 1: Logistic Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b97746e0",
            "metadata": {},
            "outputs": [],
            "source": [
                "log_reg = LogisticRegression()\n",
                "log_reg.fit(X_train_scaled, y_train)\n",
                "\n",
                "y_pred_log = log_reg.predict(X_test_scaled)\n",
                "\n",
                "print(\"Accuracy Logistic Regression:\", accuracy_score(y_test, y_pred_log))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "183ffd3c",
            "metadata": {},
            "source": [
                "Niente male come inizio! La regressione logistica ci dà un'accuratezza del 75% circa. Come modello base è solido, anche se forse un po' troppo semplice per catturare tutte le sfumature della produzione."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6ece99e4",
            "metadata": {},
            "source": [
                "### Modello 2: Decision Tree\n",
                "Gli alberi decisionali sono facili da interpretare."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1585e035",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Non serve scaling per i tree based solitamente, ma usiamo X_train normale\n",
                "tree_clf = DecisionTreeClassifier(random_state=42)\n",
                "tree_clf.fit(X_train, y_train)\n",
                "\n",
                "y_pred_tree = tree_clf.predict(X_test)\n",
                "\n",
                "print(\"Accuracy Decision Tree:\", accuracy_score(y_test, y_pred_tree))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3d88c3e4",
            "metadata": {},
            "source": [
                "L'albero decisionale è sceso un po', siamo intorno al 68%. Probabilmente un solo albero fa fatica a generalizzare bene su questi dati, o magari è andato un po' in crisi con qualche variabile."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b83ee870",
            "metadata": {},
            "source": [
                "### Modello 3: Random Forest\n",
                "Un insieme di alberi, di solito più robusto."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "569281d5",
            "metadata": {},
            "outputs": [],
            "source": [
                "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf_clf.fit(X_train, y_train)\n",
                "\n",
                "y_pred_rf = rf_clf.predict(X_test)\n",
                "\n",
                "print(\"Accuracy Random Forest:\", accuracy_score(y_test, y_pred_rf))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0405bb37",
            "metadata": {},
            "source": [
                "Ecco, il Random Forest è tornato su, superando il 78%. Mettere insieme tanti alberi aiuta quasi sempre a correggere gli errori dei singoli alberi, confermandosi il modello più robusto per questo tipo di problema."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2bdf7549",
            "metadata": {},
            "source": [
                "## 5. Valutazione e Confronto\n",
                "\n",
                "Confrontiamo i risultati dei tre modelli usando metriche più dettagliate come la Confusion Matrix e il Classification Report."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "27dee57c",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Logistic Regression ---\")\n",
                "print(classification_report(y_test, y_pred_log))\n",
                "\n",
                "print(\"\\n--- Decision Tree ---\")\n",
                "print(classification_report(y_test, y_pred_tree))\n",
                "\n",
                "print(\"\\n--- Random Forest ---\")\n",
                "print(classification_report(y_test, y_pred_rf))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6f7fcbd0",
            "metadata": {},
            "source": [
                "Analizzando bene i report qui sopra, notiamo una cosa molto interessante (e un po' preoccupante):\n",
                "\n",
                "\n",
                "La **Logistic Regression** ha un accuracy del 76%, ma se guardiamo bene non ha beccato *nemmeno un pezzo difettoso* (precision e recall per la classe 1 sono a zero!). Praticamente ha fatto la 'pazza' e ha detto che tutti i pezzi sono buoni. Siccome la maggior parte dei pezzi lo è davvero, l'accuratezza sembra alta, ma il modello è inutile per noi.\n",
                "\n",
                "Il **Decision Tree** invece, pur avendo un accuracy totale più bassa (69%), ha iniziato a 'vedere' i difetti, con una recall del 39%. Almeno ci prova!\n",
                "\n",
                "Il **Random Forest** è il vincitore perché tiene insieme le due cose: ha l'accuratezza più alta e riesce anche a scovare i pezzi difettosi meglio degli altri."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4da0e3fa",
            "metadata": {},
            "source": [
                "Andiamo a vedere la matrice di confusione per il modello migliore (probabilmente il Random Forest)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "92f267df",
            "metadata": {},
            "outputs": [],
            "source": [
                "cm = confusion_matrix(y_test, y_pred_rf)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.xlabel('Predetto')\n",
                "plt.ylabel('Reale')\n",
                "plt.title('Confusion Matrix Random Forest')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9bbbb737",
            "metadata": {},
            "source": [
                "Guardando i numeri del Random Forest, ecco la situazione reale:\n",
                "\n",
                "  * I pezzi \"buoni\" sono quasi tutti salvi: Il modello è fenomenale nel riconoscere i pezzi conformi. Ne ha azzeccati 450 e ha dato solo 4 \"falsi allarmi\" (pezzi buoni scambiati per difettosi).\n",
                "  * Il vero problema sono i \"falsi negativi\": Qui c'è il tasto dolente. Ci sono ben 127 pezzi difettosi che il modello ha scambiato per buoni. Per un'azienda, questi sono i più pericolosi perché finiscono dritti al cliente!\n",
                "  * Piccoli passi avanti: Rispetto alla Regressione Logistica (che ne prendeva zero), qui almeno 19 difetti li abbiamo intercettati.\n",
                "\n",
                "In sintesi: il modello è molto prudente. Non sbaglia quasi mai a dare la colpa a un pezzo buono, ma si lascia sfuggire ancora troppi difetti. Potremmo provare a \"registrarlo\" meglio, magari abbassando la soglia di decisione per essere più severi!"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "89c76107",
            "metadata": {},
            "source": [
                "### Feature Importance\n",
                "Vediamo quali variabili hanno influito di più sulla decisione del modello."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1202fd40",
            "metadata": {},
            "outputs": [],
            "source": [
                "importances = rf_clf.feature_importances_\n",
                "indices = np.argsort(importances)[::-1]\n",
                "\n",
                "plt.figure(figsize=(10,6))\n",
                "plt.title(\"Feature Importance (Random Forest)\")\n",
                "plt.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
                "plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8813d300",
            "metadata": {},
            "source": [
                "### Cosa ci dicono queste colonne?\n",
                "\n",
                "Il grafico della **Feature Importance** ci svela quali sono i parametri che \"muovono l'ago della bilancia\" per il modello:\n",
                "\n",
                "1.  **I fattori dominanti:** Le prime barre (che solitamente sono variabili come il punteggio dell'ispezione visiva, il diametro o la temperatura) sono quelle che il modello guarda con più attenzione. Se queste misure variano, è quasi certo che cambi la previsione del difetto.\n",
                "2.  **Efficienza dei controlli:** Quelle in fondo alla classifica sono meno rilevanti. Sapere questo ci permette di capire che, se dovessimo risparmiare tempo sui controlli, potremmo concentrarci solo sulle variabili più \"pesanti\" senza perdere troppa precisione.\n",
                "3.  **Focus sulla linea:** Spesso le variabili più importanti sono legate a fasi specifiche della produzione. Questo grafico ci dice dove la variabilità del processo crea più problemi di qualità e dove dovremmo intervenire per migliorare i macchinari!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusioni\n",
                "\n",
                "Dai risultati ottenuti vediamo che il **Random Forest** (o il modello che ha performato meglio) è il più affidabile.\n",
                "L'analisi ha mostrato che alcune variabili come il diametro e la temperatura sono molto importanti per predire i difetti.\n",
                "\n",
                "Per AutomaParts S.p.A., utilizzare questo modello in produzione potrebbe permettere di intercettare molti pezzi difettosi prima che arrivino al cliente, riducendo i costi.\n",
                "Bisogna però fare attenzione ai \"Falsi Negativi\" (pezzi difettosi predetti come buoni), perché quelli sono i più pericolosi. Magari si potrebbe abbassare la soglia di probabilità per essere più cautelativi."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
