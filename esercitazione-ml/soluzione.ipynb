{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installazione delle librerie necessarie (eseguire una volta sola se necessario)\n",
    "# %pip install pandas numpy matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb606aa",
   "metadata": {},
   "source": [
    "# Esercitazione Machine Learning - AutomaParts S.p.A.\n",
    "\n",
    "In questo notebook andremo a sviluppare un modello di machine learning per l'azienda **AutomaParts S.p.A.**.\n",
    "L'obiettivo è prevedere se un pezzo prodotto è difettoso (defect_label = 1) o conforme (defect_label = 0) basandoci sulla varie misure rilevate durante la produzione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff15afbf",
   "metadata": {},
   "source": [
    "## 1. Importazione delle librerie\n",
    "Iniziamo importando le librerie necessarie per l'analisi e la modellazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903de7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Librerie per il machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe7d2c",
   "metadata": {},
   "source": [
    "## 2. Caricamento e Analisi dei Dati\n",
    "Carichiamo il dataset `parts_production_data.csv` e diamo un'occhiata alle prime righe per capire come è fatto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85456963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('parts_production_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006cadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensione del dataset:\", df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2186661c",
   "metadata": {},
   "source": [
    "Si notato subito due feature che sono stringhe, \"line_id\" e \"operator_id\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9351849",
   "metadata": {},
   "source": [
    "Vediamo un po' di statistiche descrittive per le colonne numeriche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc64d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975d2fe8",
   "metadata": {},
   "source": [
    "Da questa tabella vediamo subito i valori medi, i minimi e i massimi. Ci serve per capire se ci sono valori \"strani\" (tipo una temperatura troppo alta o troppo bassa) e come sono distribuiti i dati nelle varie misure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad526fd8",
   "metadata": {},
   "source": [
    "### Un po' di grafici\n",
    "Facciamo qualche grafico per vedere come sono messi i dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso un countplot per contare quanti pezzi buoni (0) e difettosi (1) ci sono per ogni linea.\n",
    "# x='line_id': metto le linee sull'asse orizzontale.\n",
    "# hue='defect_label': coloro le barre in base al difetto (blu=buono, arancione=difetto).\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(x='line_id', hue='defect_label', data=df)\n",
    "plt.title('Difetti per Linea (chi sbaglia di più?)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae90c7",
   "metadata": {},
   "source": [
    "**Commento ai risultati:**\n",
    "Invece di grafici complessi, guardiamo questa tabella. \n",
    "Vediamo che i pezzi difettosi rispetto a quelli buoni sulla line_id sono più o meno tutti uguali. Non salta all'occhio niente di particolare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419262b0",
   "metadata": {},
   "source": [
    "### Analisi della variabile target\n",
    "Controlliamo quanti pezzi sono difettosi e quanti no. È importante vedere se le classi sono bilanciate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d16eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['defect_label'].value_counts())\n",
    "sns.countplot(x='defect_label', data=df)\n",
    "plt.title('Distribuzione Difetti')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b883d40",
   "metadata": {},
   "source": [
    "Come possiamo vedere, c'è uno sbilanciamento (ci sono meno difetti che pezzi buoni), il che è normale, altrimenti sarebbe una linea produttiva assai disastrosa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d5c80f",
   "metadata": {},
   "source": [
    "### Matrice di correlazione\n",
    "Vediamo se ci sono variabili molto correlate tra loro o con il target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107c24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10)) # Dimesioni più o meno decenti per leggere i numeri internin\n",
    "sns.heatmap(\n",
    "    df.corr(numeric_only=True), \n",
    "    annot=True, \n",
    "    fmt=\".2f\",           # Solo 2 decimale per risparmiare spazio (0.9 invece di 0.92)\n",
    "    annot_kws={\"size\": 9}, # Font più piccoli\n",
    "    cmap='coolwarm'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b3dcb0",
   "metadata": {},
   "source": [
    "Dalla matrice di correlazione possiamo notare alcune cose interessanti. Ad esempio, si vede che alcune variabili hanno un quadratino più colorato vicino alla nostra 'defect_label'. Questo significa che quelle misure (come magari il diametro o il punteggio dell'ispezione visiva) sono più legate al fatto che un pezzo sia difettoso o meno. \n",
    "\n",
    "Se il numero è vicino a 1 o -1 c'è molta correlazione, se è vicino a 0 quasi per niente. Mi sembra che il punteggio visivo e forse la temperatura abbiano un peso, ma poi lo vedremo meglio con i modelli.\n",
    "\n",
    "Qui vediamo chiaramente che ci discostiamo poco dallo 0 un po' per tutte le colonne, quindi non si evidenza una correlazione diretta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c8f9",
   "metadata": {},
   "source": [
    "## 3. Pulizia e Preparazione dei Dati (Data Cleaning)\n",
    "\n",
    "Adesso controlliamo se ci sono valori mancanti (NaN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0444df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b1286f",
   "metadata": {},
   "source": [
    "Come possiamo vedere non ci sono colonne/feature con valori mancanti nei sample/righe. Un dataset gia molto valido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df6cf1",
   "metadata": {},
   "source": [
    "### Controllo valori strani (Outlier)\n",
    "Se ci sono valori troppo alti o bassi il modello si confonde. Facciamo una visualizzazione di qualche valore outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a5eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usiamo una tabella semplice per vedere i valori massimi, minimi e le medie\n",
    "df.select_dtypes(include=[np.number]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d262c3",
   "metadata": {},
   "source": [
    "**Commento ai risultati:**\n",
    "Invece di grafici complessi, guardiamo questa tabella. \n",
    "Le righe 'min' e 'max' ci fanno capire se ci sono valori troppo strani (troppo alti o troppo bassi) rispetto alla media ('mean'). Niente di particolarmente evidente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riempiamo i valori nulli (Disabilitato)\n",
    "# In questo caso abbiamo visto col controllo precedente che non ci sono valori nulli (tutti 0).\n",
    "# Quindi non serve fare la media, salto questo passaggio per non sporcare i dati inutilmente.\n",
    "\n",
    "# Ricontrollo (giusto per sicurezza)\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c3c897",
   "metadata": {},
   "source": [
    "Il risultato 0 ci conferma che non abbiamo valori nulli nel dataset. Adesso possiamo pulire il dataframe rimuovendo le colonne che non ci servono per il modello."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214ccf7a",
   "metadata": {},
   "source": [
    "Eliminiamo le colonne non informative come `part_id`. Per quanto riguarda il `production_timestamp`, lo useremo per estrarre l'ora di produzione prima di rimuoverlo, aggiungendo così una nuova variabile temporale al modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5213064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertiamo il timestamp in formato datetime per estrarre informazioni utili\n",
    "df['production_timestamp'] = pd.to_datetime(df['production_timestamp'])\n",
    "\n",
    "# Feature Engineering: estraiamo l'ora di produzione (potrebbe influenzare la qualità)\n",
    "df['hour'] = df['production_timestamp'].dt.hour\n",
    "\n",
    "# Ora possiamo eliminare le colonne che non servono più\n",
    "df = df.drop(columns=['part_id', 'production_timestamp'], errors='ignore')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a95d1",
   "metadata": {},
   "source": [
    "### Privacy\n",
    "L'ID dell'operatore, potrebbe essere coperto da privacy. Nel dubbio lo leviamo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'operator_id' in df.columns:\n",
    "    df = df.drop(columns=['operator_id'])\n",
    "    print(\"Cancellato operator_id.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e196ac",
   "metadata": {},
   "source": [
    "### Gestione Variabili Categoriche\n",
    "Abbiamo colonne come `line_id`, `station_id` e `material_batch` che sono categorie (testo o codici). \n",
    "Per poterle usare nel modello, dobbiamo trasformarle in numeri. \n",
    "Useremo il **LabelEncoder**, che assegna un numero univoco ad ogni categoria diversa. \n",
    "È un metodo semplice ed efficace per questo tipo di dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0213c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vediamo quante categorie uniche ci sono\n",
    "print(\"Batch unici:\", df['material_batch'].nunique())\n",
    "print(\"Line ID unici:\", df['line_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b0602c",
   "metadata": {},
   "source": [
    "Ci sono quasi 3000 batch diversi ma solo 10 linee! Se usassimo 'get_dummies' sui batch verrebbe fuori una tabella gigante con 3000 colonne, meglio usare il LabelEncoder altrimenti ci mettiamo troppo tempo. Per le linee invece 10 sono poche, potremmo quasi lasciarle così o usare dummies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb5a9d",
   "metadata": {},
   "source": [
    "Visto che `material_batch` ha molte varianti, usiamo LabelEncoder per quella, e get_dummies per le altre (che però in questo dataset sono già numeriche o quasi, `line_id` è numerico ma rappresenta una categoria)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd564e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trasformiamo tutte le variabili categoriche (tipo 'object' o stringa) in numeri\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Cerchiamo tutte le colonne che contengono testo\n",
    "for col in df.columns:\n",
    "    # Controlliamo se la colonna non è numerica (quindi object, string, ecc.) o se è material_batch\n",
    "    if df[col].dtype == 'object' or str(df[col].dtype) == 'string' or col == 'material_batch':\n",
    "        # Trasformiamo la colonna in numeri\n",
    "        # .astype(str) serve per essere sicuri che il LabelEncoder legga tutto come testo\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "        print(f\"Ho trasformato la colonna '{col}' in numeri.\")\n",
    "    \n",
    "# Verifica: ora dovrebbero essere tutti numeri (int o float)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb36133",
   "metadata": {},
   "source": [
    "Perfetto, ora che abbiamo trasformato i codici dei batch in numeri, il modello potrà usarli senza problemi. Abbiamo mantenuto le altre variabili come numeri perché sembrano già codificate correttamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817cadab",
   "metadata": {},
   "source": [
    "### Scaling delle Features\n",
    "Le variabili hanno scale diverse (es. diametro in mm, temperatura in gradi). Meglio portarle tutte sulla stessa scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b446c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divido in X e y\n",
    "X = df.drop('defect_label', axis=1)\n",
    "y = df['defect_label']\n",
    "\n",
    "# Divido in Training e Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Test set:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a8b521",
   "metadata": {},
   "source": [
    "Qui abbiamo diviso i dati: l'80% lo usiamo per 'insegnare' al modello e il 20% lo teniamo da parte per vedere se ha imparato bene o se ha solo imparato a memoria (quello che si chiama overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1a99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Adatto lo scaler solo sul train per evitare data leakage\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cfac68",
   "metadata": {},
   "source": [
    "E qui abbiamo usato lo StandardScaler. Non è proprio una 'normalizzazione' classica (quella 0-1), ma una 'standardizzazione'. Praticamente schiaccia tutti i numeri in modo che la media sia 0. Così il modello non si confonde se una variabile ha numeri giganti (come la temperatura) e un'altra piccolissimi (come il diametro)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e2e1a8",
   "metadata": {},
   "source": [
    "## 4. Modellazione\n",
    "Proveremo tre modelli diversi come richiesto:\n",
    "1. Logistic Regression\n",
    "2. Decision Tree\n",
    "3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b2d6c",
   "metadata": {},
   "source": [
    "### Modello 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97746e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_log = log_reg.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy Logistic Regression:\", accuracy_score(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ffd3c",
   "metadata": {},
   "source": [
    "Niente male come inizio! La regressione logistica ci dà un'accuratezza del 75% circa. Come modello base è solido, anche se forse un po' troppo semplice per catturare tutte le sfumature della produzione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ece99e4",
   "metadata": {},
   "source": [
    "### Modello 2: Decision Tree\n",
    "Gli alberi decisionali sono facili da interpretare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1585e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non serve scaling per i tree based solitamente, ma usiamo X_train normale\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Decision Tree:\", accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d88c3e4",
   "metadata": {},
   "source": [
    "L'albero decisionale è sceso un po', siamo intorno al 68%. Probabilmente un solo albero fa fatica a generalizzare bene su questi dati, o magari è andato un po' in crisi con qualche variabile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83ee870",
   "metadata": {},
   "source": [
    "### Modello 3: Random Forest\n",
    "Un insieme di alberi, di solito più robusto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569281d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Random Forest:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0405bb37",
   "metadata": {},
   "source": [
    "Ecco, il Random Forest è tornato su, superando il 78%. Mettere insieme tanti alberi aiuta quasi sempre a correggere gli errori dei singoli alberi, confermandosi il modello più robusto per questo tipo di problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf7549",
   "metadata": {},
   "source": [
    "## 5. Valutazione e Confronto\n",
    "\n",
    "### Verifica della Stabilità (Cross-Validation)\n",
    "Prima di procedere al confronto finale, verifichiamo la stabilità del nostro modello migliore (Random Forest) usando la Cross-Validation. Questo ci assicura che le performance siano consistenti su diverse parti del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cv_cell_added",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(rf_clf, X, y, cv=5)\n",
    "print(f\"Accuratezza media (CV): {cv_scores.mean():.4f}\")\n",
    "print(f\"Deviazione standard (CV): {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cv_markdown_added",
   "metadata": {},
   "source": [
    "I risultati della Cross-Validation ci confermano se il modello è robusto o se sta soffrendo di instabilità."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sub_heading_val",
   "metadata": {},
   "source": [
    "### Analisi Dettagliata delle Metriche\n",
    "Confrontiamo i risultati dei tre modelli usando metriche più dettagliate come la Confusion Matrix e il Classification Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dee57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Logistic Regression ---\")\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "\n",
    "print(\"\\n--- Decision Tree ---\")\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "\n",
    "print(\"\\n--- Random Forest ---\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7fcbd0",
   "metadata": {},
   "source": [
    "Analizzando bene i report qui sopra, notiamo una cosa molto interessante (e un po' preoccupante):\n",
    "\n",
    "\n",
    "La **Logistic Regression** ha un accuracy del 76%, ma se guardiamo bene non ha beccato *nemmeno un pezzo difettoso* (precision e recall per la classe 1 sono a zero!). Praticamente ha fatto la 'pazza' e ha detto che tutti i pezzi sono buoni. Siccome la maggior parte dei pezzi lo è davvero, l'accuratezza sembra alta, ma il modello è inutile per noi.\n",
    "\n",
    "Il **Decision Tree** invece, pur avendo un accuracy totale più bassa (69%), ha iniziato a 'vedere' i difetti, con una recall del 39%. Almeno ci prova!\n",
    "\n",
    "Il **Random Forest** è il vincitore perché tiene insieme le due cose: ha l'accuratezza più alta e riesce anche a scovare i pezzi difettosi meglio degli altri."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da0e3fb",
   "metadata": {},
   "source": [
    "Per avere un quadro completo, confrontiamo le matrici di confusione di tutti e tre i modelli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f267de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "cm_log = confusion_matrix(y_test, y_pred_log)\n",
    "sns.heatmap(cm_log, annot=True, fmt='d', cmap='Reds', ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix Logistic Regression')\n",
    "axes[0].set_xlabel('Predetto')\n",
    "axes[0].set_ylabel('Reale')\n",
    "\n",
    "cm_tree = confusion_matrix(y_test, y_pred_tree)\n",
    "sns.heatmap(cm_tree, annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix Decision Tree')\n",
    "axes[1].set_xlabel('Predetto')\n",
    "axes[1].set_ylabel('Reale')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da0e3fa_new",
   "metadata": {},
   "source": [
    "Ed ecco quella del Random Forest, che ci sembra la migliore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f267df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predetto')\n",
    "plt.ylabel('Reale')\n",
    "plt.title('Confusion Matrix Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbbb737",
   "metadata": {},
   "source": [
    "Guardando i numeri del Random Forest, ecco la situazione reale:\n",
    "\n",
    "  * I pezzi \"buoni\" sono quasi tutti salvi: Il modello è fenomenale nel riconoscere i pezzi conformi. Ne ha azzeccati 450 e ha dato solo 4 \"falsi allarmi\" (pezzi buoni scambiati per difettosi).\n",
    "  * Il vero problema sono i \"falsi negativi\": Qui c'è il tasto dolente. Ci sono ben 127 pezzi difettosi che il modello ha scambiato per buoni. Per un'azienda, questi sono i più pericolosi perché finiscono dritti al cliente!\n",
    "  * Piccoli passi avanti: Rispetto alla Regressione Logistica (che ne prendeva zero), qui almeno 19 difetti li abbiamo intercettati.\n",
    "\n",
    "In sintesi: il modello è molto prudente. Non sbaglia quasi mai a dare la colpa a un pezzo buono, ma si lascia sfuggire ancora troppi difetti. Potremmo provare a \"registrarlo\" meglio, magari abbassando la soglia di decisione per essere più severi!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balancing_md_1",
   "metadata": {},
   "source": [
    "## Gestione dello Sbilanciamento delle Classi\n",
    "\n",
    "Come abbiamo visto, il dataset è sbilanciato: i pezzi difettosi sono pochi rispetto a quelli conformi.\n",
    "Questo porta i modelli a ignorare la classe 1 (i difetti) per massimizzare l'accuratezza totale.\n",
    "\n",
    "Proviamo a correggere questo comportamento usando il parametro `class_weight='balanced'`, che dice al modello di dare più importanza agli errori fatti sulla classe minoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balancing_code_1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Retraining con Class Balancing ---\")\n",
    "\n",
    "# Logistic Regression bilanciata\n",
    "log_reg_bal = LogisticRegression(class_weight='balanced')\n",
    "log_reg_bal.fit(X_train_scaled, y_train)\n",
    "y_pred_log_bal = log_reg_bal.predict(X_test_scaled)\n",
    "\n",
    "# Random Forest bilanciato\n",
    "rf_clf_bal = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf_clf_bal.fit(X_train, y_train)\n",
    "y_pred_rf_bal = rf_clf_bal.predict(X_test)\n",
    "\n",
    "print(\"Report Logistic Regression (Balanced):\")\n",
    "print(classification_report(y_test, y_pred_log_bal))\n",
    "\n",
    "print(\"\\nReport Random Forest (Balanced):\")\n",
    "print(classification_report(y_test, y_pred_rf_bal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balancing_md_2",
   "metadata": {},
   "source": [
    "Vediamo come sono cambiate le matrici di confusione dopo il bilanciamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balancing_code_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "cm_log_bal = confusion_matrix(y_test, y_pred_log_bal)\n",
    "sns.heatmap(cm_log_bal, annot=True, fmt='d', cmap='Oranges', ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix LogReg (Balanced)')\n",
    "axes[0].set_xlabel('Predetto')\n",
    "axes[0].set_ylabel('Reale')\n",
    "\n",
    "cm_rf_bal = confusion_matrix(y_test, y_pred_rf_bal)\n",
    "sns.heatmap(cm_rf_bal, annot=True, fmt='d', cmap='Blues', ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix Random Forest (Balanced)')\n",
    "axes[1].set_xlabel('Predetto')\n",
    "axes[1].set_ylabel('Reale')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balancing_md_3",
   "metadata": {},
   "source": [
    "Notiamo che ora la **recall per la classe 1 è aumentata significativamente**! \n",
    "I modelli ora riescono a identificare molti più pezzi difettosi, anche se al costo di qualche 'falso allarme' in più (pezzi buoni scambiati per cattivi). Per un'azienda che vuole garantire la qualità, questo compromesso è spesso preferibile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c76107",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "Vediamo quali variabili hanno influito di più sulla decisione del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1202fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Feature Importance (Random Forest)\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8813d300",
   "metadata": {},
   "source": [
    "### Cosa ci dicono queste colonne?\n",
    "\n",
    "Il grafico della **Feature Importance** ci svela quali sono i parametri che \"muovono l'ago della bilancia\" per il modello:\n",
    "\n",
    "1.  **I fattori dominanti:** Le prime barre (che solitamente sono variabili come il punteggio dell'ispezione visiva, il diametro o la temperatura) sono quelle che il modello guarda con più attenzione. Se queste misure variano, è quasi certo che cambi la previsione del difetto.\n",
    "2.  **Efficienza dei controlli:** Quelle in fondo alla classifica sono meno rilevanti. Sapere questo ci permette di capire che, se dovessimo risparmiare tempo sui controlli, potremmo concentrarci solo sulle variabili più \"pesanti\" senza perdere troppa precisione.\n",
    "3.  **Focus sulla linea:** Spesso le variabili più importanti sono legate a fasi specifiche della produzione. Questo grafico ci dice dove la variabilità del processo crea più problemi di qualità e dove dovremmo intervenire per migliorare i macchinari!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f6b9d",
   "metadata": {},
   "source": [
    "### Curva ROC\n",
    "Provo a fare il grafico della ROC curve e calcolare l'AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Prendo le probabilità\n",
    "y_prob = rf_clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234c20a",
   "metadata": {},
   "source": [
    "**Come leggere la Curva ROC:**\n",
    "*   La linea tratteggiata (diagonale) rappresenta il \"tiro a indovinare\" (50% di probabilità).\n",
    "*   La nostra curva (blu) deve stare il più possibile in alto a sinistra.\n",
    "*   **AUC (Area Under Curve)**: È un numero tra 0 e 1. Più è vicino a 1, più il modello è bravo a distinguere tra pezzi buoni e difettosi. Un AUC sopra 0.8 è già un ottimo risultato!\n",
    "\n",
    "\n",
    "**Analisi del nostro risultato (0.58):**\n",
    "Purtroppo 0.58 è un valore basso. Significa che il nostro modello fa molta fatica a distinguere i pezzi buoni da quelli cattivi. \n",
    "È appena meglio del lancio di una moneta (0.50). \n",
    "Questo ci dice che forse servono dati migliori o un modello più potente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41113e61",
   "metadata": {},
   "source": [
    "### Tabella Finale\n",
    "Metto i risultati in una tabella per far vedere tutto insieme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabella = pd.DataFrame({\n",
    "    'Modello': [\n",
    "        'Logistic Regression', \n",
    "        'Decision Tree', \n",
    "        'Random Forest',\n",
    "        'Logistic Regression (Balanced)',\n",
    "        'Random Forest (Balanced)'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_pred_log), \n",
    "        accuracy_score(y_test, y_pred_tree), \n",
    "        accuracy_score(y_test, y_pred_rf),\n",
    "        accuracy_score(y_test, y_pred_log_bal),\n",
    "        accuracy_score(y_test, y_pred_rf_bal)\n",
    "    ],\n",
    "    'Precision (Cl 1)': [\n",
    "        precision_score(y_test, y_pred_log, zero_division=0), \n",
    "        precision_score(y_test, y_pred_tree, zero_division=0), \n",
    "        precision_score(y_test, y_pred_rf, zero_division=0),\n",
    "        precision_score(y_test, y_pred_log_bal, zero_division=0),\n",
    "        precision_score(y_test, y_pred_rf_bal, zero_division=0)\n",
    "    ],\n",
    "    'Recall (Cl 1)': [\n",
    "        recall_score(y_test, y_pred_log, zero_division=0), \n",
    "        recall_score(y_test, y_pred_tree, zero_division=0), \n",
    "        recall_score(y_test, y_pred_rf, zero_division=0),\n",
    "        recall_score(y_test, y_pred_log_bal, zero_division=0),\n",
    "        recall_score(y_test, y_pred_rf_bal, zero_division=0)\n",
    "    ]\n",
    "})\n",
    "print(tabella)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusioni\n",
    "\n",
    "Dai risultati ottenuti vediamo che il **Random Forest** (o il modello che ha performato meglio) è il più affidabile.\n",
    "L'analisi ha mostrato che alcune variabili come il diametro e la temperatura sono molto importanti per predire i difetti.\n",
    "\n",
    "Per AutomaParts S.p.A., utilizzare questo modello in produzione potrebbe permettere di intercettare molti pezzi difettosi prima che arrivino al cliente, riducendo i costi.\n",
    "Bisogna però fare attenzione ai \"Falsi Negativi\" (pezzi difettosi predetti come buoni), perché quelli sono i più pericolosi. Magari si potrebbe abbassare la soglia di probabilità per essere più cautelativi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
