{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione Machine Learning - AutomaParts S.p.A.\n",
    "\n",
    "In questo notebook andremo a sviluppare un modello di machine learning per l'azienda **AutomaParts S.p.A.**.\n",
    "L'obiettivo è prevedere se un pezzo prodotto è difettoso (defect_label = 1) o conforme (defect_label = 0) basandoci su varie misure rilevate durante la produzione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importazione delle librerie\n",
    "Iniziamo importando le librerie necessarie per l'analisi e la modellazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Librerie per il machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Caricamento e Analisi dei Dati\n",
    "Carichiamo il dataset `parts_production_data.csv` e diamo un'occhiata alle prime righe per capire come è fatto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('parts_production_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensione del dataset:\", df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo un po' di statistiche descrittive per le colonne numeriche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi della variabile target\n",
    "Controlliamo quanti pezzi sono difettosi e quanti no. È importante vedere se le classi sono bilanciate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['defect_label'].value_counts())\n",
    "sns.countplot(x='defect_label', data=df)\n",
    "plt.title('Distribuzione Difetti')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come possiamo vedere, c'è uno sbilanciamento (ci sono meno difetti che pezzi buoni), il che è normale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice di correlazione\n",
    "Vediamo se ci sono variabili molto correlate tra loro o con il target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "# Selezioniamo solo le colonne numeriche per la correlazione\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Matrice di Correlazione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pulizia e Preparazione dei Dati (Data Cleaning)\n",
    "\n",
    "Adesso controlliamo se ci sono valori mancanti (NaN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ci sono valori mancanti, li riempiamo con la media della colonna. In questo modo non perdiamo i dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riempio i valori nulli con la media solo per le colonne numeriche\n",
    "colonne_numeriche = df.select_dtypes(include=[np.number]).columns\n",
    "df[colonne_numeriche] = df[colonne_numeriche].fillna(df[colonne_numeriche].mean())\n",
    "\n",
    "# Ricontrollo\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminiamo le colonne che non servono per la predizione, come `part_id` (è solo un codice) e `production_timestamp` (per ora non facciamo analisi temporali complesse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['part_id', 'production_timestamp'], errors='ignore')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestione Variabili Categoriche\n",
    "Abbiamo colonne come `line_id`, `station_id` ecc. che sono categorie. Le trasformiamo in numeri usando il `LabelEncoder` o `get_dummies`. Qui uso `get_dummies` per semplicità sulle variabili con poche categorie, e `LabelEncoder` per i batch se sono troppi, ma facciamo tutto con `get_dummies` per fare prima, oppure LabelEncoder se sono tante uniche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vediamo quante categorie uniche ci sono\n",
    "print(\"Batch unici:\", df['material_batch'].nunique())\n",
    "print(\"Line ID unici:\", df['line_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visto che `material_batch` ha molte varianti, usiamo LabelEncoder per quella, e get_dummies per le altre (che però in questo dataset sono già numeriche o quasi, `line_id` è numerico ma rappresenta una categoria)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converto measure e altre se necessario. Ma le colonne ID sembrano numeri interi, le trattiamo come numeri o categorie?\n",
    "# Per semplicità le lascio come numeri per ora, ma material_batch è stringa.\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['material_batch'] = le.fit_transform(df['material_batch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling delle Features\n",
    "Le variabili hanno scale diverse (es. diametro in mm, temperatura in gradi). Meglio portarle tutte sulla stessa scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divido in X e y\n",
    "X = df.drop('defect_label', axis=1)\n",
    "y = df['defect_label']\n",
    "\n",
    "# Divido in Training e Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Test set:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Adatto lo scaler solo sul train per evitare data leakage\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modellazione\n",
    "Proveremo tre modelli diversi come richiesto:\n",
    "1. Logistic Regression\n",
    "2. Decision Tree\n",
    "3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modello 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_log = log_reg.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy Logistic Regression:\", accuracy_score(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modello 2: Decision Tree\n",
    "Gli alberi decisionali sono facili da interpretare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non serve scaling per i tree based solitamente, ma usiamo X_train normale\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Decision Tree:\", accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modello 3: Random Forest\n",
    "Un insieme di alberi, di solito più robusto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Random Forest:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Valutazione e Confronto\n",
    "\n",
    "Confrontiamo i risultati dei tre modelli usando metriche più dettagliate come la Confusion Matrix e il Classification Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Logistic Regression ---\")\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "\n",
    "print(\"\\n--- Decision Tree ---\")\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "\n",
    "print(\"\\n--- Random Forest ---\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo a vedere la matrice di confusione per il modello migliore (probabilmente il Random Forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predetto')\n",
    "plt.ylabel('Reale')\n",
    "plt.title('Confusion Matrix Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "Vediamo quali variabili hanno influito di più sulla decisione del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Feature Importance (Random Forest)\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusioni\n",
    "\n",
    "Dai risultati ottenuti vediamo che il **Random Forest** (o il modello che ha performato meglio) è il più affidabile.\n",
    "L'analisi ha mostrato che alcune variabili come il diametro e la temperatura sono molto importanti per predire i difetti.\n",
    "\n",
    "Per AutomaParts S.p.A., utilizzare questo modello in produzione potrebbe permettere di intercettare molti pezzi difettosi prima che arrivino al cliente, riducendo i costi.\n",
    "Bisogna però fare attenzione ai \"Falsi Negativi\" (pezzi difettosi predetti come buoni), perché quelli sono i più pericolosi. Magari si potrebbe abbassare la soglia di probabilità per essere più cautelativi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
