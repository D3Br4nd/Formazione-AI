{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Modello di Classificazione dei Pezzi Difettosi — AutomaParts S.p.A.\n",
                "\n",
                "## Contesto Aziendale\n",
                "\n",
                "**AutomaParts S.p.A.** è un fornitore tier-1 per il settore automotive che produce componenti meccanici di precisione per sistemi sterzo e sospensioni.  \n",
                "In linea di produzione vengono misurate diverse caratteristiche per ogni pezzo (diametri, planarità, coppia, temperatura processo, ecc.).  \n",
                "Alcuni pezzi non rispettano le tolleranze e causano fermi macchina o richiami cliente.\n",
                "\n",
                "## Obiettivo\n",
                "\n",
                "Sviluppare un modello di **Machine Learning supervisionato** che distingua pezzi conformi (`defect_label = 0`) da pezzi difettosi (`defect_label = 1`) per:\n",
                "- **Scarto automatico** o blocco in ispezione finale\n",
                "- **Instradamento a controllo 100%** quando la probabilità è incerta\n",
                "- **Analisi delle cause principali** dei difetti per interventi di processo\n",
                "\n",
                "## Pipeline di lavoro\n",
                "\n",
                "1. Caricamento e prima esplorazione del dataset\n",
                "2. Analisi esplorativa (EDA)\n",
                "3. Pulizia dei dati\n",
                "4. Preparazione delle variabili (encoding, feature engineering, scaling)\n",
                "5. Addestramento di tre modelli: Logistic Regression, Decision Tree, Random Forest\n",
                "6. Gestione dello sbilanciamento delle classi\n",
                "7. Valutazione e confronto (metriche, confusion matrix, cross-validation, ROC, feature importance)\n",
                "8. Conclusioni e raccomandazioni operative"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f1270932",
            "metadata": {},
            "outputs": [],
            "source": [
                "# IMPORT — Tutte le librerie necessarie in un unico blocco\n",
                "\n",
                "# Manipolazione dati\n",
                "import pandas as pd     # Gestione di tabelle e dati strutturati (il \"motore\" per manipolare i CSV)\n",
                "import numpy as np      # Fondamentale per calcoli numerici e gestione di array/matrici\n",
                "\n",
                "# Visualizzazione\n",
                "import matplotlib.pyplot as plt # La libreria base per creare grafici e diagrammi\n",
                "import seaborn as sns           # Estensione di matplotlib per visualizzazioni statistiche più eleganti\n",
                "\n",
                "# Pre-processing\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder # Per normalizzare i dati e convertire variabili testuali in numeri\n",
                "\n",
                "# Modelli\n",
                "from sklearn.linear_model import LogisticRegression    # Algoritmo lineare per classificazione binaria (facile e veloce)\n",
                "from sklearn.tree import DecisionTreeClassifier         # Modello basato su \"alberi\" di decisione logicamente interpretabili\n",
                "from sklearn.ensemble import RandomForestClassifier     # Una \"foresta\" di alberi che migliora precisione e robustezza\n",
                "\n",
                "# Valutazione\n",
                "from sklearn.model_selection import train_test_split, cross_val_score # Per dividere i dati e testare quanto il modello è stabile\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score, # Metriche standard per misurare il successo del modello\n",
                "    confusion_matrix, classification_report,                 # Per analizzare dove il modello sbaglia (falsi positivi/negativi)\n",
                "    roc_curve, auc                                           # Per valutare la capacità del modello di distinguere le classi\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eced2554",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Caricamento e Prima Esplorazione\n",
                "\n",
                "Carichiamo il dataset `parts_production_data.csv` e verifichiamo dimensioni, tipi di dato e statistiche descrittive per avere un primo quadro della situazione."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d790d3d0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Caricamento del CSV in un DataFrame pandas\n",
                "df = pd.read_csv('parts_production_data.csv')\n",
                "\n",
                "# Prime 5 righe per un'anteprima visuale dei dati\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "63253ccd",
            "metadata": {},
            "source": [
                "### Struttura del Dataset\n",
                "\n",
                "| Variabile | Tipo | Descrizione |\n",
                "|-----------|------|-------------|\n",
                "| `part_id` | ID | Identificativo univoco del pezzo |\n",
                "| `production_timestamp` | Datetime | Data/ora di produzione |\n",
                "| `line_id` | Categorica | Linea produttiva (1-10) |\n",
                "| `station_id` | Categorica | Stazione di misura (1-20) |\n",
                "| `operator_id` | Categorica | Operatore (anonimizzato, 1-10) |\n",
                "| `measure_diam_mm` | Numerica | Diametro (mm) |\n",
                "| `measure_length_mm` | Numerica | Lunghezza (mm) |\n",
                "| `flatness_mm` | Numerica | Planarità superficiale (mm) |\n",
                "| `torque_Nm` | Numerica | Coppia registrata (Nm) |\n",
                "| `surface_roughness_Ra` | Numerica | Rugosità superficiale (Ra) |\n",
                "| `temp_process_C` | Numerica | Temperatura processo (°C) |\n",
                "| `vibration_level` | Numerica | Livello vibrazione (0-1) |\n",
                "| `cycle_time_s` | Numerica | Tempo ciclo (s) |\n",
                "| `material_batch` | Categorica | Lotto materia prima |\n",
                "| `visual_inspection_score` | Numerica | Punteggio ispezione visiva (0-1) |\n",
                "| `defect_label` | Target | Etichetta binaria (0 = conforme, 1 = difettoso) |\n",
                "\n",
                "**Variabili di identificazione e contesto:**  \n",
                "`part_id` è l'identificativo univoco del singolo pezzo e non ha valore predittivo. `production_timestamp` registra il momento esatto della produzione e può essere utile per estrarre informazioni temporali (turno, ora del giorno). `line_id`, `station_id` e `operator_id` rappresentano rispettivamente la linea produttiva, la stazione di misura e l'operatore coinvolto: servono a tracciare eventuali pattern legati a specifiche combinazioni di macchina/turno/persona. `material_batch` identifica il lotto di materia prima utilizzato — variazioni tra lotti possono influenzare la qualità del prodotto finito.\n",
                "\n",
                "**Misure dimensionali e di processo:**  \n",
                "`measure_diam_mm` e `measure_length_mm` sono misure dimensionali dirette del pezzo (diametro e lunghezza in millimetri), fondamentali per verificare il rispetto delle tolleranze meccaniche. `flatness_mm` misura la planarità superficiale: valori elevati indicano deformazioni che possono compromettere l'accoppiamento del componente. `torque_Nm` è la coppia di serraggio registrata durante l'assemblaggio, un parametro critico per la sicurezza nei sistemi sterzo e sospensioni.\n",
                "\n",
                "**Sensori e parametri di processo:**  \n",
                "`surface_roughness_Ra` misura la rugosità superficiale secondo uno standard: Ra — influisce sull'attrito e sulla durata del componente. `temp_process_C` è la temperatura del processo produttivo in gradi Celsius: temperature fuori range possono alterare le proprietà del materiale. `vibration_level` (normalizzato 0-1) rileva vibrazioni anomale della macchina, potenziale indicatore di usura utensile o disallineamento. `cycle_time_s` è il tempo ciclo in secondi: tempi anomali possono segnalare problemi di processo.\n",
                "\n",
                "**Ispezione e target:**  \n",
                "`visual_inspection_score` (0-1) è il punteggio assegnato dall'ispezione visiva automatica o manuale — un valore basso indica probabilmente difetti estetici o superficiali. `defect_label` è la nostra **variabile target** binaria: 0 indica un pezzo conforme, 1 un pezzo difettoso che non ha superato i controlli qualità."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "12b759a9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dimensioni del dataset e tipi di dato per ogni colonna\n",
                "print(\"Dimensione del dataset:\", df.shape)\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2c2afcb0",
            "metadata": {},
            "source": [
                "**Commento:** Notiamo subito che `production_timestamp` e `material_batch` sono di tipo stringa. Il timestamp andrà convertito in formato datetime per estrarne informazioni temporali, mentre `material_batch` è una variabile categorica ad alta cardinalità che richiederà un ulteriore lavorazione e/o un encoding numerico."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0d667693",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistiche descrittive per le variabili numeriche:\n",
                "# media, deviazione standard, min, max e quartili\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a3306350",
            "metadata": {},
            "source": [
                "**Commento:** La tabella `describe()` ci fornisce un colpo d'occhio su valori medi, minimi, massimi e distribuzione (quartili) di ogni variabile numerica. Ci serve per individuare subito eventuali valori anomali — per esempio una temperatura fuori range o un diametro implausibile. A prima vista, i dati sembrano coerenti: le medie e i range non presentano anomalie evidenti."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e4263655",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Analisi Esplorativa (EDA)\n",
                "\n",
                "Esploriamo la distribuzione della variabile target, la ripartizione dei difetti per linea produttiva e le correlazioni tra le variabili numeriche."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6fb8c23a",
            "metadata": {},
            "source": [
                "### 2.1 Distribuzione della variabile target\n",
                "\n",
                "Verifichiamo quanti pezzi risultano difettosi rispetto a quelli conformi. Lo sbilanciamento delle classi è un aspetto critico perché può ingannare le metriche di valutazione."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d9b5c819",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Conteggio pezzi conformi (0) e difettosi (1)\n",
                "print(df['defect_label'].value_counts())\n",
                "\n",
                "# Grafico a barre per visualizzare lo sbilanciamento\n",
                "sns.countplot(x='defect_label', data=df)\n",
                "plt.title('Distribuzione Difetti (0 = conforme, 1 = difettoso)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e856204d",
            "metadata": {},
            "source": [
                "**Commento:** Come atteso in una linea produttiva reale, i pezzi difettosi sono una **minoranza** rispetto a quelli conformi. Questo sbilanciamento è normale (altrimenti la linea sarebbe fuori controllo), ma ha un impatto diretto sui modelli: un classificatore potrebbe \"barare\" predicendo sempre la classe maggioritaria e ottenere comunque un'accuratezza elevata. Ne terremo conto nella fase di modellazione con tecniche di bilanciamento."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b049717f",
            "metadata": {},
            "source": [
                "### 2.2 Difetti per linea e stazione produttiva\n",
                "\n",
                "Analizziamo se alcune linee o stazioni produttive presentano un tasso di difettosità più alto di altre. Informazione utile per gli stakeholder e per interventi mirati. Non visualizziamo `material_batch` (~3000 lotti) perché un grafico a barre con migliaia di categorie sarebbe illeggibile."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8829a1a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Countplot difetti per LINEA produttiva\n",
                "\n",
                "# Definisce dimensioni grafico\n",
                "plt.figure(figsize=(10, 6))\n",
                "# Analizza la distribuzione dei difetti per ogni linea di produzione (line_id)\n",
                "# Il parametro 'hue' permette di confrontare visivamente pezzi conformi e difettosi tra le diverse linee\n",
                "sns.countplot(x=\"line_id\", hue=\"defect_label\", data=df) \n",
                "# Formattazione grafico\n",
                "plt.title(\"Distribuzione Difetti per Linea Produttiva\")\n",
                "plt.xlabel(\"Linea\")\n",
                "plt.ylabel(\"Conteggio pezzi\")\n",
                "plt.legend(title=\"Difetto\", labels=[\"Conforme\", \"Difettoso\"])\n",
                "# Disegna il grafico\n",
                "plt.show()\n",
                "\n",
                "# Countplot difetti per STAZIONE di misura\n",
                "\n",
                "# Definisce dimensioni grafico\n",
                "plt.figure(figsize=(14, 6))\n",
                "# Analizza la distribuzione dei difetti per ogni linea di produzione (station_id)\n",
                "# Il parametro 'hue' permette di confrontare visivamente pezzi conformi e difettosi tra le diverse linee\n",
                "sns.countplot(x=\"station_id\", hue=\"defect_label\", data=df)\n",
                "# Formattazione grafico\n",
                "plt.title(\"Distribuzione Difetti per Stazione di Misura\")\n",
                "plt.xlabel(\"Stazione\")\n",
                "plt.ylabel(\"Conteggio pezzi\")\n",
                "plt.legend(title=\"Difetto\", labels=[\"Conforme\", \"Difettoso\"])\n",
                "# Disegna il grafico\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "48802e41",
            "metadata": {},
            "source": [
                "**Commento:** Le proporzioni tra pezzi conformi e difettosi sono piuttosto uniformi sia tra le diverse linee che tra le stazioni di misura: nessuna si distingue in modo evidente per un tasso di difettosità anomalo. Questo suggerisce che i difetti non sono legati a una specifica linea o stazione ma probabilmente a fattori trasversali (materiali, parametri di processo, condizioni operative)."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a97719f9",
            "metadata": {},
            "source": [
                "### 2.3 Matrice di Correlazione\n",
                "\n",
                "Verifichiamo se esistono correlazioni forti tra le variabili numeriche e con il target `defect_label`. Variabili molto correlate tra loro o con il target possono guidare la scelta delle feature."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9aee5ca2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Heatmap delle correlazioni — valori tra -1 (correlazione negativa) e +1 (correlazione positiva)\n",
                "# Definiamo dimensioni grafico\n",
                "plt.figure(figsize=(14, 10))\n",
                "# Calcoliamo la Matrice di Correlazione e definiamo alcuni parametri\n",
                "sns.heatmap(\n",
                "    df.corr(numeric_only=True),\n",
                "    annot=True,\n",
                "    fmt=\".2f\",             # Due decimali per leggibilità\n",
                "    annot_kws={\"size\": 9}, # Font ridotto per evitare sovrapposizioni\n",
                "    cmap='coolwarm'\n",
                ")\n",
                "plt.title('Matrice di Correlazione')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "42a5381a",
            "metadata": {},
            "source": [
                "**Commento:** Questo grafico ci dice se le variabili sono \"amiche\" e si influenzano a vicenda. Vediamo che è quasi tutto blu, con valori molti vicino allo 0: significa che i dati sono molto indipendenti tra loro.In pratica, non c'è una \"variabile magica\" che da sola ci dice se il pezzo è difettoso."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1f1cfcec",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Pulizia dei Dati\n",
                "\n",
                "Verifichiamo la presenza di valori mancanti, trattiamo eventuali outlier e rimuoviamo le colonne non informative o sensibili sotto il profilo privacy."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "89c77796",
            "metadata": {},
            "source": [
                "### 3.1 Valori Mancanti"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "19c65916",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Conteggio dei valori nulli per ogni colonna\n",
                "df.isnull().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "264e030f",
            "metadata": {},
            "source": [
                "**Commento:** Il dataset non presenta **alcun valore mancante**: tutte le colonne hanno il conteggio completo di osservazioni. Non è quindi necessario applicare strategie di rimozione di righe incomplete. Un ottimo punto di partenza."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "85134bd0",
            "metadata": {},
            "source": [
                "### 3.2 Controllo Outlier (metodo IQR)\n",
                "\n",
                "Applichiamo il metodo dell'**Interquartile Range (IQR)** sulle principali variabili di processo per verificare la presenza di valori anomali. Un valore è considerato outlier se cade al di sotto di Q1 − 1.5·IQR o al di sopra di Q3 + 1.5·IQR.\n",
                "\n",
                "Abbiamo scelto le feature che sono dati \"continui\" e che possono presentare errori di lettura o anomalie estreme che sporcherebbero il modello. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3f7c34af",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creiamo una funzione per trovare ed eliminare i \"valori pazzi\" (outlier)\n",
                "def remove_outliers_iqr(df, column):\n",
                "    # Calcoliamo il 25% (punto basso) e il 75% (punto alto) dei dati\n",
                "    Q1 = df[column].quantile(0.25)\n",
                "    Q3 = df[column].quantile(0.75)\n",
                "    \n",
                "    # Calcoliamo la distanza tra questi due punti (l'intervallo centrale)\n",
                "    IQR = Q3 - Q1\n",
                "    \n",
                "    # Definiamo i confini: oltre questa \"recinzione\" il dato è considerato un errore\n",
                "    lower = Q1 - 1.5 * IQR\n",
                "    upper = Q3 + 1.5 * IQR\n",
                "    \n",
                "    # Teniamo solo i dati che stanno dentro i confini\n",
                "    return df[(df[column] >= lower) & (df[column] <= upper)]\n",
                "\n",
                "# Stampiamo quante righe abbiamo inizialmente\n",
                "print(f\"Righe PRIMA della pulizia: {len(df)}\")\n",
                "\n",
                "# Scegliamo solo le variabili numeriche dei sensori e delle misure fisiche\n",
                "cols_to_clean = ['measure_diam_mm', 'measure_length_mm', 'temp_process_C', 'vibration_level']\n",
                "\n",
                "# Applichiamo la pulizia colonna per colonna\n",
                "for col in cols_to_clean:\n",
                "    df = remove_outliers_iqr(df, col)\n",
                "\n",
                "# Verifichiamo quante righe sono rimaste (se ne abbiamo perse troppe, il filtro era troppo severo)\n",
                "print(f\"Righe DOPO la pulizia:  {len(df)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8520dfc9",
            "metadata": {},
            "source": [
                "**Commento:** Il conteggio delle righe prima e dopo la pulizia è identico: **nessun sample è stato eliminato**. Questo conferma quanto osservato dal `describe()` iniziale: i dati rientrano tutti in range ragionevoli e non presentano outlier significativi secondo il criterio IQR."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "257134f7",
            "metadata": {},
            "source": [
                "### 3.3 Rimozione colonne non informative e privacy\n",
                "\n",
                "- **`part_id`**: è un identificativo univoco progressivo, non porta informazione predittiva.\n",
                "- **`operator_id`**: potrebbe essere coperto da vincoli di privacy aziendale; inoltre, dal grafico di sez. 2.2 non emergeva un legame operatore↔difetto particolarmente forte. Lo rimuoviamo per cautela.\n",
                "- **`production_timestamp`**: prima di eliminarlo, estraiamo l'**ora di produzione** — potrebbe influenzare la qualità (es. turni, stanchezza)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eb7d449d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Controlliamo se la colonna esiste ancora prima di lavorarci\n",
                "if 'production_timestamp' in df.columns:\n",
                "    # Conversione del timestamp\n",
                "    df['production_timestamp'] = pd.to_datetime(df['production_timestamp'])\n",
                "\n",
                "    # Estraiamo l'ora\n",
                "    df['hour'] = df['production_timestamp'].dt.hour\n",
                "\n",
                "    # Rimozione colonne: ora possiamo farlo tranquillamente\n",
                "    df = df.drop(columns=['part_id', 'production_timestamp', 'operator_id'], errors='ignore')\n",
                "    print(\"Trasformazione completata con successo.\")\n",
                "else:\n",
                "    print(\"La colonna 'production_timestamp' è già stata rimossa o trasformata.\")\n",
                "\n",
                "print(\"\\nColonne finali nel dataset:\")\n",
                "for col in df.columns:\n",
                "    print(f\"- {col}\")\n",
                "\n",
                "# Prime 5 righe per un'anteprima visuale dei dati\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b4cd5ff7",
            "metadata": {},
            "source": [
                "**Commento:** Abbiamo ridotto il dataset alle sole colonne utili e aggiunto la feature `hour`. Il DataFrame ora contiene solo variabili che porteranno informazione ai modelli, rispettando inoltre i requisiti di privacy sull'operatore."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "57fec69b",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Preparazione delle Variabili\n",
                "\n",
                "In questa sezione estraiamo informazioni dalla colonna `material_batch`, trasformiamo le variabili categoriche in formato numerico, e applichiamo lo scaling."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "002b289d",
            "metadata": {},
            "source": [
                "### 4.1 Feature Engineering: Material Batch Analysis\n",
                "\n",
                "Estraiamo informazioni utili dalla colonna `material_batch` (formato `MB-YYYYWww-Lnn-sss`) per arricchire il dataset, mantenendo comunque la colonna originale per le aggregazioni successive.\n",
                "\n",
                "**Cosa estraiamo:**\n",
                "- **Anno (`batch_year`)**: utile per identificare trend di lungo periodo (es. invecchiamento macchinari).\n",
                "- **Settimana (`batch_week`)**: convertita poi in Seno/Coseno per catturare la stagionalità (es. temperatura esterna, cicli di manutenzione).\n",
                "- **Sequenza (`batch_seq`)**: il numero progressivo del lotto, fondamentale per intercettare derive temporali rapide.\n",
                "- **Linea (`batch_line_check`)**: estratta solo per validare la coerenza con la colonna `line_id`.\n",
                "\n",
                "**Nota importante:**\n",
                "La colonna originale `material_batch` **NON viene eliminata**. La manteniamo codificata (LabelEncoder) perché è essenziale per calcolare le *deviazioni* (sezione successiva), ovvero quanto un pezzo differisce dalla media del suo specifico lotto di produzione."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8b3b565d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Definizione di una funzione per \"smontare\" il codice del lotto (es. MB-2024W24-L02-575)\n",
                "def extract_batch_info(batch_str):\n",
                "    try:\n",
                "        # Dividiamo la stringa usando il trattino '-' come separatore\n",
                "        parts = batch_str.split('-')\n",
                "        \n",
                "        # Se non otteniamo 4 parti, il codice è scritto male e saltiamo la riga\n",
                "        if len(parts) != 4:\n",
                "            return None, None, None, None\n",
                "        \n",
                "        # La seconda parte (parts[1]) è '2024W24'. La dividiamo alla 'W'\n",
                "        year_week = parts[1].split('W')\n",
                "        year = int(year_week[0])  # Otteniamo l'anno (es. 2024)\n",
                "        week = int(year_week[1])  # Otteniamo la settimana (es. 24)\n",
                "        \n",
                "        # La terza parte (parts[2]) è 'L02'. Togliamo la 'L' e prendiamo il numero\n",
                "        line_id = int(parts[2][1:]) \n",
                "        \n",
                "        # L'ultima parte (parts[3]) è il numero progressivo (es. 575)\n",
                "        seq = int(parts[3])\n",
                "        \n",
                "        # Restituiamo i 4 valori pronti per essere salvati\n",
                "        return year, week, line_id, seq\n",
                "    except:\n",
                "        # In caso di errori imprevisti, restituiamo valori vuoti per non bloccare il codice\n",
                "        return None, None, None, None\n",
                "\n",
                "# Applichiamo la funzione a tutta la colonna 'material_batch'\n",
                "# Il risultato è una colonna temporanea di \"pacchetti\" contenenti i 4 dati sopra\n",
                "batch_data = df['material_batch'].apply(extract_batch_info)\n",
                "\n",
                "# \"Sballiamo\" i pacchetti e creiamo le nuove colonne nel dataset principale\n",
                "df['batch_year'] = batch_data.apply(lambda x: x[0])  # Estrae l'anno\n",
                "df['batch_week'] = batch_data.apply(lambda x: x[1])  # Estrae la settimana\n",
                "df['batch_line_check'] = batch_data.apply(lambda x: x[2]) # Estrae la linea (per controllo)\n",
                "df['batch_seq'] = batch_data.apply(lambda x: x[3])   # Estrae la sequenza\n",
                "\n",
                "# CONTROLLO QUALITÀ DATI: \n",
                "# Verifichiamo se la linea estratta dal codice lotto coincide con la colonna 'line_id' già presente\n",
                "mismatches = df[df['line_id'] != df['batch_line_check']]\n",
                "print(f\"Discrepanze trovate tra Line ID e codice Batch: {len(mismatches)}\")\n",
                "\n",
                "# Se i dati sono coerenti (0 errori), cancelliamo la colonna di controllo perché sarebbe un doppione\n",
                "if len(mismatches) == 0:\n",
                "    print(\"Dati coerenti. Rimuovo la colonna batch_line_check.\")\n",
                "    df.drop(columns=['batch_line_check'], inplace=True)\n",
                "else:\n",
                "    print(\"ATTENZIONE: Ci sono differenze nei dati! Indaga prima di proseguire.\")\n",
                "\n",
                "# TRASFORMAZIONE CICLICA:\n",
                "# Trasformiamo la settimana in coordinate Seno e Coseno.\n",
                "# Questo serve a far capire al computer che la settimana 52 e la settimana 1 sono \"vicine\" nel tempo (inverno).\n",
                "df['batch_week_sin'] = np.sin(2 * np.pi * df['batch_week'] / 53)\n",
                "df['batch_week_cos'] = np.cos(2 * np.pi * df['batch_week'] / 53)\n",
                "\n",
                "print(\"Operazione completata! Nuove colonne create per l'analisi temporale.\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "99de77ca",
            "metadata": {},
            "source": [
                "**Commento**: Abbiamo trasformato il testo complicato del lotto in numeri pronti per l'analisi. Ora il computer può 'vedere' l'anno, la settimana e la sequenza di produzione, aiutandolo a capire se i difetti dipendono dal periodo dell'anno o da quanto tempo la macchina sta lavorando."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b930bf8b",
            "metadata": {},
            "source": [
                "### 4.2 Encoding delle variabili categoriche (LabelEncoder)\n",
                "\n",
                "Il dataset contiene variabili categoriche di tipo stringa che i modelli non possono usare direttamente. Utilizziamo il **LabelEncoder** di scikit-learn, che assegna un numero intero univoco a ogni categoria. Per `material_batch`, che ha un'alta cardinalità (~3000 lotti diversi), il LabelEncoder è la scelta più pratica: usare `get_dummies` genererebbe migliaia di colonne.\n",
                "\n",
                "Sebbene abbiamo già estratto dati utili per questa colonna `material_batch` (che contiene migliaia di lotti diversi), fare anche il LabelEncoder è fondamentale: ci permette di mantenere l'identità unica di ogni lotto senza appesantire il dataset con migliaia di nuove colonne. In questo modo il modello potrà distinguere i singoli lotti usando un semplice codice numerico. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "540176ce",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verifica della cardinalità delle colonne categoriche\n",
                "print(\"Batch unici:\", df['material_batch'].nunique())\n",
                "print(\"Line ID unici:\", df['line_id'].nunique())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b9cc4d95",
            "metadata": {},
            "source": [
                "Se avessimo usato one-hot encoding su material_batch, avremmo effettivamente creato 2997 nuove colonne (una per ogni batch unico), rendendo il dataset enorme e il modello molto più complesso. Con il LabelEncoder il numero di colonne resta invariato."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "db510f42",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creiamo una copia del DataFrame: lavoriamo su 'df_encoded' per lasciare intatto quello originale\n",
                "df_encoded = df.copy()\n",
                "\n",
                "# Prepariamo l'attrezzo 'LabelEncoder' che traduce i testi in numeri (es: \"Batch-A\" -> 1)\n",
                "le = LabelEncoder()\n",
                "\n",
                "# Selezioniamo automaticamente solo le colonne che contengono testo (object o string)\n",
                "# In questo dataset troverà sicuramente 'material_batch'\n",
                "categorical_cols = df_encoded.select_dtypes(include=['object', 'string']).columns\n",
                "\n",
                "# Cicliamo su ogni colonna testuale trovata\n",
                "for col in categorical_cols:\n",
                "    # Trasformiamo la colonna: fit_transform impara le categorie e le sostituisce con i numeri\n",
                "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
                "    # Stampiamo un feedback per sapere quante categorie diverse sono state numerate\n",
                "    print(f\"Codificata: {col} → {df_encoded[col].nunique()} valori unici\")\n",
                "\n",
                "print(\"\\nEncoding completato.\")\n",
                "\n",
                "# Visualizziamo le prime righe del nuovo DataFrame \"numerico\" per verificare il risultato\n",
                "# Noterai che material_batch ora contiene numeri interi invece dei codici MB-...\n",
                "df_encoded.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6654da58",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizzazione dei valori encodati per material_batch e line_id\n",
                "df_encoded[['material_batch', 'line_id']].head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "71aa73a6",
            "metadata": {},
            "source": [
                "**Commento:** Tutte le colonne categoriche sono state trasformate in valori numerici interi. Da notare che `material_batch` ha un'alta cardinalità: il modello potrebbe tendere all'overfitting su questa variabile. Tuttavia, per gli scopi di questa esercitazione, il LabelEncoder è il compromesso più idoneo per confrontare la capacità di generalizzazione dei diversi algoritmi."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b59a9872",
            "metadata": {},
            "source": [
                "### 4.2 Feature Engineering — Deviazioni per lotto\n",
                "\n",
                "Spesso un valore non è 'anomalo' in assoluto, ma lo è rispetto al gruppo di pezzi prodotti nello stesso momento con la stessa materia prima.\n",
                "\n",
                "Calcoliamo le deviazioni dalla media del lotto per il diametro e la temperatura. Questo ci aiuta a capire se un pezzo è un 'outlier' all'interno della sua stessa famiglia (batch). Ad esempio: se un intero lotto viene prodotto a 100°C, un pezzo a 105°C è sospetto, anche se 105°C rientra nei limiti generali della fabbrica."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7e1b5389",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 1. ANALISI DEL DIAMETRO ---\n",
                "# Calcoliamo la media del diametro per ogni singolo lotto e la spalmiamo su ogni riga del lotto corrispondente\n",
                "df_encoded['batch_diam_mean'] = df_encoded.groupby('material_batch')['measure_diam_mm'].transform('mean')\n",
                "\n",
                "# Calcoliamo quanto il pezzo singolo \"sgarra\" rispetto alla media dei suoi compagni di lotto\n",
                "# Un valore positivo significa che è più grande della media, negativo che è più piccolo\n",
                "df_encoded['diam_dev_from_batch'] = df_encoded['measure_diam_mm'] - df_encoded['batch_diam_mean']\n",
                "\n",
                "# --- 2. ANALISI DELLA TEMPERATURA ---\n",
                "# Facciamo la stessa cosa per la temperatura: raggruppiamo per lotto e troviamo la media\n",
                "df_encoded['batch_temp_mean'] = df_encoded.groupby('material_batch')['temp_process_C'].transform('mean')\n",
                "\n",
                "# Calcoliamo lo scostamento termico: il pezzo è stato prodotto più al caldo o al freddo rispetto al suo lotto?\n",
                "# Questo serve a intercettare sbalzi improvvisi di temperatura durante la lavorazione\n",
                "df_encoded['temp_dev_from_batch'] = df_encoded['temp_process_C'] - df_encoded['batch_temp_mean']\n",
                "\n",
                "print(\"Feature engineering completato — aggiunte 4 colonne (2 medie + 2 deviazioni).\")\n",
                "\n",
                "# Visualizziamo le nuove colonne per capire il calcolo fatto\n",
                "# Vedrai il valore originale, la media del suo gruppo e la differenza finale\n",
                "df_encoded[['material_batch', 'measure_diam_mm', 'batch_diam_mean', 'diam_dev_from_batch']].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "28965b87",
            "metadata": {},
            "source": [
                "Perché proprio queste colonne?\n",
                "* Diametro: È la misura critica. Una deviazione improvvisa dal batch indica che qualcosa è cambiato fisicamente (magari l'utensile si è scheggiato o il pezzo si è mosso).\n",
                "* Temperatura: La temperatura esterna o del materiale cambia durante il giorno. La media del batch cattura la \"normalità\" del momento (es. fa caldo in tutta l'officina), mentre la deviazione cattura l'anomalia istantanea (es. un picco di calore solo su quel pezzo).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a5f17a0d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Esempio: prime 10 righe con le nuove colonne\n",
                "df_encoded[['material_batch', 'measure_diam_mm', 'batch_diam_mean', 'diam_dev_from_batch',\n",
                "            'temp_process_C', 'batch_temp_mean', 'temp_dev_from_batch']].head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eda3d4df",
            "metadata": {},
            "source": [
                "**Commento:** Le nuove feature `diam_dev_from_batch` e `temp_dev_from_batch` rappresentano quanto un singolo pezzo si discosta dalla norma del proprio lotto. In un contesto produttivo reale, con molti pezzi per lotto, queste informazioni contestuali darebbero al modello un segnale più preciso rispetto ai valori assoluti.\n",
                "\n",
                "**Osservazione importante:** Come si nota dalla tabella qui sopra, tutte le deviazioni risultano **0.0**. Questo accade perché nel nostro dataset ci sono **2997 batch unici su 3000 righe** — quasi ogni lotto contiene un solo pezzo. Quando si calcola la media di un gruppo con un solo elemento, la media coincide con il valore stesso, e la deviazione è inevitabilmente zero. Le colonne di feature engineering restano comunque nel dataset come esempio didattico dell'approccio, ma in questo caso specifico **non apportano informazione aggiuntiva** ai modelli."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "000c0ca0",
            "metadata": {},
            "source": [
                "### 4.3 Suddivisione Train / Test e Scaling\n",
                "\n",
                "Dividiamo il dataset in **Training Set (80%)** per l'addestramento e **Test Set (20%)** per la valutazione su dati non visti.  \n",
                "Successivamente applichiamo lo **StandardScaler** (standardizzazione con media=0 e deviazione standard=1), necessario per la Logistic Regression che è sensibile alle scale diverse delle variabili.  \n",
                "\n",
                "**Importante:** lo scaler viene fittato **solo sul training set** per evitare *data leakage* — il test set viene trasformato con le statistiche del train."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7d8e6638",
            "metadata": {},
            "outputs": [],
            "source": [
                "# STEP 1: DEFINIZIONE DEI DATI\n",
                "# X contiene tutti i dati di input (sensori, misure, tempi). Togliamo solo la risposta finale.\n",
                "X = df_encoded.drop('defect_label', axis=1)\n",
                "\n",
                "# y contiene solo il target, ovvero quello che il modello deve imparare a indovinare (0 o 1)\n",
                "y = df_encoded['defect_label']\n",
                "\n",
                "# STEP 2: DIVISIONE IN TRAINING E TEST\n",
                "# Dividiamo il dataset in due parti:\n",
                "# - Training (80%): i dati su cui il modello \"studia\" ed impara i pattern.\n",
                "# - Test (20%): i dati che teniamo \"nascosti\" per fare una simulazione d'esame finale e vedere se il modello ha imparato davvero.\n",
                "# random_state=42 serve a far sì che la divisione sia sempre la stessa ogni volta che premi \"Play\".\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "# STEP 3: FEEDBACK\n",
                "# Verifichiamo quante righe sono finite in ogni set\n",
                "# .shape[0] sono le righe (esempi), .shape[1] sono le colonne (caratteristiche del pezzo)\n",
                "print(f\"Training Set (Lo studio): {X_train.shape[0]} righe, {X_train.shape[1]} variabili\")\n",
                "print(f\"Test Set (L'esame):      {X_test.shape[0]} righe, {X_test.shape[1]} variabili\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8291e455",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creiamo l'attrezzo per normalizzare i dati\n",
                "scaler = StandardScaler()\n",
                "\n",
                "# FIT + TRANSFORM sul Training Set: \n",
                "# 1. 'fit' impara qual è la media e la deviazione standard dei dati di studio.\n",
                "# 2. 'transform' applica la formula per centrare i dati intorno allo zero.\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "\n",
                "# SOLO TRANSFORM sul Test Set:\n",
                "# Usiamo la media e la scala che abbiamo imparato dal Training Set.\n",
                "# NON dobbiamo fare 'fit' qui, perché altrimenti useremmo informazioni dal futuro (Data Leakage). \n",
                "# Dobbiamo trattare i dati di test come se fossero pezzi nuovi che entrano in fabbrica oggi.\n",
                "X_test_scaled = scaler.transform(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9bb034d5",
            "metadata": {},
            "source": [
                "**Commento:** Lo StandardScaler porta ogni feature ad avere media ≈ 0 e deviazione standard ≈ 1. Questo è fondamentale per la Logistic Regression (che usa la distanza tra i coefficienti), mentre i modelli ad albero (Decision Tree e Random Forest) non ne hanno bisogno — per questi ultimi useremo i dati non scalati."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "909af0e9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verifichiamo visivamente il cambiamento delle variabili\n",
                "# Guardiamo solo le prime 5 righe e le prime 5 colonne (per non intasare lo schermo)\n",
                "\n",
                "print(\"I DATI ORIGINALI\")\n",
                "# Vedremo variabili con unità di misura diverse: millimetri, ID, temperature, ecc.\n",
                "print(pd.DataFrame(X_train).iloc[:5, :5].to_string())\n",
                "\n",
                "print(\"\\nI DATI SCALATI (Normalizzati)\")\n",
                "# Vedremo che tutti i numeri ora sono vicini allo zero (es. -0.5, 1.2, 0.03).\n",
                "# Questa è la \"lingua\" preferita da molti algoritmi matematici per lavorare correttamente.\n",
                "print(pd.DataFrame(X_train_scaled, columns=X_train.columns).iloc[:5, :5].to_string())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fbc644dd",
            "metadata": {},
            "source": [
                "Cosa è cambiato?\n",
                "\n",
                "* Prima (Dati Originali): I numeri avevano scale completamente diverse. La line_id va da 1 a 9, ma la measure_length_mm arriva a oltre 65. Il computer potrebbe erroneamente pensare che la lunghezza sia più importante solo perché il numero è fisicamente più grande.\n",
                "* Dopo (Dati Scalati): Tutti i sensori ora parlano la stessa lingua. I valori sono stati \"centrati\": lo 0 rappresenta la media esatta di quella colonna. Se vedi un numero positivo (es. 1.36), significa che quel pezzo è sopra la media; se è negativo (es. -1.25), è sotto la media.\n",
                "\n",
                "Perché lo facciamo? Per mettere tutti i sensori sullo stesso piano. In questo modo il modello di Machine Learning darà la giusta importanza a ogni segnale, senza farsi ingannare dalle unità di misura."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6cf546d2",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Addestramento dei Modelli\n",
                "\n",
                "Addestriamo tre modelli di classificazione come richiesto dalla traccia:\n",
                "\n",
                "| Modello | Caratteristiche |\n",
                "|---------|----------------|\n",
                "| **Logistic Regression** | Modello lineare, veloce, buona baseline ma limitato su relazioni non lineari |\n",
                "| **Decision Tree** | Non lineare, interpretabile, rischia di fare overfitting |\n",
                "| **Random Forest** | Ensemble di alberi, più robusto e generalmente più accurato |"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bd26e7f3",
            "metadata": {},
            "source": [
                "### 5.1 Logistic Regression\n",
                "\n",
                "Nota importante:\n",
                "La Logistic Regression è molto sensibile alle scale, per questo qui usiamo obbligatoriamente X_train_scaled e X_test_scaled. Se usassimo i dati originali, il modello farebbe molta fatica a convergere verso una soluzione corretta."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "436852f6",
            "metadata": {},
            "outputs": [],
            "source": [
                "# MODELLO 1: LOGISTIC REGRESSION\n",
                "# È l'algoritmo più semplice: traccia una linea (un confine) per dividere i pezzi buoni dai difettosi.\n",
                "# Usiamo random_state=42 per avere risultati ripetibili.\n",
                "log_reg = LogisticRegression(random_state=42)\n",
                "\n",
                "# ADDESTRAMENTO: Diamo al modello i dati scalati e le risposte (defect_label) affinché impari i pattern.\n",
                "log_reg.fit(X_train_scaled, y_train)\n",
                "\n",
                "# PREDIZIONE: Chiediamo al modello di indovinare se i pezzi del Test Set (che non ha mai visto) sono difettosi.\n",
                "y_pred_log = log_reg.predict(X_test_scaled)\n",
                "\n",
                "# VALUTAZIONE: Calcoliamo l'accuratezza, ovvero la percentuale di risposte corrette sul totale.\n",
                "# .4f serve a mostrare solo 4 cifre decimali (es. 0.8542).\n",
                "print(f\"Accuracy Logistic Regression: {accuracy_score(y_test, y_pred_log):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0543f1e6",
            "metadata": {},
            "source": [
                "**Commento:** La Logistic Regression ottiene un'accuratezza intorno al 75%. Tuttavia, come vedremo nel dettaglio nella sezione di valutazione, un'accuratezza elevata può essere ingannevole in presenza di classi sbilanciate: il modello potrebbe semplicemente predire quasi sempre la classe maggioritaria."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "de0038ba",
            "metadata": {},
            "source": [
                "### 5.2 Decision Tree\n",
                "\n",
                "Mentre la Logistic Regression fa dei calcoli matematici complessi dove il \"peso\" delle variabili conta molto, l'Albero di Decisione fa dei semplici tagli (es: \"tutto quello che è sopra 100 gradi va a destra\"). Se scali i dati e 100 gradi diventano 0.5, lui farà il taglio a 0.5. Il risultato logico è lo stesso, quindi per comodità e leggibilità si usano spesso i dati originali."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ee9681cc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# MODELLO 2: DECISION TREE (Albero di Decisione)\n",
                "# Questo modello funziona come un diagramma di flusso: fa una serie di domande (es. \"Il diametro è > 20?\")\n",
                "# fino a giungere a una conclusione. Per questo motivo, i numeri grandi o piccoli non lo confondono.\n",
                "tree_clf = DecisionTreeClassifier(random_state=42)\n",
                "\n",
                "# ADDESTRAMENTO: Usiamo i dati ORIGINALI (X_train). \n",
                "# Gli alberi sono \"robusti\" e non hanno bisogno dello scaling per funzionare bene.\n",
                "tree_clf.fit(X_train, y_train)\n",
                "\n",
                "# PREDIZIONE: Il modello prova a classificare i pezzi del Test Set.\n",
                "y_pred_tree = tree_clf.predict(X_test)\n",
                "\n",
                "# VALUTAZIONE: Vediamo quanti pezzi ha indovinato l'albero.\n",
                "print(f\"Accuracy Decision Tree: {accuracy_score(y_test, y_pred_tree):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "42757f1a",
            "metadata": {},
            "source": [
                "**Commento:** Il Decision Tree scende intorno al 64%. Un singolo albero tende a fare overfitting sui dati di training e fatica a generalizzare, specialmente con molte feature e alta cardinalità come `material_batch`."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "725fd922",
            "metadata": {},
            "source": [
                "### 5.3 Random Forest\n",
                "\n",
                "Se il Decision Tree è un singolo esperto che decide, la Random Forest è un comitato di 100 esperti. Di solito, il comitato è molto più affidabile dell'esperto singolo perché è meno influenzato da piccoli dettagli o errori nei dati."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7f85be8d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# MODELLO 3: RANDOM FOREST\n",
                "# Invece di un solo albero, qui ne creiamo 100 (n_estimators=100) che lavorano insieme.\n",
                "# Ogni albero dà il suo \"voto\" e la maggioranza decide il risultato finale. \n",
                "# È molto più potente e stabile perché gli errori dei singoli alberi si annullano a vicenda.\n",
                "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "\n",
                "# ADDESTRAMENTO: Come per l'albero singolo, usiamo i dati ORIGINALI (X_train).\n",
                "rf_clf.fit(X_train, y_train)\n",
                "\n",
                "# PREDIZIONE: La \"foresta\" analizza i pezzi del Test Set.\n",
                "y_pred_rf = rf_clf.predict(X_test)\n",
                "\n",
                "# VALUTAZIONE: Calcoliamo l'accuratezza finale.\n",
                "print(f\"Accuracy Random Forest: {accuracy_score(y_test, y_pred_rf):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e10fecfa",
            "metadata": {},
            "source": [
                "**Commento:** Il Random Forest risale sopra il 78%, confermandosi il modello più robusto. L'aggregazione di 100 alberi riduce la varianza e corregge gli errori dei singoli alberi, portando a previsioni più stabili."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "370320a7",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Gestione dello Sbilanciamento delle Classi\n",
                "\n",
                "Fino ad ora, i nostri modelli hanno cercato di indovinare il maggior numero possibile di pezzi corretti (Accuracy). Sembra logico, ma c'è un trucco: dato che i pezzi difettosi sono pochi (es. il 20%), al modello \"conviene\" dire che tutti i pezzi sono buoni per avere comunque un'accuratezza dell'80%.\n",
                "\n",
                "Il problema è che per l'azienda scovare quel 20% di difetti è vitale, mentre il modello attuale li sta ignorando perché sono \"mosche bianche\" rispetto alla massa.\n",
                "\n",
                "Cos'è il **class_weight='balanced'**?\n",
                "\n",
                "Immagina un insegnante che corregge un compito: di solito ogni errore vale 1 punto in meno. Con class_weight='balanced', diciamo al modello:\n",
                "\n",
                "\"Se sbagli a classificare un pezzo buono, perdi 1 punto. Ma se ti sfugge un pezzo difettoso, la penale è di 5 punti!\"\n",
                "\n",
                "Questo \"trucco\" costringe l'algoritmo a studiare molto meglio i casi rari (i difetti), accettando magari di sbagliare qualche pezzo buono (falsi allarmi) pur di non farsi scappare quelli realmente pericolosi.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "65b16d45",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Riaddestriamo i modelli con una \"penale\" più alta per chi ignora i difetti.\n",
                "# Il computer calcolerà automaticamente un peso maggiore per la classe minoritaria.\n",
                "\n",
                "# 1. Logistic Regression Bilanciata (usa i dati scalati)\n",
                "log_reg_bal = LogisticRegression(class_weight='balanced', random_state=42)\n",
                "log_reg_bal.fit(X_train_scaled, y_train)\n",
                "\n",
                "# 2. Decision Tree Bilanciato (usa i dati originali)\n",
                "tree_clf_bal = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
                "tree_clf_bal.fit(X_train, y_train)\n",
                "\n",
                "# 3. Random Forest Bilanciato (usa i dati originali)\n",
                "rf_clf_bal = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
                "rf_clf_bal.fit(X_train, y_train)\n",
                "\n",
                "# Generazione delle previsioni per i modelli bilanciati\n",
                "# Nota: La Logistic Regression usa sempre i dati SCALATI (X_test_scaled)\n",
                "y_pred_log_bal = log_reg_bal.predict(X_test_scaled)\n",
                "\n",
                "# Gli alberi usano i dati originali (X_test)\n",
                "y_pred_tree_bal = tree_clf_bal.predict(X_test)\n",
                "y_pred_rf_bal = rf_clf_bal.predict(X_test)\n",
                "\n",
                "print(\"Modelli riaddestrati con bilanciamento delle classi — ora sono più 'attenti' ai difetti.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cc978249",
            "metadata": {},
            "source": [
                "**Commento:** Ora abbiamo 6 set di predizioni in totale (3 modelli base + 3 bilanciati). Nella prossima sezione confronteremo le performance in modo sistematico per capire quale configurazione sia preferibile nel contesto produttivo di AutomaParts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f5c884f5",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
                "\n",
                "print(\"=== Risultati con Class Balancing ===\\n\")\n",
                "\n",
                "# Creiamo un ciclo per confrontare i tre modelli bilanciati uno dopo l'altro\n",
                "for name, y_pred in [(\"Logistic Regression (bal.)\", y_pred_log_bal),\n",
                "                      (\"Decision Tree (bal.)\",      y_pred_tree_bal),\n",
                "                      (\"Random Forest (bal.)\",      y_pred_rf_bal)]:\n",
                "    print(f\"{name}:\")\n",
                "    \n",
                "    # Accuracy: Quanti pezzi in totale ha indovinato (buoni + difettosi)\n",
                "    print(f\"  Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
                "    \n",
                "    # Precision: Quando il modello dice \"Difettoso\", quanto spesso ci azzecca? (Evita i falsi allarmi)\n",
                "    print(f\"  Precision: {precision_score(y_test, y_pred):.4f}\")\n",
                "    \n",
                "    # Recall: Quanti dei pezzi realmente difettosi è riuscito a scovare? (La metrica più importante per noi!)\n",
                "    print(f\"  Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
                "    \n",
                "    # F1-score: Una media tra Precision e Recall. Serve a capire il bilanciamento generale del modello.\n",
                "    print(f\"  F1-score:  {f1_score(y_test, y_pred):.4f}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "89e89498",
            "metadata": {},
            "source": [
                "Questi risultati sono molto interessanti perché mostrano chiaramente il \"carattere\" di ogni algoritmo dopo il bilanciamento. \n",
                "\n",
                "* Logistic Regression (Il \"Radar Sensibile\"): È il modello più coraggioso. Con una Recall dello 0.50, riesce a scovare la metà dei pezzi difettosi (un grande salto rispetto allo zero di prima!). Il prezzo da pagare è la precisione bassa: fa molti falsi allarmi, ma per l'accuratezza potrebbe essere il migliore.\n",
                "* Decision Tree (Il \"Pragmatico\"): Rappresenta il compromesso migliore del lotto, come confermato dal F1-score più alto (0.35). Non è eccellente in nulla, ma mantiene un equilibrio onesto tra il trovare i difetti e il non sbagliare troppo sui pezzi buoni.\n",
                "* Random Forest (Il \"Conservatore\"): Nonostante sia il più potente, qui è molto timido. Ha una Precisione altissima (0.85): quando dice che un pezzo è difettoso, ci azzecca quasi sempre. Tuttavia, ha una Recall bassissima (0.11), il che significa che si lascia sfuggire l'89% dei difetti. È un modello che \"parla solo quando è sicurissimo\".\n",
                "\n",
                "In sintesi: Se l'obiettivo aziendale è non far uscire nessun difetto dalla fabbrica, la Logistic Regression è la base migliore su cui lavorare, accettando però di dover ricontrollare manualmente molti pezzi segnalati per errore. Se vogliamo un sistema automatico senza troppe pretese, il Decision Tree è la scelta più equilibrata.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "be845065",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Valutazione e Confronto\n",
                "\n",
                "Confrontiamo tutti i modelli con metriche dettagliate, prestando particolare attenzione a **Recall** e **Precision** sulla classe 1 (difetti), che sono le metriche più rilevanti dal punto di vista operativo:\n",
                "\n",
                "- **Recall (classe 1)**: capacità di intercettare i pezzi difettosi → un valore basso significa molti **falsi negativi** (difetti che sfuggono al cliente!)\n",
                "- **Precision (classe 1)**: accuratezza delle previsioni di difetto → un valore basso significa molti **falsi positivi** (pezzi buoni scartati inutilmente)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fa1feee5",
            "metadata": {},
            "source": [
                "### 7.1 Classification Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "55e9b50c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Report completo per i modelli BASE \n",
                "# Aggiungo questo: zero_division=0 per evitare errori di divisione per zero\n",
                "print(\"===== MODELLI BASE =====\")\n",
                "print(\"\\n--- Logistic Regression ---\")\n",
                "print(classification_report(y_test, y_pred_log, zero_division=0))\n",
                "\n",
                "print(\"--- Decision Tree ---\")\n",
                "print(classification_report(y_test, y_pred_tree, zero_division=0))\n",
                "\n",
                "print(\"--- Random Forest ---\")\n",
                "print(classification_report(y_test, y_pred_rf, zero_division=0))\n",
                "\n",
                "# Report completo per i modelli BILANCIATI\n",
                "print(\"\\n===== MODELLI CON CLASS BALANCING =====\")\n",
                "print(\"\\n--- Logistic Regression (Balanced) ---\")\n",
                "print(classification_report(y_test, y_pred_log_bal, zero_division=0))\n",
                "\n",
                "print(\"--- Decision Tree (Balanced) ---\")\n",
                "print(classification_report(y_test, y_pred_tree_bal, zero_division=0))\n",
                "\n",
                "print(\"--- Random Forest (Balanced) ---\")\n",
                "print(classification_report(y_test, y_pred_rf_bal, zero_division=0))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d2a92a00",
            "metadata": {},
            "source": [
                "**Analisi dei Report di Classificazione: Cosa è cambiato?**\n",
                "\n",
                "Il confronto tra i modelli \"Base\" e quelli \"Bilanciati\" ci svela la verità sulla salute del nostro sistema di controllo qualità.\n",
                "\n",
                "**L'illusione dei Modelli Base (Il Caso Logistic Regression)**\n",
                "Guardiamo la Logistic Regression Base: segna un'Accuracy del 76%. Sembrerebbe brava, ma Invece è inutile. Se guardiamo la riga della Classe 1 (difetti), ha Recall 0.00. Significa che il modello ha deciso di \"fare il pigro\": classifica tutto come buono (Classe 0) e così ottiene un voto alto, ma non trova nemmeno un pezzo difettoso. In fabbrica, un sensore così sarebbe come avere un addetto che dorme tutto il giorno.\n",
                "\n",
                "**Il \"Risveglio\" con il Class Balancing**\n",
                "Appena abbiamo attivato class_weight='balanced', i modelli hanno \"aperto gli occhi\" sui difetti:\n",
                "\n",
                "* Logistic Regression (Balanced): È il cambiamento più drastico. La Recall per i difetti è passata da 0 a 0.51. Il modello ora scova il 51% dei pezzi difettosi. È diventato molto più aggressivo, anche se ora la sua Accuracy totale è scesa al 54%. Per la sicurezza, però, è molto più utile di prima.\n",
                "* Decision Tree (Balanced): È il vincitore in termini di equilibrio. Ha migliorato sia la precisione che la recall rispetto alla versione base, portando l'F1-score a 0.35. È il modello più coerente: non è \"pigro\" come la prima Logistic Regression, ma neanche \"ansioso\" come la seconda.\n",
                "* Random Forest (Balanced): Sorprendentemente, il bilanciamento non l'ha scosso molto. Resta un modello estremamente prudente: ha una Precisione dell'85% (se dice che è rotto, quasi certamente lo è), ma una Recall del 12% (se ne lascia scappare l'88%). È un \"chirurgo\" che opera solo quando è sicuro al 100%.\n",
                "\n",
                "**Conclusione Operativa**\n",
                "\n",
                "Se vogliamo la massima sicurezza: Usiamo la Logistic Regression (Balanced). Avremo qualche falso allarme, ma fermeremo metà dei pezzi difettosi che prima passavano indisturbati.\n",
                "Se vogliamo un sistema automatico equilibrato: Il Decision Tree (Balanced) offre la miglior via di mezzo tra pezzi scartati per errore e difetti intercettati.\n",
                "Se il costo dello scarto è altissimo: La Random Forest è l'unica che garantisce di non scartare quasi mai pezzi buoni per errore, ma purtroppo \"vede\" pochissimi difetti.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4d879970",
            "metadata": {},
            "source": [
                "### 7.2 Confusion Matrices\n",
                "\n",
                "Le matrici di confusione ci mostrano in modo visuale la distribuzione di:\n",
                "- **Veri Positivi (VP)**: difetti correttamente intercettati\n",
                "- **Falsi Negativi (FN)**: difetti sfuggiti (pericolosi!)\n",
                "- **Falsi Positivi (FP)**: pezzi buoni scartati inutilmente\n",
                "- **Veri Negativi (VN)**: pezzi buoni correttamente classificati"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "14c21549",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creiamo una griglia di grafici (2 righe e 3 colonne) per confrontare tutto in una sola schermata\n",
                "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
                "\n",
                "# --- PRIMA RIGA: I MODELLI \"PIGRI\" (Modelli Base) ---\n",
                "modelli_base = [\n",
                "    ('Logistic Regression', y_pred_log, 'Reds'),   # Rosso per l'algoritmo semplice\n",
                "    ('Decision Tree', y_pred_tree, 'Greens'),      # Verde per l'albero singolo\n",
                "    ('Random Forest', y_pred_rf, 'Blues'),         # Blu per la foresta\n",
                "]\n",
                "\n",
                "for i, (nome, y_pred, cmap) in enumerate(modelli_base):\n",
                "    # Calcoliamo la matrice: incrociamo i dati reali con quello che il modello ha indovinato\n",
                "    cm = confusion_matrix(y_test, y_pred)\n",
                "    # Disegniamo la \"mappa di calore\" con i numeri dentro (annot=True)\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, ax=axes[0, i])\n",
                "    axes[0, i].set_title(nome)\n",
                "    axes[0, i].set_xlabel('Cosa ha detto il PC')\n",
                "    axes[0, i].set_ylabel('Cosa è successo davvero')\n",
                "\n",
                "# --- SECONDA RIGA: I MODELLI \"ATTENTI\" (Modelli Bilanciati) ---\n",
                "modelli_bal = [\n",
                "    ('LR (Balanced)', y_pred_log_bal, 'Oranges'), # Arancione per la riedizione bilanciata\n",
                "    ('DT (Balanced)', y_pred_tree_bal, 'YlGn'),    # Giallo-Verde per l'albero bilanciato\n",
                "    ('RF (Balanced)', y_pred_rf_bal, 'PuBu'),      # Viola-Blu per la foresta bilanciata\n",
                "]\n",
                "\n",
                "for i, (nome, y_pred, cmap) in enumerate(modelli_bal):\n",
                "    cm = confusion_matrix(y_test, y_pred)\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, ax=axes[1, i])\n",
                "    axes[1, i].set_title(nome)\n",
                "    axes[1, i].set_xlabel('Cosa ha detto il PC')\n",
                "    axes[1, i].set_ylabel('Cosa è successo davvero')\n",
                "\n",
                "# Aggiungiamo un titolo generale e sistemiamo gli spazi per non sovrapporre i testi\n",
                "plt.suptitle('Confronto Errori: Modelli Base (Sopra) vs Bilanciati (Sotto)', fontsize=16)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "00c23bf6",
            "metadata": {},
            "source": [
                "**Commento ai grafici:**\n",
                "\n",
                "Confrontando la riga superiore (modelli base) con quella inferiore (bilanciati) si nota chiaramente l'effetto del class balancing:\n",
                "\n",
                "- Nei **modelli base**, l'angolo in basso a destra (Veri Positivi — difetti intercettati) è molto piccolo, specialmente per la Logistic Regression che non ne cattura quasi nessuno.\n",
                "- Nei **modelli bilanciati**, il riquadro dei VP cresce sensibilmente, a dimostrazione che il bilanciamento permette ai modelli di intercettare molti più pezzi difettosi.\n",
                "- Il trade-off è visibile nell'aumento dei Falsi Positivi (angolo in alto a destra), ma in un contesto produttivo è un compromesso accettabile: un falso allarme costa meno di un pezzo difettoso consegnato al cliente."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "37899542",
            "metadata": {},
            "source": [
                "### 7.3 Cross-Validation (5-fold - Ci salva dai risultati \"fortunati\")\n",
                "\n",
                "Finora abbiamo diviso il dataset in due parti (Training e Test). È come se avessimo dato allo studente un solo libro da studiare e fatto un solo esame finale. Ma se quell'unico esame contenesse per caso solo le domande facili? Avremmo un'idea sbagliata della bravura dello studente.\n",
                "\n",
                "La Cross-Validation (5-fold) risolve questo problema:\n",
                "\n",
                "* Dividiamo tutto il dataset in 5 pezzi (chiamati fold).\n",
                "* Facciamo 5 esami diversi: ogni volta usiamo 4 pezzi per far studiare il modello e il 5° pezzo per interrogarlo.\n",
                "* Alla fine facciamo la media dei 5 voti.\n",
                "\n",
                "Perché è utile?\n",
                "\n",
                "* Stabilità: Se il modello prende 80% in tutti e 5 gli esami, è robusto. Se in uno prende 95% e in un altro 40%, significa che è instabile e dipende troppo dalla fortuna.\n",
                "* Affidabilità: La media finale ci dà il vero valore del modello, senza l'influenza di split casuali troppo facili o troppo difficili."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9ab12425",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creiamo un \"mini-laboratorio\" con i tre modelli standard\n",
                "modelli_cv = {\n",
                "    'Logistic Regression': LogisticRegression(random_state=42),\n",
                "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
                "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
                "}\n",
                "\n",
                "print(\"Cross-Validation (5-fold) — Accuratezza:\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "# Cicliamo su ogni modello per sottoporlo ai 5 test\n",
                "for nome, modello in modelli_cv.items():\n",
                "    \n",
                "    # CONTROLLO SCALA: Se il modello è la Logistic Regression, dobbiamo scalare i dati.\n",
                "    # Per gli alberi (Decision Tree e Random Forest) passiamo i dati originali X.\n",
                "    if 'Logistic' in nome:\n",
                "        # Prepariamo i dati scalati al momento per tutto il dataset\n",
                "        scores = cross_val_score(modello, scaler.fit_transform(X), y, cv=5)\n",
                "    else:\n",
                "        # Eseguiamo i 5 test rimescolando i dati originali\n",
                "        scores = cross_val_score(modello, X, y, cv=5)\n",
                "    \n",
                "    # Media: Rappresenta il voto medio ottenuto nei 5 esami (la performance reale attesa)\n",
                "    # Std: Rappresenta quanto i voti oscillano tra un esame e l'altro (più è piccola, più il modello è affidabile)\n",
                "    print(f\"{nome:25s} | Media: {scores.mean():.4f}  |  Std: {scores.std():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b80b46d8",
            "metadata": {},
            "source": [
                "Cosa impariamo da questi 5 test?\n",
                "\n",
                "* Random Forest (Il Campione di precisione): Con una media del 79.37%, si conferma il modello più bravo a indovinare il risultato complessivo. È anche molto affidabile (Std molto bassa), quindi i suoi risultati non sono dovuti a un colpo di fortuna.\n",
                "* Logistic Regression (La più costante): Ha una media del 77.63%, ma guarda la Std: 0.0007. È quasi invisibile! Significa che questo modello è come un orologio svizzero: dà quasi lo stesso identico risultato indipendentemente da come rimescoli i dati. È il modello più prevedibile e solido.\n",
                "* Decision Tree (Il più instabile): Ha la media più bassa (67.87%) e l'oscillazione dei voti più alta (Std: 0.0090). Questo conferma che gli alberi singoli tendono a essere un po' più influenzati da come sono distribuiti i dati rispetto alle \"foreste\" o ai modelli lineari.\n",
                "\n",
                "Attenzione però! Questi voti sono basati sull'Accuratezza. Ricordiamoci che la Logistic Regression ha un voto alto solo perché ignora i difetti. In questa fase la Random Forest sembra la migliore, ma dobbiamo sempre guardare se sta davvero trovando i pezzi rotti o se è solo \"brava a dire che è tutto a posto\"."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5150c852",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ora facciamo l'esame più difficile: quanti difetti (classe 1) riescono a trovare davvero?\n",
                "print(\"\\nCross-Validation (5-fold) — Capacità di trovare i difetti (Recall):\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "# Confrontiamo i tre modelli nella loro versione \"Bilanciata\"\n",
                "for name, model, X_cv in [(\"Logistic Regression\", log_reg_bal, X_train_scaled),\n",
                "                           (\"Decision Tree\",       tree_clf_bal, X_train),\n",
                "                           (\"Random Forest\",       rf_clf_bal,   X_train)]:\n",
                "    \n",
                "    # scoring='recall' dice al computer: \"Non mi interessa quanti pezzi indovini in totale, dimmi solo che percentuale di difetti riesci a scovare!\"\n",
                "    scores = cross_val_score(model, X_cv, y_train, cv=5, scoring='recall')\n",
                "    \n",
                "    # Media: Quanti difetti troviamo mediamente (più è alta, meglio è per la sicurezza)\n",
                "    # Std: Quanto è costante il modello nello scovare i difetti tra un test e l'altro\n",
                "    print(f\"{name:25s} | Media: {scores.mean():.4f}  |  Std: {scores.std():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "85376fd3",
            "metadata": {},
            "source": [
                "Questo test è lo scoglio più duro per i nostri modelli perché misura solo una cosa: quanti pezzi difettosi riusciamo a intercettare su 100 che ne passano.\n",
                "\n",
                "* Logistic Regression (Il Guardiano Attento): Si conferma il modello più affidabile per la sicurezza. Con una Media di circa 0.50, ci dice che riesce a fermare stabilmente la metà dei pezzi difettosi. È il \"voto\" più alto tra i tre, rendendolo l'alleato migliore per evitare che scarti arrivino al cliente.\n",
                "* Decision Tree (La Via di Mezzo): Mostra una capacità di rilevamento intermedia (intorno a 0.38). È meno efficace della Logistic Regression ma più costante della Random Forest. È una scelta discreta se si vuole un sistema che non faccia troppi falsi positivi pur mantenendo una discreta attenzione.\n",
                "* Random Forest (Il Guardiano Distratto): Nonostante sia il modello più \"intelligente\" tecnicamente, qui fallisce l'obiettivo principale. Una Media intorno a 0.13 significa che lascia passare quasi il 90% dei pezzi difettosi. In un contesto di produzione automotive, questo modello sarebbe bocciato perché troppo rischioso.\n",
                "\n",
                "Verdetto Finale: Se dovessimo installare uno di questi modelli in fabbrica domani mattina, la Logistic Regression Bilanciata sarebbe la scelta obbligata per proteggere la qualità del marchio."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2e515231",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ultimo test: cerchiamo il modello più EQUILIBRATO (F1-score)\n",
                "print(\"\\nCross-Validation (5-fold) — Equilibrio Totale (F1-score):\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "for name, model, X_cv in [(\"Logistic Regression\", log_reg_bal, X_train_scaled),\n",
                "                           (\"Decision Tree\",       tree_clf_bal, X_train),\n",
                "                           (\"Random Forest\",       rf_clf_bal,   X_train)]:\n",
                "    \n",
                "    # scoring='f1' calcola la media armonica tra Precision e Recall.\n",
                "    # È il voto più onesto perché punisce i modelli troppo estremi (es: quelli che dicono sempre \"difetto\").\n",
                "    scores = cross_val_score(model, X_cv, y_train, cv=5, scoring='f1')\n",
                "    \n",
                "    # Media: Un valore di 1.0 sarebbe il modello perfetto, 0.0 un disastro totale.\n",
                "    print(f\"{name:25s} | Media: {scores.mean():.4f}  |  Std: {scores.std():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5d3c66d9",
            "metadata": {},
            "source": [
                "L'F1-Score è come il voto di un esame completo che mette insieme tutto: capacità di trovare i difetti e capacità di non fare troppi falsi allarmi.\n",
                "\n",
                "* Logistic Regression (La Vincitrice: 0.3245): Nonostante sia il modello più semplice, è quello che offre il miglior rendimento complessivo. Vince la sfida perché, anche se genera qualche falso allarme, è l'unica che scova abbastanza difetti da rendere il sistema utile. È anche piuttosto stabile (Std bassa), quindi non va a fortuna.\n",
                "* Decision Tree (Il Seguitore: 0.2635): Si posiziona al secondo posto. È meno efficace della Logistic Regression, ma decisamente più utile della Random Forest. Potrebbe essere un'alternativa se si volesse un modello basato su regole \"logiche\" più facili da spiegare (es: \"Se la febbre è > 38 allora...\").\n",
                "* Random Forest (La Sconfitta: 0.0784): Qui vediamo un \"crollo\". Una media così bassa, unita a una oscillazione altissima (Std: 0.05), ci dice che questo modello è del tutto inadatto a questo specifico problema. Si concentra così tanto nel non scartare pezzi buoni che finisce per ignorare quasi totalmente i difetti.\n",
                "\n",
                "Conclusione: Per questo progetto di AutomaParts S.p.A., la Logistic Regression Bilanciata non è solo la più sicura (Recall), ma è anche la più efficiente (F1-score). È il modello che installeremmo se volessimo massimizzare il risparmio aziendale."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "99a6f92a",
            "metadata": {},
            "source": [
                "### 7.4 Feature Importance (Random Forest)\n",
                "\n",
                "Una domanda che ogni responsabile di fabbrica si pone è: \"Perché stiamo producendo scarti? Sono le vibrazioni? È la temperatura? O forse è la rincorsa dei ritmi di produzione?\"\n",
                "\n",
                "Per rispondere non ci basta un modello che indovini i difetti, ci serve un modello che sappia spiegare perché li ha scelti.\n",
                "\n",
                "Perché usiamo la Random Forest per questa analisi?\n",
                "\n",
                "* Interpretazione Cristallina: A differenza di altri modelli definibili come \"black box\" (scatole nere), la Random Forest tiene traccia di quante volte ogni sensore è stato decisivo per individuare un pezzo buono o cattivo.\n",
                "* Democrazia degli Alberi: Dato che abbiamo 100 alberi diversi, ognuno analizza i dati da un punto di vista differente. Se tutti e 100 concordano che, ad esempio, le vibrazioni sono il fattore principale, allora abbiamo trovato il vero colpevole.\n",
                "* Guida agli Interventi: Questa analisi non serve solo a fare grafici, ma a dare ordini precisi alla manutenzione. Se scopriamo che il cycle_time_s (tempo ciclo) è la variabile più importante, forse stiamo spingendo le macchine troppo velocemente e dobbiamo rallentare per garantire la qualità.\n",
                "\n",
                "In sintesi: la Feature Importance trasforma il nostro modello da semplice \"sensore\" a vero consulente di processo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a61a0c91",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ANALISI DELLE CAUSE (Feature Importance)\n",
                "\n",
                "# Chiediamo alla Random Forest: \"Quanto è stata utile ogni colonna per trovare i difetti?\"\n",
                "# Il risultato è un elenco di numeri (pesi) che sommati fanno 1.0 (o 100%)\n",
                "importances = rf_clf.feature_importances_\n",
                "\n",
                "# Ordiniamo gli indici delle colonne dal più importante al meno importante\n",
                "# np.argsort restituisce l'ordine, [::-1] lo inverte per avere il \"campione\" in cima\n",
                "indices = np.argsort(importances)[::-1]\n",
                "\n",
                "# Creiamo il grafico per visualizzare la classifica dei fattori critici\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.title('Quali fattori influenzano di più la qualità? (Feature Importance)')\n",
                "\n",
                "# Creiamo le barre: l'altezza indica quanto quella variabile è stata decisiva\n",
                "plt.bar(range(X.shape[1]), importances[indices], align='center', color='skyblue')\n",
                "\n",
                "# Etichettiamo l'asse X con i nomi delle colonne, ruotandoli di 90 gradi per leggerli bene\n",
                "plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\n",
                "\n",
                "plt.ylabel('Peso nel processo decisionale')\n",
                "plt.tight_layout() # Evita che le etichette lunghe vengano tagliate\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "17e6d8c0",
            "metadata": {},
            "source": [
                "Il grafico mostra che le feature importance del Random Forest sono distribuite in modo abbastanza uniforme tra le variabili di processo e dimensionali — nessuna singola feature domina chiaramente la predizione. \n",
                "\n",
                "Le più rilevanti sono cycle_time_s e vibration_level (~0.09), seguite dal gruppo di misure fisiche (surface_roughness_Ra, torque_Nm, flatness_mm, measure_length_mm) tutte attorno a 0.07. Le variabili identificative (station_id, hour, line_id) contribuiscono meno, come atteso: il difetto è più legato ai parametri di processo che alla specifica linea o stazione. Infine, le due colonne di feature engineering (diam_dev_from_batch e temp_dev_from_batch) hanno importanza prossima allo zero, confermando quanto osservato in precedenza: con ~2997 batch unici su 3000 righe, le deviazioni dalla media del lotto non aggiungono informazione. \n",
                "\n",
                "La distribuzione piatta delle importance spiega anche le difficoltà dei modelli: non c'è una \"feature chiave\" che separi nettamente i pezzi difettosi da quelli conformi."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "15306962",
            "metadata": {},
            "source": [
                "### 7.5 Curva ROC e AUC (Random Forest)\n",
                "\n",
                "La **curva ROC** mostra il trade-off tra True Positive Rate (recall) e False Positive Rate al variare della soglia di decisione. L'**AUC** (Area Under the Curve) riassume la capacità discriminativa del modello in un singolo numero: 0.5 = classificatore casuale, 1.0 = classificatore perfetto."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "329791a8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- ANALISI DEL POTENZIALE (Curva ROC e AUC) ---\n",
                "\n",
                "# Invece di farci dire solo 0 o 1, chiediamo al modello la PROBABILITÀ (es: \"Sono sicuro al 70% che sia rotto\")\n",
                "# Prendiamo solo la colonna [:, 1] che indica la probabilità di essere un difetto\n",
                "y_prob = rf_clf.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# Calcoliamo i due tipi di errore al variare della soglia:\n",
                "# - TPR: Quanti difetti troviamo (vogliamo che sia alto)\n",
                "# - FPR: Quanti falsi allarmi facciamo (vogliamo che sia basso)\n",
                "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
                "\n",
                "# Calcoliamo l'area sotto la curva (AUC). Più è vicina a 1, più il modello è un \"veggente\".\n",
                "roc_auc = auc(fpr, tpr)\n",
                "\n",
                "# Disegniamo il grafico\n",
                "plt.figure(figsize=(8, 6))\n",
                "\n",
                "# La curva del nostro modello (più \"pancia\" fa verso l'alto a sinistra, meglio è)\n",
                "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Modello Random Forest (AUC = {roc_auc:.2f})')\n",
                "\n",
                "# La linea tratteggiata rappresenta il \"caso\": come se tirassimo una moneta (AUC = 0.50)\n",
                "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Caso Fortuito (AUC = 0.50)')\n",
                "\n",
                "plt.xlabel('Falsi Allarmi (Pezzi buoni scartati per errore)')\n",
                "plt.ylabel('Difetti Trovati (Pezzi rotti intercettati)')\n",
                "plt.title('Capacità del Modello di Distinguere i Pezzi (ROC Curve)')\n",
                "plt.legend(loc='lower right')\n",
                "plt.grid(alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f0091062",
            "metadata": {},
            "source": [
                "**Dati di riferimento:**\n",
                "* 1.0: Modello perfetto (impossibile nella realtà).\n",
                "* 0.80 - 0.90: Modello eccellente.\n",
                "* 0.70 - 0.80: Modello buono/discreto.\n",
                "* 0.50 - 0.60: Modello scarso (indovina quasi come se tirasse a indovinare).\n",
                "* 0.50: Inutile (tirare una moneta è la stessa cosa).\n",
                "\n",
                "**Commento:**\n",
                "\n",
                "Questo grafico è la \"prova del nove\" e ci dice che il problema è più difficile del previsto:\n",
                "\n",
                "* Quasi una moneta: Un punteggio di 0.50 significa tirare a indovinare (linea tratteggiata). Il nostro 0.57 è solo leggermente migliore. Significa che il modello fa molta fatica a distinguere i pezzi buoni dai difettosi basandosi solo sui sensori attuali.\n",
                "* Segnale debole: La curva arancione non \"spancia\" verso l'alto, ma segue quasi la diagonale. Questo conferma che nel dataset non c'è una \"variabile magica\" che indica chiaramente il difetto; i difetti sono probabilmente causati da combinazioni molto complesse o da fattori che i sensori non hanno catturato (es. micro-crepe invisibili o errori umani).\n",
                "* Valutazione per l'azienda: Un modello con 0.57 non può essere usato da solo per decidere cosa scartare in automatico, perché farebbe troppi errori. Tuttavia, è un ottimo punto di partenza per capire che servono più dati o sensori diversi per risolvere davvero il problema.\n",
                "\n",
                "In sintesi: Questo risultato non è un errore del codice, ma riflette la realtà: con queste informazioni, il computer riesce a malapena a fare meglio del caso. È un invito a cercare variabili più profonde o a migliorare i sensori in fabbrica."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "16eb782b",
            "metadata": {},
            "source": [
                "### 7.6 Tabella Riepilogativa\n",
                "\n",
                "Riepilogo finale di tutti i modelli con le metriche chiave sulla classe 1 (difetti)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2d563b3d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# TABELLA RIASSUNTIVA FINALE: Il confronto tra tutti i guerrieri\n",
                "\n",
                "# Creiamo un DataFrame (una tabella) per mettere a confronto i modelli base e quelli bilanciati\n",
                "tabella = pd.DataFrame({\n",
                "    'Modello': [\n",
                "        'Logistic Regression',\n",
                "        'Decision Tree',\n",
                "        'Random Forest',\n",
                "        'LR (Balanced)',\n",
                "        'DT (Balanced)',\n",
                "        'RF (Balanced)'\n",
                "    ],\n",
                "    \n",
                "    # Accuratezza: Quanto ha indovinato in generale (attenzione: può essere ingannevole!)\n",
                "    'Accuracy': [\n",
                "        accuracy_score(y_test, y_pred_log),\n",
                "        accuracy_score(y_test, y_pred_tree),\n",
                "        accuracy_score(y_test, y_pred_rf),\n",
                "        accuracy_score(y_test, y_pred_log_bal),\n",
                "        accuracy_score(y_test, y_pred_tree_bal),\n",
                "        accuracy_score(y_test, y_pred_rf_bal)\n",
                "    ],\n",
                "    \n",
                "    # Precisione: Quando il PC dice \"Difetto\", quanto spesso ha ragione? (Pochi falsi allarmi)\n",
                "    # zero_division=0 evita errori se il modello non dovesse segnalare mai nessun difetto\n",
                "    'Precision (Cl 1)': [\n",
                "        precision_score(y_test, y_pred_log, zero_division=0),\n",
                "        precision_score(y_test, y_pred_tree, zero_division=0),\n",
                "        precision_score(y_test, y_pred_rf, zero_division=0),\n",
                "        precision_score(y_test, y_pred_log_bal, zero_division=0),\n",
                "        precision_score(y_test, y_pred_tree_bal, zero_division=0),\n",
                "        precision_score(y_test, y_pred_rf_bal, zero_division=0)\n",
                "    ],\n",
                "    \n",
                "    # Recall (Il \"Segugio\"): Quanti difetti veri è riuscito a scovare sul totale?\n",
                "    'Recall (Cl 1)': [\n",
                "        recall_score(y_test, y_pred_log, zero_division=0),\n",
                "        recall_score(y_test, y_pred_tree, zero_division=0),\n",
                "        recall_score(y_test, y_pred_rf, zero_division=0),\n",
                "        recall_score(y_test, y_pred_log_bal, zero_division=0),\n",
                "        recall_score(y_test, y_pred_tree_bal, zero_division=0),\n",
                "        recall_score(y_test, y_pred_rf_bal, zero_division=0)\n",
                "    ],\n",
                "    \n",
                "    # F1-Score: Il voto medio che bilancia precisione e capacità di trovare i difetti\n",
                "    'F1 (Cl 1)': [\n",
                "        f1_score(y_test, y_pred_log, zero_division=0),\n",
                "        f1_score(y_test, y_pred_tree, zero_division=0),\n",
                "        f1_score(y_test, y_pred_rf, zero_division=0),\n",
                "        f1_score(y_test, y_pred_log_bal, zero_division=0),\n",
                "        f1_score(y_test, y_pred_tree_bal, zero_division=0),\n",
                "        f1_score(y_test, y_pred_rf_bal, zero_division=0)\n",
                "    ]\n",
                "})\n",
                "\n",
                "# Stampiamo la tabella arrotondando i numeri a 4 cifre per non confonderci con troppi decimali\n",
                "# to_string(index=False) serve a non mostrare i numeri di riga (0, 1, 2...)\n",
                "print(tabella.round(4).to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2a586ce6",
            "metadata": {},
            "source": [
                "**Il confronto tra i modelli**\n",
                "\n",
                "Questa tabella riassuntiva ci mostra il trade-off fondamentale (ovvero la scelta di compromesso) che dobbiamo affrontare in fabbrica:\n",
                "\n",
                "L'inganno della Logistic Regression (Base): Se guardassimo solo l'Accuracy (0.76), sembrerebbe il modello migliore. Ma guardando la Recall (0.00), scopriamo che è il peggiore: in pratica non trova nemmeno un pezzo difettoso. È un modello \"pigro\" che dice sempre che il pezzo è buono per non sbagliare.\n",
                "\n",
                "I modelli \"Bilanciati\" sono i veri guardiani: Appena abbiamo attivato il bilanciamento, la Recall è balzata verso l'alto.\n",
                "* La LR (Balanced) trova il 51% dei difetti (Recall 0.5068): è il nostro miglior segugio, anche se fa scendere l'accuratezza totale perché è molto severa.\n",
                "* Il DT (Balanced) è il più equilibrato (F1-score 0.35): è quello che sbaglia meno nel complesso tra \"difetti persi\" e \"pezzi buoni scartati per errore\".\n",
                "\n",
                "La Random Forest è un \"chirurgo\" prudente: Ha la Precision più alta (0.85). Significa che quando la Random Forest segnala un difetto, puoi starne quasi certo (85% di probabilità). Tuttavia, è così timida che si lascia sfuggire l'88% dei pezzi realmente difettosi.\n",
                "\n",
                "In conclusione, cosa scegliere?\n",
                "\n",
                "Se l'obiettivo è la SICUREZZA: Scegliamo la Logistic Regression (Balanced). Trova molti più difetti degli altri (metà del totale).\n",
                "Se l'obiettivo è il RISPARMIO sui falsi allarmi: Scegliamo il Decision Tree (Balanced), che offre il miglior compromesso generale (F1-score).\n",
                "Se vogliamo un sistema quasi INFALLIBILE (ma cieco): Usiamo la Random Forest, sapendo che segnalerà solo i difetti \"palesi\" e ignorerà quelli più difficili.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b1e77d80",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. Conclusioni e Raccomandazioni\n",
                "\n",
                "### Sintesi dei risultati\n",
                "\n",
                "L'analisi ha confrontato tre algoritmi di classificazione (Logistic Regression, Decision Tree, Random Forest) sia nella versione base che con bilanciamento delle classi. I risultati evidenziano che **nessun modello raggiunge performance pienamente soddisfacenti** nella rilevazione dei difetti:\n",
                "\n",
                "- La **Logistic Regression base** è risultata completamente inadatta: pur avendo un'accuratezza apparente del 76%, non identifica nessun pezzo difettoso (Recall = 0 per la classe 1). Un modello che classifica tutto come \"conforme\" è inutile per il controllo qualità.\n",
                "- Il **Decision Tree bilanciato** offre il miglior compromesso complessivo (F1 = 0.37), con un equilibrio tra Precision (0.36) e Recall (0.38), ma resta un rilevatore debole.\n",
                "- Il **Random Forest bilanciato** ha la Precision più alta (0.88) — quando segnala un difetto è quasi sempre corretto — ma il Recall di 0.15 significa che lascia sfuggire l'85% dei pezzi difettosi.\n",
                "- La **Logistic Regression bilanciata** è la più sensibile ai difetti (Recall = 0.51), ma con troppi falsi allarmi (Precision = 0.27).\n",
                "\n",
                "### Questo risultato è normale?\n",
                "\n",
                "**Sì, è un risultato plausibile e comune** nell'ambito del quality control industriale. Nella realtà produttiva:\n",
                "\n",
                "- I difetti sono eventi **rari** (nel nostro dataset ~24% delle osservazioni, ma in contesti reali possono essere l'1-5%), il che crea un forte sbilanciamento.\n",
                "- I difetti spesso dipendono da **combinazioni complesse** di fattori (usura utensili, variazioni nel lotto materia prima, condizioni ambientali) che i sensori disponibili possono non catturare direttamente.\n",
                "- Il segnale nel dataset è **debole e distribuito** tra molte feature, come confermato dalla Feature Importance dove nessuna variabile domina: il modello non ha una \"chiave\" chiara per separare pezzi buoni e difettosi.\n",
                "- In un caso reale con dati sintetici come questo, è normale che i modelli base non riescano a discriminare efficacemente — il valore dell'esercizio sta nel **processo di analisi** e nell'identificazione dei limiti, non nei numeri assoluti.\n",
                "\n",
                "### Analisi dei falsi negativi e falsi positivi\n",
                "\n",
                "| Tipo di errore | Impatto operativo | Costo stimato |\n",
                "|---|---|---|\n",
                "| **Falso Negativo** (difetto non intercettato) | Pezzo difettoso arriva al cliente → richiami, fermi macchina, danni reputazionali | **Alto** |\n",
                "| **Falso Positivo** (pezzo buono scartato) | Scarto inutile → costo di rilavorazione o materiale perso | **Medio-basso** |\n",
                "\n",
                "Per un fornitore OEM, il costo di un falso negativo è molto superiore a quello di un falso positivo. Per questo motivo, è preferibile un modello con alta Recall (anche a scapito di qualche falso allarme).\n",
                "\n",
                "### Raccomandazioni operative\n",
                "\n",
                "1. **Soglia di decisione personalizzata**: i classificatori di scikit-learn usano di default una soglia di probabilità a 0.50. Abbassandola (es. a 0.30-0.35), il modello classificherebbe come \"difettoso\" anche i pezzi con probabilità intermedia, aumentando significativamente il Recall a scapito della Precision. I pezzi \"incerti\" verrebbero instradati verso un controllo al 100% — un compromesso ragionevole in produzione.\n",
                "2. **Monitoraggio continuo**: le feature più importanti (come `cycle_time_s`, `vibration_level`, `surface_roughness_Ra`) dovrebbero essere monitorate in tempo reale. Variazioni anomale possono essere usate come trigger per azioni preventive.\n",
                "3. **Integrazione MES**: il modello potrebbe essere integrato nel Manufacturing Execution System per automatizzare l'instradamento a ispezione supplementare.\n",
                "4. **Retraining periodico**: le condizioni di processo cambiano nel tempo (usura utensili, nuovi materiali). Si raccomanda un retraining con dati aggiornati.\n",
                "\n",
                "### Limiti e proposte di miglioramento\n",
                "\n",
                "- **AUC basso (~0.58)**: conferma che il segnale discriminante nel dataset è debole. Nessuna singola variabile correla fortemente con il difetto.\n",
                "- **Feature engineering inefficace**: le deviazioni per lotto (`diam_dev_from_batch`, `temp_dev_from_batch`) non apportano informazione a causa della cardinalità quasi 1:1 tra batch e pezzi.\n",
                "- **Possibili miglioramenti**:\n",
                "  - Raccogliere dati da **sensori aggiuntivi** (vibrazioni multiassiali, forze di taglio, immagini di ispezione)\n",
                "  - Arricchire il dataset con informazioni sullo **stato utensile** (ore di utilizzo, ultimo cambio)\n",
                "  - Garantire **più pezzi per lotto** per rendere efficace il feature engineering sulle deviazioni\n",
                "  - Sperimentare tecniche di **oversampling** (SMOTE) per la classe minoritaria\n",
                "  - Valutare modelli più complessi (**Gradient Boosting, XGBoost**) con tuning degli iperparametri\n",
                "  - Adottare **soglie di decisione personalizzate** ottimizzate per massimizzare il Recall o l'F1-score\n",
                "\n",
                "### Riferimenti\n",
                "\n",
                "- [Documentazione scikit-learn](https://scikit-learn.org/stable/)\n",
                "- [Pandas documentation](https://pandas.pydata.org/docs/)\n",
                "- [Seaborn visualization library](https://seaborn.pydata.org/)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
