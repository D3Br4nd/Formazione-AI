{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Modello di Classificazione dei Pezzi Difettosi — AutomaParts S.p.A.\n",
                "\n",
                "## Contesto Aziendale\n",
                "\n",
                "**AutomaParts S.p.A.** è un fornitore tier-1 per il settore automotive che produce componenti meccanici di precisione per sistemi sterzo e sospensioni.  \n",
                "In linea di produzione vengono misurate diverse caratteristiche per ogni pezzo (diametri, planarità, coppia, temperatura processo, ecc.).  \n",
                "Alcuni pezzi non rispettano le tolleranze e causano fermi macchina o richiami cliente.\n",
                "\n",
                "## Obiettivo\n",
                "\n",
                "Sviluppare un modello di **Machine Learning supervisionato** che distingua pezzi conformi (`defect_label = 0`) da pezzi difettosi (`defect_label = 1`) per:\n",
                "- **Scarto automatico** o blocco in ispezione finale\n",
                "- **Instradamento a controllo 100%** quando la probabilità è incerta\n",
                "- **Analisi delle cause principali** dei difetti per interventi di processo\n",
                "\n",
                "## Pipeline di lavoro\n",
                "\n",
                "1. Caricamento e prima esplorazione del dataset\n",
                "2. Analisi esplorativa (EDA)\n",
                "3. Pulizia dei dati\n",
                "4. Preparazione delle variabili (encoding, feature engineering, scaling)\n",
                "5. Addestramento di tre modelli: Logistic Regression, Decision Tree, Random Forest\n",
                "6. Gestione dello sbilanciamento delle classi\n",
                "7. Valutazione e confronto (metriche, confusion matrix, cross-validation, ROC, feature importance)\n",
                "8. Conclusioni e raccomandazioni operative"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# IMPORT — Tutte le librerie necessarie in un unico blocco\n",
                "# ============================================================\n",
                "\n",
                "# Manipolazione dati\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Visualizzazione\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Pre-processing\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "\n",
                "# Modelli\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "\n",
                "# Valutazione\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    confusion_matrix, classification_report,\n",
                "    roc_curve, auc\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Caricamento e Prima Esplorazione\n",
                "\n",
                "Carichiamo il dataset `parts_production_data.csv` e verifichiamo dimensioni, tipi di dato e statistiche descrittive per avere un primo quadro della situazione."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Caricamento del CSV in un DataFrame pandas\n",
                "df = pd.read_csv('parts_production_data.csv')\n",
                "\n",
                "# Prime 5 righe per un'anteprima visuale dei dati\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Struttura del Dataset\n",
                "\n",
                "| Variabile | Tipo | Descrizione |\n",
                "|-----------|------|-------------|\n",
                "| `part_id` | ID | Identificativo univoco del pezzo |\n",
                "| `production_timestamp` | Datetime | Data/ora di produzione |\n",
                "| `line_id` | Categorica | Linea produttiva (1-10) |\n",
                "| `station_id` | Categorica | Stazione di misura (1-20) |\n",
                "| `operator_id` | Categorica | Operatore (anonimizzato, 1-10) |\n",
                "| `measure_diam_mm` | Numerica | Diametro (mm) |\n",
                "| `measure_length_mm` | Numerica | Lunghezza (mm) |\n",
                "| `flatness_mm` | Numerica | Planarità superficiale (mm) |\n",
                "| `torque_Nm` | Numerica | Coppia registrata (Nm) |\n",
                "| `surface_roughness_Ra` | Numerica | Rugosità superficiale (Ra) |\n",
                "| `temp_process_C` | Numerica | Temperatura processo (°C) |\n",
                "| `vibration_level` | Numerica | Livello vibrazione (0-1) |\n",
                "| `cycle_time_s` | Numerica | Tempo ciclo (s) |\n",
                "| `material_batch` | Categorica | Lotto materia prima |\n",
                "| `visual_inspection_score` | Numerica | Punteggio ispezione visiva (0-1) |\n",
                "| `defect_label` | Target | Etichetta binaria (0 = conforme, 1 = difettoso) |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dimensioni del dataset e tipi di dato per ogni colonna\n",
                "print(\"Dimensione del dataset:\", df.shape)\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** Notiamo subito che `production_timestamp` e `material_batch` sono di tipo stringa (`object`). Il timestamp andrà convertito in formato datetime per estrarne informazioni temporali, mentre `material_batch` è una variabile categorica ad alta cardinalità che richiederà un encoding numerico."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistiche descrittive per le variabili numeriche:\n",
                "# media, deviazione standard, min, max e quartili\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** La tabella `describe()` ci fornisce un colpo d'occhio su valori medi, minimi, massimi e distribuzione (quartili) di ogni variabile numerica. Ci serve per individuare subito eventuali valori anomali — per esempio una temperatura fuori range o un diametro implausibile. A prima vista, i dati sembrano coerenti: le medie e i range non presentano anomalie evidenti."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Analisi Esplorativa (EDA)\n",
                "\n",
                "Esploriamo la distribuzione della variabile target, la ripartizione dei difetti per linea produttiva e le correlazioni tra le variabili numeriche."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 Distribuzione della variabile target\n",
                "\n",
                "Verifichiamo quanti pezzi risultano difettosi rispetto a quelli conformi. Lo sbilanciamento delle classi è un aspetto critico perché può ingannare le metriche di valutazione."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Conteggio pezzi conformi (0) e difettosi (1)\n",
                "print(df['defect_label'].value_counts())\n",
                "\n",
                "# Grafico a barre per visualizzare lo sbilanciamento\n",
                "sns.countplot(x='defect_label', data=df)\n",
                "plt.title('Distribuzione Difetti (0 = conforme, 1 = difettoso)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** Come atteso in una linea produttiva reale, i pezzi difettosi sono una **minoranza** rispetto a quelli conformi. Questo sbilanciamento è normale (altrimenti la linea sarebbe fuori controllo), ma ha un impatto diretto sui modelli: un classificatore potrebbe \"barare\" predicendo sempre la classe maggioritaria e ottenere comunque un'accuratezza elevata. Ne terremo conto nella fase di modellazione con tecniche di bilanciamento."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Difetti per linea produttiva\n",
                "\n",
                "Analizziamo se alcune linee produttive presentano un tasso di difettosità più alto di altre. Informazione utile per gli stakeholder e per interventi mirati."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Countplot con hue per separare conformi e difettosi per ogni linea\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.countplot(x='line_id', hue='defect_label', data=df)\n",
                "plt.title('Distribuzione Difetti per Linea Produttiva')\n",
                "plt.xlabel('Linea')\n",
                "plt.ylabel('Conteggio pezzi')\n",
                "plt.legend(title='Difetto', labels=['Conforme', 'Difettoso'])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** Le proporzioni tra pezzi conformi e difettosi sono piuttosto uniformi tra le diverse linee: nessuna linea si distingue in modo evidente per un tasso di difettosità anomalo. Questo suggerisce che i difetti non sono legati a una specifica linea ma piuttosto a fattori trasversali (materiali, parametri di processo, ecc.)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Matrice di Correlazione\n",
                "\n",
                "Verifichiamo se esistono correlazioni forti tra le variabili numeriche e con il target `defect_label`. Variabili molto correlate tra loro o con il target possono guidare la scelta delle feature."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Heatmap delle correlazioni — valori tra -1 (correlazione negativa) e +1 (correlazione positiva)\n",
                "plt.figure(figsize=(14, 10))\n",
                "sns.heatmap(\n",
                "    df.corr(numeric_only=True),\n",
                "    annot=True,\n",
                "    fmt=\".2f\",             # Due decimali per leggibilità\n",
                "    annot_kws={\"size\": 9}, # Font ridotto per evitare sovrapposizioni\n",
                "    cmap='coolwarm'\n",
                ")\n",
                "plt.title('Matrice di Correlazione')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** I valori di correlazione con `defect_label` sono tutti piuttosto vicini a 0. Questo indica che **nessuna singola variabile è un predittore forte del difetto** presa isolatamente. Tuttavia, questo non significa che le variabili siano inutili: la combinazione di più feature, catturata dai modelli di ML, può comunque fornire un potere predittivo significativo. Non si evidenziano nemmeno multi-collinearità forti tra le feature indipendenti."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Pulizia dei Dati\n",
                "\n",
                "Verifichiamo la presenza di valori mancanti, trattiamo eventuali outlier e rimuoviamo le colonne non informative o sensibili sotto il profilo privacy."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1 Valori Mancanti"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Conteggio dei valori nulli per ogni colonna\n",
                "df.isnull().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** Il dataset non presenta **alcun valore mancante**: tutte le colonne hanno il conteggio completo di osservazioni. Non è quindi necessario applicare strategie di imputation o rimozione di righe incomplete. Un ottimo punto di partenza."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Controllo Outlier (metodo IQR)\n",
                "\n",
                "Applichiamo il metodo dell'**Interquartile Range (IQR)** sulle principali variabili di processo per verificare la presenza di valori anomali. Un valore è considerato outlier se cade al di sotto di Q1 − 1.5·IQR o al di sopra di Q3 + 1.5·IQR."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def remove_outliers_iqr(df, column):\n",
                "    \"\"\"Rimuove le righe con valori outlier in 'column' secondo il metodo IQR.\"\"\"\n",
                "    Q1 = df[column].quantile(0.25)\n",
                "    Q3 = df[column].quantile(0.75)\n",
                "    IQR = Q3 - Q1\n",
                "    lower = Q1 - 1.5 * IQR\n",
                "    upper = Q3 + 1.5 * IQR\n",
                "    return df[(df[column] >= lower) & (df[column] <= upper)]\n",
                "\n",
                "print(f\"Righe PRIMA della pulizia: {len(df)}\")\n",
                "\n",
                "# Colonne su cui verificare gli outlier (misure fisiche e sensori)\n",
                "cols_to_clean = ['measure_diam_mm', 'measure_length_mm', 'temp_process_C', 'vibration_level']\n",
                "\n",
                "for col in cols_to_clean:\n",
                "    df = remove_outliers_iqr(df, col)\n",
                "\n",
                "print(f\"Righe DOPO la pulizia:  {len(df)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** Il conteggio delle righe prima e dopo la pulizia è identico: **nessun sample è stato eliminato**. Questo conferma quanto osservato dal `describe()`: i dati rientrano tutti in range ragionevoli e non presentano outlier significativi secondo il criterio IQR."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 Rimozione colonne non informative e privacy\n",
                "\n",
                "- **`part_id`**: è un identificativo univoco progressivo, non porta informazione predittiva.\n",
                "- **`operator_id`**: potrebbe essere coperto da vincoli di privacy aziendale; inoltre, dal grafico di sez. 2.2 non emergeva un legame operatore↔difetto particolarmente forte. Lo rimuoviamo per cautela.\n",
                "- **`production_timestamp`**: prima di eliminarlo, estraiamo l'**ora di produzione** — potrebbe influenzare la qualità (es. turni, stanchezza)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Conversione del timestamp in formato datetime\n",
                "df['production_timestamp'] = pd.to_datetime(df['production_timestamp'])\n",
                "\n",
                "# Feature Engineering: estraiamo l'ora di produzione come nuova colonna\n",
                "df['hour'] = df['production_timestamp'].dt.hour\n",
                "\n",
                "# Rimozione delle colonne non più necessarie\n",
                "df = df.drop(columns=['part_id', 'production_timestamp', 'operator_id'], errors='ignore')\n",
                "\n",
                "print(\"Colonne finali dopo la pulizia:\")\n",
                "print(list(df.columns))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** Abbiamo ridotto il dataset alle sole colonne utili e aggiunto la feature `hour`. Il DataFrame ora contiene solo variabili che porteranno informazione ai modelli, rispettando inoltre i requisiti di privacy sull'operatore."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Preparazione delle Variabili\n",
                "\n",
                "In questa sezione trasformiamo le variabili categoriche in formato numerico, creiamo feature derivate aggregate per lotto e applichiamo lo scaling prima dell'addestramento."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1 Encoding delle variabili categoriche (LabelEncoder)\n",
                "\n",
                "Il dataset contiene variabili categoriche di tipo stringa che i modelli non possono usare direttamente. Utilizziamo il **LabelEncoder** di scikit-learn, che assegna un numero intero univoco a ogni categoria. Per `material_batch`, che ha un'alta cardinalità (~3000 lotti diversi), il LabelEncoder è la scelta più pratica: usare `get_dummies` genererebbe migliaia di colonne."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verifica della cardinalità delle colonne categoriche\n",
                "print(\"Batch unici:\", df['material_batch'].nunique())\n",
                "print(\"Line ID unici:\", df['line_id'].nunique())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Copia del DataFrame per non alterare l'originale\n",
                "df_encoded = df.copy()\n",
                "\n",
                "# Inizializzazione del LabelEncoder\n",
                "le = LabelEncoder()\n",
                "\n",
                "# Applichiamo il Label Encoding a tutte le colonne di tipo object/string\n",
                "categorical_cols = df_encoded.select_dtypes(include=['object', 'string']).columns\n",
                "\n",
                "for col in categorical_cols:\n",
                "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
                "    print(f\"Codificata: {col} → {df_encoded[col].nunique()} valori unici\")\n",
                "\n",
                "print(\"\\nEncoding completato.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** Tutte le colonne categoriche sono state trasformate in valori numerici interi. Da notare che `material_batch` ha un'alta cardinalità: il modello potrebbe tendere all'overfitting su questa variabile. Tuttavia, per gli scopi di questa esercitazione, il LabelEncoder è il compromesso più idoneo per confrontare la capacità di generalizzazione dei diversi algoritmi."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 Feature Engineering — Deviazioni per lotto\n",
                "\n",
                "Creiamo feature derivate che catturano lo **scostamento** di una misura rispetto alla media del proprio lotto di materia prima. L'intuizione è che un pezzo con un diametro o una temperatura anomali *rispetto al proprio batch* potrebbe essere più probabile difettoso."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Scostamento del diametro dalla media del batch\n",
                "df_encoded['batch_diam_mean'] = df_encoded.groupby('material_batch')['measure_diam_mm'].transform('mean')\n",
                "df_encoded['diam_dev_from_batch'] = df_encoded['measure_diam_mm'] - df_encoded['batch_diam_mean']\n",
                "\n",
                "# 2. Scostamento della temperatura dalla media del batch\n",
                "df_encoded['batch_temp_mean'] = df_encoded.groupby('material_batch')['temp_process_C'].transform('mean')\n",
                "df_encoded['temp_dev_from_batch'] = df_encoded['temp_process_C'] - df_encoded['batch_temp_mean']\n",
                "\n",
                "print(\"Feature engineering completato — aggiunte 4 colonne (2 medie + 2 deviazioni).\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** Le nuove feature `diam_dev_from_batch` e `temp_dev_from_batch` rappresentano quanto un singolo pezzo si discosta dalla norma del proprio lotto. Queste informazioni contestuali possono dare al modello un segnale più preciso rispetto ai valori assoluti."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 Suddivisione Train / Test e Scaling\n",
                "\n",
                "Dividiamo il dataset in **Training Set (80%)** per l'addestramento e **Test Set (20%)** per la valutazione su dati non visti.  \n",
                "Successivamente applichiamo lo **StandardScaler** (standardizzazione con media=0 e deviazione standard=1), necessario per la Logistic Regression che è sensibile alle scale diverse delle variabili.  \n",
                "\n",
                "**Importante:** lo scaler viene fittato **solo sul training set** per evitare *data leakage* — il test set viene trasformato con le statistiche del train."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Separazione Feature (X) e Target (y)\n",
                "X = df_encoded.drop('defect_label', axis=1)\n",
                "y = df_encoded['defect_label']\n",
                "\n",
                "# Split 80/20 con random_state fissato per riproducibilità\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "print(f\"Training Set: {X_train.shape[0]} campioni, {X_train.shape[1]} feature\")\n",
                "print(f\"Test Set:     {X_test.shape[0]} campioni, {X_test.shape[1]} feature\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# StandardScaler: fit solo su train, transform su entrambi\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** Lo StandardScaler porta ogni feature ad avere media ≈ 0 e deviazione standard ≈ 1. Questo è fondamentale per la Logistic Regression (che usa la distanza tra i coefficienti), mentre i modelli ad albero (Decision Tree e Random Forest) non ne hanno bisogno — per questi ultimi useremo i dati non scalati."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Addestramento dei Modelli\n",
                "\n",
                "Addestriamo tre modelli di classificazione come richiesto dalla traccia:\n",
                "\n",
                "| Modello | Caratteristiche |\n",
                "|---------|----------------|\n",
                "| **Logistic Regression** | Modello lineare, veloce, buona baseline ma limitato su relazioni non lineari |\n",
                "| **Decision Tree** | Non lineare, interpretabile, rischia di fare overfitting |\n",
                "| **Random Forest** | Ensemble di alberi, più robusto e generalmente più accurato |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.1 Logistic Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# La Logistic Regression usa i dati scalati\n",
                "log_reg = LogisticRegression(random_state=42)\n",
                "log_reg.fit(X_train_scaled, y_train)\n",
                "y_pred_log = log_reg.predict(X_test_scaled)\n",
                "\n",
                "print(f\"Accuracy Logistic Regression: {accuracy_score(y_test, y_pred_log):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** La Logistic Regression ottiene un'accuratezza intorno al 75%. Tuttavia, come vedremo nel dettaglio nella sezione di valutazione, un'accuratezza elevata può essere ingannevole in presenza di classi sbilanciate: il modello potrebbe semplicemente predire quasi sempre la classe maggioritaria."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2 Decision Tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# I modelli ad albero non richiedono lo scaling — usiamo X_train originale\n",
                "tree_clf = DecisionTreeClassifier(random_state=42)\n",
                "tree_clf.fit(X_train, y_train)\n",
                "y_pred_tree = tree_clf.predict(X_test)\n",
                "\n",
                "print(f\"Accuracy Decision Tree: {accuracy_score(y_test, y_pred_tree):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** Il Decision Tree scende intorno al 68%. Un singolo albero tende a fare overfitting sui dati di training e fatica a generalizzare, specialmente con molte feature e alta cardinalità come `material_batch`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.3 Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Random Forest: ensemble di 100 alberi per compensare la varianza\n",
                "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf_clf.fit(X_train, y_train)\n",
                "y_pred_rf = rf_clf.predict(X_test)\n",
                "\n",
                "print(f\"Accuracy Random Forest: {accuracy_score(y_test, y_pred_rf):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** Il Random Forest risale sopra il 78%, confermandosi il modello più robusto. L'aggregazione di 100 alberi riduce la varianza e corregge gli errori dei singoli alberi, portando a previsioni più stabili."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Gestione dello Sbilanciamento delle Classi\n",
                "\n",
                "Il dataset è sbilanciato: i pezzi difettosi sono pochi rispetto a quelli conformi. Questo porta i modelli a favorire la classe maggioritaria, ignorando spesso la classe 1 (difetti) — che è proprio quella più importante per l'azienda.\n",
                "\n",
                "Utilizziamo il parametro **`class_weight='balanced'`** che aumenta il peso degli errori commessi sulla classe minoritaria, forzando il modello a \"prestare più attenzione\" ai difetti. Riaddestriamo **tutti e tre** i modelli."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Logistic Regression bilanciata (dati scalati)\n",
                "log_reg_bal = LogisticRegression(class_weight='balanced', random_state=42)\n",
                "log_reg_bal.fit(X_train_scaled, y_train)\n",
                "y_pred_log_bal = log_reg_bal.predict(X_test_scaled)\n",
                "\n",
                "# Decision Tree bilanciato (dati non scalati)\n",
                "tree_clf_bal = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
                "tree_clf_bal.fit(X_train, y_train)\n",
                "y_pred_tree_bal = tree_clf_bal.predict(X_test)\n",
                "\n",
                "# Random Forest bilanciato (dati non scalati)\n",
                "rf_clf_bal = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
                "rf_clf_bal.fit(X_train, y_train)\n",
                "y_pred_rf_bal = rf_clf_bal.predict(X_test)\n",
                "\n",
                "print(\"Addestramento con class balancing completato per tutti e 3 i modelli.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** Ora abbiamo 6 set di predizioni in totale (3 modelli base + 3 bilanciati). Nella prossima sezione confronteremo le performance in modo sistematico per capire quale configurazione sia preferibile nel contesto produttivo di AutomaParts."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Valutazione e Confronto\n",
                "\n",
                "Confrontiamo tutti i modelli con metriche dettagliate, prestando particolare attenzione a **Recall** e **Precision** sulla classe 1 (difetti), che sono le metriche più rilevanti dal punto di vista operativo:\n",
                "\n",
                "- **Recall (classe 1)**: capacità di intercettare i pezzi difettosi → un valore basso significa molti **falsi negativi** (difetti che sfuggono al cliente!)\n",
                "- **Precision (classe 1)**: accuratezza delle previsioni di difetto → un valore basso significa molti **falsi positivi** (pezzi buoni scartati inutilmente)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.1 Classification Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Report completo per i modelli BASE\n",
                "print(\"===== MODELLI BASE =====\")\n",
                "print(\"\\n--- Logistic Regression ---\")\n",
                "print(classification_report(y_test, y_pred_log))\n",
                "\n",
                "print(\"--- Decision Tree ---\")\n",
                "print(classification_report(y_test, y_pred_tree))\n",
                "\n",
                "print(\"--- Random Forest ---\")\n",
                "print(classification_report(y_test, y_pred_rf))\n",
                "\n",
                "# Report completo per i modelli BILANCIATI\n",
                "print(\"\\n===== MODELLI CON CLASS BALANCING =====\")\n",
                "print(\"\\n--- Logistic Regression (Balanced) ---\")\n",
                "print(classification_report(y_test, y_pred_log_bal))\n",
                "\n",
                "print(\"--- Decision Tree (Balanced) ---\")\n",
                "print(classification_report(y_test, y_pred_tree_bal))\n",
                "\n",
                "print(\"--- Random Forest (Balanced) ---\")\n",
                "print(classification_report(y_test, y_pred_rf_bal))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento dettagliato:**\n",
                "\n",
                "**Modelli base:**\n",
                "- La **Logistic Regression** ha un'accuratezza intorno al 76%, ma precision e recall sulla classe 1 sono bassissime (o nulle): il modello predice quasi sempre 0, rendendo di fatto inutile la classificazione dei difetti.\n",
                "- Il **Decision Tree** ha un'accuratezza più bassa (~69%) ma almeno inizia a intercettare qualche difetto, con una recall per la classe 1 intorno al 39%.\n",
                "- Il **Random Forest** è il migliore tra i modelli base, con l'accuracy più alta e una recall discreta per la classe 1.\n",
                "\n",
                "**Modelli bilanciati:**\n",
                "- Con `class_weight='balanced'`, la **recall per la classe 1 aumenta significativamente** per tutti i modelli. Il compromesso è un leggero aumento dei falsi positivi (pezzi buoni scartati), ma dal punto di vista industriale è preferibile scartare qualche pezzo buono in più piuttosto che lasciar passare un difettoso."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.2 Confusion Matrices\n",
                "\n",
                "Le matrici di confusione ci mostrano in modo visuale la distribuzione di:\n",
                "- **Veri Positivi (VP)**: difetti correttamente intercettati\n",
                "- **Falsi Negativi (FN)**: difetti sfuggiti (pericolosi!)\n",
                "- **Falsi Positivi (FP)**: pezzi buoni scartati inutilmente\n",
                "- **Veri Negativi (VN)**: pezzi buoni correttamente classificati"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Griglia 2x3 per visualizzare tutte le confusion matrices insieme\n",
                "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
                "\n",
                "# Riga 1: modelli BASE\n",
                "modelli_base = [\n",
                "    ('Logistic Regression', y_pred_log, 'Reds'),\n",
                "    ('Decision Tree', y_pred_tree, 'Greens'),\n",
                "    ('Random Forest', y_pred_rf, 'Blues'),\n",
                "]\n",
                "\n",
                "for i, (nome, y_pred, cmap) in enumerate(modelli_base):\n",
                "    cm = confusion_matrix(y_test, y_pred)\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, ax=axes[0, i])\n",
                "    axes[0, i].set_title(nome)\n",
                "    axes[0, i].set_xlabel('Predetto')\n",
                "    axes[0, i].set_ylabel('Reale')\n",
                "\n",
                "# Riga 2: modelli BILANCIATI\n",
                "modelli_bal = [\n",
                "    ('LR (Balanced)', y_pred_log_bal, 'Oranges'),\n",
                "    ('DT (Balanced)', y_pred_tree_bal, 'YlGn'),\n",
                "    ('RF (Balanced)', y_pred_rf_bal, 'PuBu'),\n",
                "]\n",
                "\n",
                "for i, (nome, y_pred, cmap) in enumerate(modelli_bal):\n",
                "    cm = confusion_matrix(y_test, y_pred)\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, ax=axes[1, i])\n",
                "    axes[1, i].set_title(nome)\n",
                "    axes[1, i].set_xlabel('Predetto')\n",
                "    axes[1, i].set_ylabel('Reale')\n",
                "\n",
                "plt.suptitle('Confusion Matrices — Base (sopra) vs Bilanciati (sotto)', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento ai grafici:**\n",
                "\n",
                "Confrontando la riga superiore (modelli base) con quella inferiore (bilanciati) si nota chiaramente l'effetto del class balancing:\n",
                "\n",
                "- Nei **modelli base**, l'angolo in basso a destra (Veri Positivi — difetti intercettati) è molto piccolo, specialmente per la Logistic Regression che non ne cattura quasi nessuno.\n",
                "- Nei **modelli bilanciati**, il riquadro dei VP cresce sensibilmente, a dimostrazione che il bilanciamento permette ai modelli di intercettare molti più pezzi difettosi.\n",
                "- Il trade-off è visibile nell'aumento dei Falsi Positivi (angolo in alto a destra), ma in un contesto produttivo è un compromesso accettabile: un falso allarme costa meno di un pezzo difettoso consegnato al cliente."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.3 Cross-Validation (5-fold)\n",
                "\n",
                "La cross-validation ci permette di valutare la **stabilità** delle performance dividendo il dataset in 5 parti e addestrandone una diversa ogni volta. Una deviazione standard bassa indica che il modello è robusto e non dipende da un singolo split casuale."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cross-validation per tutti e 3 i modelli (versione base)\n",
                "modelli_cv = {\n",
                "    'Logistic Regression': LogisticRegression(random_state=42),\n",
                "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
                "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
                "}\n",
                "\n",
                "print(\"Cross-Validation (5-fold) — Accuratezza:\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "for nome, modello in modelli_cv.items():\n",
                "    # Per la LR usiamo i dati scalati, per gli alberi quelli originali\n",
                "    if 'Logistic' in nome:\n",
                "        scores = cross_val_score(modello, scaler.fit_transform(X), y, cv=5)\n",
                "    else:\n",
                "        scores = cross_val_score(modello, X, y, cv=5)\n",
                "    print(f\"{nome:25s} | Media: {scores.mean():.4f}  |  Std: {scores.std():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** La cross-validation conferma la stabilità dei risultati. Una deviazione standard contenuta (< 0.02-0.03) indica che le performance non dipendono dal particolare split casuale dei dati e che i modelli generalizzano in modo coerente su diverse porzioni del dataset."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.4 Feature Importance (Random Forest)\n",
                "\n",
                "Il Random Forest ci permette di estrarre l'**importanza relativa** di ogni feature nella decisione del modello. Questo è fondamentale per capire quali variabili di processo vanno monitorate con più attenzione e dove intervenire per ridurre la difettosità."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Estrazione e ordinamento delle feature importance\n",
                "importances = rf_clf.feature_importances_\n",
                "indices = np.argsort(importances)[::-1]\n",
                "\n",
                "# Grafico a barre orizzontali per leggibilità\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.title('Feature Importance — Random Forest')\n",
                "plt.bar(range(X.shape[1]), importances[indices], align='center')\n",
                "plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\n",
                "plt.ylabel('Importanza relativa')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento al grafico:**\n",
                "\n",
                "Le barre più alte identificano le variabili che il modello considera più discriminanti:\n",
                "\n",
                "1. **Feature dominanti** (prime barre): sono le variabili che più influenzano la previsione. Se queste misure variano, la probabilità di difetto cambia sensibilmente. Sono i candidati principali per il monitoraggio in tempo reale.\n",
                "2. **Feature secondarie**: contribuiscono alla decisione ma in misura minore. Potrebbero essere utili in un'ottica di riduzione della complessità se si volessero snellire i controlli.\n",
                "3. **Implicazioni operative**: le feature più importanti indicano dove la variabilità di processo crea più problemi di qualità. Concentrare gli interventi di manutenzione e taratura su questi parametri può avere il maggior impatto sulla riduzione della difettosità."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.5 Curva ROC e AUC (Random Forest)\n",
                "\n",
                "La **curva ROC** mostra il trade-off tra True Positive Rate (recall) e False Positive Rate al variare della soglia di decisione. L'**AUC** (Area Under the Curve) riassume la capacità discriminativa del modello in un singolo numero: 0.5 = classificatore casuale, 1.0 = classificatore perfetto."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Probabilità predette per la classe positiva (difettoso)\n",
                "y_prob = rf_clf.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# Calcolo della curva ROC\n",
                "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
                "roc_auc = auc(fpr, tpr)\n",
                "\n",
                "# Plot\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
                "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Random (AUC = 0.50)')\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate')\n",
                "plt.title('Curva ROC — Random Forest')\n",
                "plt.legend(loc='lower right')\n",
                "plt.grid(alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:**\n",
                "\n",
                "- La linea tratteggiata grigia rappresenta il classificatore casuale (AUC = 0.50).\n",
                "- La curva arancione del nostro modello deve posizionarsi il più possibile verso l'angolo in alto a sinistra.\n",
                "- Un **AUC intorno a 0.58** è un valore basso: il modello fa fatica a distinguere nettamente i pezzi difettosi da quelli conformi. Questo è coerente con quanto osservato nella matrice di correlazione, dove nessuna variabile presa singolarmente correlava fortemente con il target.\n",
                "- Per migliorare significativamente l'AUC, servirebbero probabilmente dati più informativi (nuovi sensori, metriche aggiuntive) o un dataset con un segnale più chiaro."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.6 Tabella Riepilogativa\n",
                "\n",
                "Riepilogo finale di tutti i modelli con le metriche chiave sulla classe 1 (difetti)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Costruzione della tabella riassuntiva\n",
                "tabella = pd.DataFrame({\n",
                "    'Modello': [\n",
                "        'Logistic Regression',\n",
                "        'Decision Tree',\n",
                "        'Random Forest',\n",
                "        'LR (Balanced)',\n",
                "        'DT (Balanced)',\n",
                "        'RF (Balanced)'\n",
                "    ],\n",
                "    'Accuracy': [\n",
                "        accuracy_score(y_test, y_pred_log),\n",
                "        accuracy_score(y_test, y_pred_tree),\n",
                "        accuracy_score(y_test, y_pred_rf),\n",
                "        accuracy_score(y_test, y_pred_log_bal),\n",
                "        accuracy_score(y_test, y_pred_tree_bal),\n",
                "        accuracy_score(y_test, y_pred_rf_bal)\n",
                "    ],\n",
                "    'Precision (Cl 1)': [\n",
                "        precision_score(y_test, y_pred_log, zero_division=0),\n",
                "        precision_score(y_test, y_pred_tree, zero_division=0),\n",
                "        precision_score(y_test, y_pred_rf, zero_division=0),\n",
                "        precision_score(y_test, y_pred_log_bal, zero_division=0),\n",
                "        precision_score(y_test, y_pred_tree_bal, zero_division=0),\n",
                "        precision_score(y_test, y_pred_rf_bal, zero_division=0)\n",
                "    ],\n",
                "    'Recall (Cl 1)': [\n",
                "        recall_score(y_test, y_pred_log, zero_division=0),\n",
                "        recall_score(y_test, y_pred_tree, zero_division=0),\n",
                "        recall_score(y_test, y_pred_rf, zero_division=0),\n",
                "        recall_score(y_test, y_pred_log_bal, zero_division=0),\n",
                "        recall_score(y_test, y_pred_tree_bal, zero_division=0),\n",
                "        recall_score(y_test, y_pred_rf_bal, zero_division=0)\n",
                "    ],\n",
                "    'F1 (Cl 1)': [\n",
                "        f1_score(y_test, y_pred_log, zero_division=0),\n",
                "        f1_score(y_test, y_pred_tree, zero_division=0),\n",
                "        f1_score(y_test, y_pred_rf, zero_division=0),\n",
                "        f1_score(y_test, y_pred_log_bal, zero_division=0),\n",
                "        f1_score(y_test, y_pred_tree_bal, zero_division=0),\n",
                "        f1_score(y_test, y_pred_rf_bal, zero_division=0)\n",
                "    ]\n",
                "})\n",
                "\n",
                "# Arrotondiamo a 4 decimali per leggibilità\n",
                "print(tabella.round(4).to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Commento:** La tabella consente un confronto diretto tra tutte le configurazioni. Si evidenzia chiaramente come il **class balancing** migliori drasticamente la recall sulla classe 1 (difetti) — la metrica più critica per AutomaParts. Il **Random Forest (Balanced)** rappresenta il miglior compromesso tra accuratezza complessiva e capacità di intercettare i pezzi difettosi."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. Conclusioni e Raccomandazioni\n",
                "\n",
                "### Sintesi dei risultati\n",
                "\n",
                "L'analisi ha confrontato tre algoritmi di classificazione (Logistic Regression, Decision Tree, Random Forest) sia nella versione base che con bilanciamento delle classi:\n",
                "\n",
                "- La **Logistic Regression base** è risultata inadatta: pur avendo un'accuratezza apparentemente buona (~76%), non è in grado di identificare i pezzi difettosi (recall ≈ 0 per la classe 1). Questo la rende inutilizzabile nel contesto produttivo.\n",
                "- Il **Decision Tree** offre un minimo di capacità di rilevamento ma è instabile e tende all'overfitting.\n",
                "- Il **Random Forest** è il modello più robusto, con la migliore combinazione di accuratezza e recall — specialmente nella versione bilanciata.\n",
                "\n",
                "Il **Random Forest con `class_weight='balanced'`** è il modello raccomandato per l'uso operativo.\n",
                "\n",
                "### Analisi dei falsi negativi e falsi positivi\n",
                "\n",
                "| Tipo di errore | Impatto operativo | Costo stimato |\n",
                "|---------------|-------------------|---------------|\n",
                "| **Falso Negativo** (difetto non intercettato) | Pezzo difettoso arriva al cliente → possibili richiami, fermi macchina, danni reputazionali | **Alto** |\n",
                "| **Falso Positivo** (pezzo buono scartato) | Scarto inutile → costo di rilavorazione o materiale perso | **Medio-basso** |\n",
                "\n",
                "Per un fornitore OEM, il costo di un falso negativo è molto superiore a quello di un falso positivo. Per questo motivo, è preferibile un modello con alta recall (anche a scapito di qualche falso allarme), come il Random Forest bilanciato.\n",
                "\n",
                "### Raccomandazioni operative\n",
                "\n",
                "1. **Soglia di decisione**: considerare di abbassare la soglia di probabilità dal default 0.50 (es. a 0.30-0.40) per intercettare più difetti, instradando i pezzi \"incerti\" verso un controllo 100%.\n",
                "2. **Monitoraggio continuo**: le feature più importanti (quelle evidenziate nel grafico della sezione 7.4) dovrebbero essere monitorate in tempo reale. Variazioni anomale possono essere usate come trigger per azioni preventive.\n",
                "3. **Integrazione MES**: il modello potrebbe essere integrato nel Manufacturing Execution System per automatizzare lo scarto o l'instradamento a ispezione supplementare.\n",
                "4. **Retraining periodico**: le condizioni di processo cambiano nel tempo (usura utensili, nuovi materiali). Si raccomanda un retraining periodico del modello con dati aggiornati.\n",
                "\n",
                "### Limiti e proposte di miglioramento\n",
                "\n",
                "- **AUC basso (~0.58)**: il segnale nel dataset attuale è debole. Nessuna singola variabile correla fortemente con il difetto, come emerso dalla matrice di correlazione.\n",
                "- **Possibili miglioramenti**:\n",
                "  - Raccogliere dati da sensori aggiuntivi (vibrazioni multiassiali, forze di taglio, immagini di ispezione)\n",
                "  - Arricchire il dataset con informazioni sullo stato utensile (ore di utilizzo, ultimo cambio)\n",
                "  - Sperimentare tecniche di oversampling (SMOTE) per la classe minoritaria\n",
                "  - Valutare modelli più complessi (Gradient Boosting, XGBoost) se il volume dati lo consente\n",
                "\n",
                "### Riferimenti\n",
                "\n",
                "- [Documentazione scikit-learn](https://scikit-learn.org/stable/)\n",
                "- [Pandas documentation](https://pandas.pydata.org/docs/)\n",
                "- [Seaborn visualization library](https://seaborn.pydata.org/)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
