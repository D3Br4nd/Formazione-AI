{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Modello di Classificazione dei Pezzi Difettosi — AutomaParts S.p.A.\n",
                "\n",
                "## Contesto Aziendale\n",
                "\n",
                "**AutomaParts S.p.A.** è un fornitore tier-1 per il settore automotive che produce componenti meccanici di precisione per sistemi sterzo e sospensioni.  \n",
                "In linea di produzione vengono misurate diverse caratteristiche per ogni pezzo (diametri, planarità, coppia, temperatura processo, ecc.).  \n",
                "Alcuni pezzi non rispettano le tolleranze e causano fermi macchina o richiami cliente.\n",
                "\n",
                "## Obiettivo\n",
                "\n",
                "Sviluppare un modello di **Machine Learning supervisionato** che distingua pezzi conformi (`defect_label = 0`) da pezzi difettosi (`defect_label = 1`) per:\n",
                "- **Scarto automatico** o blocco in ispezione finale\n",
                "- **Instradamento a controllo 100%** quando la probabilità è incerta\n",
                "- **Analisi delle cause principali** dei difetti per interventi di processo\n",
                "\n",
                "## Pipeline di lavoro\n",
                "\n",
                "1. Caricamento e prima esplorazione del dataset\n",
                "2. Analisi esplorativa (EDA)\n",
                "3. Pulizia dei dati\n",
                "4. Preparazione delle variabili (encoding, feature engineering, scaling)\n",
                "5. Addestramento di tre modelli: Logistic Regression, Decision Tree, Random Forest\n",
                "6. Gestione dello sbilanciamento delle classi\n",
                "7. Valutazione e confronto (metriche, confusion matrix, cross-validation, ROC, feature importance)\n",
                "8. Conclusioni e raccomandazioni operative"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f1270932",
            "metadata": {},
            "outputs": [],
            "source": [
                "# IMPORT — Tutte le librerie necessarie in un unico blocco\n",
                "\n",
                "# Manipolazione dati\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Visualizzazione\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Pre-processing\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "\n",
                "# Modelli\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "\n",
                "# Valutazione\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    confusion_matrix, classification_report,\n",
                "    roc_curve, auc\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eced2554",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Caricamento e Prima Esplorazione\n",
                "\n",
                "Carichiamo il dataset `parts_production_data.csv` e verifichiamo dimensioni, tipi di dato e statistiche descrittive per avere un primo quadro della situazione."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d790d3d0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Caricamento del CSV in un DataFrame pandas\n",
                "df = pd.read_csv('parts_production_data.csv')\n",
                "\n",
                "# Prime 5 righe per un'anteprima visuale dei dati\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "63253ccd",
            "metadata": {},
            "source": [
                "### Struttura del Dataset\n",
                "\n",
                "| Variabile | Tipo | Descrizione |\n",
                "|-----------|------|-------------|\n",
                "| `part_id` | ID | Identificativo univoco del pezzo |\n",
                "| `production_timestamp` | Datetime | Data/ora di produzione |\n",
                "| `line_id` | Categorica | Linea produttiva (1-10) |\n",
                "| `station_id` | Categorica | Stazione di misura (1-20) |\n",
                "| `operator_id` | Categorica | Operatore (anonimizzato, 1-10) |\n",
                "| `measure_diam_mm` | Numerica | Diametro (mm) |\n",
                "| `measure_length_mm` | Numerica | Lunghezza (mm) |\n",
                "| `flatness_mm` | Numerica | Planarità superficiale (mm) |\n",
                "| `torque_Nm` | Numerica | Coppia registrata (Nm) |\n",
                "| `surface_roughness_Ra` | Numerica | Rugosità superficiale (Ra) |\n",
                "| `temp_process_C` | Numerica | Temperatura processo (°C) |\n",
                "| `vibration_level` | Numerica | Livello vibrazione (0-1) |\n",
                "| `cycle_time_s` | Numerica | Tempo ciclo (s) |\n",
                "| `material_batch` | Categorica | Lotto materia prima |\n",
                "| `visual_inspection_score` | Numerica | Punteggio ispezione visiva (0-1) |\n",
                "| `defect_label` | Target | Etichetta binaria (0 = conforme, 1 = difettoso) |\n",
                "\n",
                "**Variabili di identificazione e contesto:**  \n",
                "`part_id` è l'identificativo univoco del singolo pezzo e non ha valore predittivo. `production_timestamp` registra il momento esatto della produzione e può essere utile per estrarre informazioni temporali (turno, ora del giorno). `line_id`, `station_id` e `operator_id` rappresentano rispettivamente la linea produttiva, la stazione di misura e l'operatore coinvolto: servono a tracciare eventuali pattern legati a specifiche combinazioni di macchina/turno/persona. `material_batch` identifica il lotto di materia prima utilizzato — variazioni tra lotti possono influenzare la qualità del prodotto finito.\n",
                "\n",
                "**Misure dimensionali e di processo:**  \n",
                "`measure_diam_mm` e `measure_length_mm` sono misure dimensionali dirette del pezzo (diametro e lunghezza in millimetri), fondamentali per verificare il rispetto delle tolleranze meccaniche. `flatness_mm` misura la planarità superficiale: valori elevati indicano deformazioni che possono compromettere l'accoppiamento del componente. `torque_Nm` è la coppia di serraggio registrata durante l'assemblaggio, un parametro critico per la sicurezza nei sistemi sterzo e sospensioni.\n",
                "\n",
                "**Sensori e parametri di processo:**  \n",
                "`surface_roughness_Ra` misura la rugosità superficiale secondo lo standard Ra — influisce sull'attrito e sulla durata del componente. `temp_process_C` è la temperatura del processo produttivo in gradi Celsius: temperature fuori range possono alterare le proprietà del materiale. `vibration_level` (normalizzato 0-1) rileva vibrazioni anomale della macchina, potenziale indicatore di usura utensile o disallineamento. `cycle_time_s` è il tempo ciclo in secondi: tempi anomali possono segnalare problemi di processo.\n",
                "\n",
                "**Ispezione e target:**  \n",
                "`visual_inspection_score` (0-1) è il punteggio assegnato dall'ispezione visiva automatica o manuale — un valore basso indica difetti estetici o superficiali. `defect_label` è la nostra **variabile target** binaria: 0 indica un pezzo conforme, 1 un pezzo difettoso che non ha superato i controlli qualità."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "12b759a9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dimensioni del dataset e tipi di dato per ogni colonna\n",
                "print(\"Dimensione del dataset:\", df.shape)\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2c2afcb0",
            "metadata": {},
            "source": [
                "**Commento:** Notiamo subito che `production_timestamp` e `material_batch` sono di tipo stringa (`object`). Il timestamp andrà convertito in formato datetime per estrarne informazioni temporali, mentre `material_batch` è una variabile categorica ad alta cardinalità che richiederà un encoding numerico."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0d667693",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistiche descrittive per le variabili numeriche:\n",
                "# media, deviazione standard, min, max e quartili\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a3306350",
            "metadata": {},
            "source": [
                "**Commento:** La tabella `describe()` ci fornisce un colpo d'occhio su valori medi, minimi, massimi e distribuzione (quartili) di ogni variabile numerica. Ci serve per individuare subito eventuali valori anomali — per esempio una temperatura fuori range o un diametro implausibile. A prima vista, i dati sembrano coerenti: le medie e i range non presentano anomalie evidenti."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e4263655",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Analisi Esplorativa (EDA)\n",
                "\n",
                "Esploriamo la distribuzione della variabile target, la ripartizione dei difetti per linea produttiva e le correlazioni tra le variabili numeriche."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6fb8c23a",
            "metadata": {},
            "source": [
                "### 2.1 Distribuzione della variabile target\n",
                "\n",
                "Verifichiamo quanti pezzi risultano difettosi rispetto a quelli conformi. Lo sbilanciamento delle classi è un aspetto critico perché può ingannare le metriche di valutazione."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d9b5c819",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Conteggio pezzi conformi (0) e difettosi (1)\n",
                "print(df['defect_label'].value_counts())\n",
                "\n",
                "# Grafico a barre per visualizzare lo sbilanciamento\n",
                "sns.countplot(x='defect_label', data=df)\n",
                "plt.title('Distribuzione Difetti (0 = conforme, 1 = difettoso)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e856204d",
            "metadata": {},
            "source": [
                "**Commento:** Come atteso in una linea produttiva reale, i pezzi difettosi sono una **minoranza** rispetto a quelli conformi. Questo sbilanciamento è normale (altrimenti la linea sarebbe fuori controllo), ma ha un impatto diretto sui modelli: un classificatore potrebbe \"barare\" predicendo sempre la classe maggioritaria e ottenere comunque un'accuratezza elevata. Ne terremo conto nella fase di modellazione con tecniche di bilanciamento."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b049717f",
            "metadata": {},
            "source": [
                "### 2.2 Difetti per linea e stazione produttiva\n",
                "\n",
                "Analizziamo se alcune linee o stazioni produttive presentano un tasso di difettosità più alto di altre. Informazione utile per gli stakeholder e per interventi mirati. Non visualizziamo `material_batch` (~3000 lotti) perché un grafico a barre con migliaia di categorie sarebbe illeggibile."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8829a1a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Countplot difetti per LINEA produttiva\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.countplot(x=\"line_id\", hue=\"defect_label\", data=df)\n",
                "plt.title(\"Distribuzione Difetti per Linea Produttiva\")\n",
                "plt.xlabel(\"Linea\")\n",
                "plt.ylabel(\"Conteggio pezzi\")\n",
                "plt.legend(title=\"Difetto\", labels=[\"Conforme\", \"Difettoso\"])\n",
                "plt.show()\n",
                "\n",
                "# Countplot difetti per STAZIONE di misura\n",
                "plt.figure(figsize=(14, 6))\n",
                "sns.countplot(x=\"station_id\", hue=\"defect_label\", data=df)\n",
                "plt.title(\"Distribuzione Difetti per Stazione di Misura\")\n",
                "plt.xlabel(\"Stazione\")\n",
                "plt.ylabel(\"Conteggio pezzi\")\n",
                "plt.legend(title=\"Difetto\", labels=[\"Conforme\", \"Difettoso\"])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "48802e41",
            "metadata": {},
            "source": [
                "**Commento:** Le proporzioni tra pezzi conformi e difettosi sono piuttosto uniformi sia tra le diverse linee che tra le stazioni di misura: nessuna si distingue in modo evidente per un tasso di difettosità anomalo. Questo suggerisce che i difetti non sono legati a una specifica linea o stazione ma piuttosto a fattori trasversali (materiali, parametri di processo, condizioni operative)."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a97719f9",
            "metadata": {},
            "source": [
                "### 2.3 Matrice di Correlazione\n",
                "\n",
                "Verifichiamo se esistono correlazioni forti tra le variabili numeriche e con il target `defect_label`. Variabili molto correlate tra loro o con il target possono guidare la scelta delle feature."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9aee5ca2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Heatmap delle correlazioni — valori tra -1 (correlazione negativa) e +1 (correlazione positiva)\n",
                "plt.figure(figsize=(14, 10))\n",
                "sns.heatmap(\n",
                "    df.corr(numeric_only=True),\n",
                "    annot=True,\n",
                "    fmt=\".2f\",             # Due decimali per leggibilità\n",
                "    annot_kws={\"size\": 9}, # Font ridotto per evitare sovrapposizioni\n",
                "    cmap='coolwarm'\n",
                ")\n",
                "plt.title('Matrice di Correlazione')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "42a5381a",
            "metadata": {},
            "source": [
                "**Commento:** I valori di correlazione con `defect_label` sono tutti piuttosto vicini a 0. Questo indica che **nessuna singola variabile è un predittore forte del difetto** presa isolatamente. Tuttavia, questo non significa che le variabili siano inutili: la combinazione di più feature, catturata dai modelli di ML, può comunque fornire un potere predittivo significativo. Non si evidenziano nemmeno multi-collinearità forti tra le feature indipendenti."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1f1cfcec",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Pulizia dei Dati\n",
                "\n",
                "Verifichiamo la presenza di valori mancanti, trattiamo eventuali outlier e rimuoviamo le colonne non informative o sensibili sotto il profilo privacy."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "89c77796",
            "metadata": {},
            "source": [
                "### 3.1 Valori Mancanti"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "19c65916",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Conteggio dei valori nulli per ogni colonna\n",
                "df.isnull().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "264e030f",
            "metadata": {},
            "source": [
                "**Commento:** Il dataset non presenta **alcun valore mancante**: tutte le colonne hanno il conteggio completo di osservazioni. Non è quindi necessario applicare strategie di imputation o rimozione di righe incomplete. Un ottimo punto di partenza."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "85134bd0",
            "metadata": {},
            "source": [
                "### 3.2 Controllo Outlier (metodo IQR)\n",
                "\n",
                "Applichiamo il metodo dell'**Interquartile Range (IQR)** sulle principali variabili di processo per verificare la presenza di valori anomali. Un valore è considerato outlier se cade al di sotto di Q1 − 1.5·IQR o al di sopra di Q3 + 1.5·IQR."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3f7c34af",
            "metadata": {},
            "outputs": [],
            "source": [
                "def remove_outliers_iqr(df, column):\n",
                "    \"\"\"Rimuove le righe con valori outlier in 'column' secondo il metodo IQR.\"\"\"\n",
                "    Q1 = df[column].quantile(0.25)\n",
                "    Q3 = df[column].quantile(0.75)\n",
                "    IQR = Q3 - Q1\n",
                "    lower = Q1 - 1.5 * IQR\n",
                "    upper = Q3 + 1.5 * IQR\n",
                "    return df[(df[column] >= lower) & (df[column] <= upper)]\n",
                "\n",
                "print(f\"Righe PRIMA della pulizia: {len(df)}\")\n",
                "\n",
                "# Colonne su cui verificare gli outlier (misure fisiche e sensori)\n",
                "cols_to_clean = ['measure_diam_mm', 'measure_length_mm', 'temp_process_C', 'vibration_level']\n",
                "\n",
                "for col in cols_to_clean:\n",
                "    df = remove_outliers_iqr(df, col)\n",
                "\n",
                "print(f\"Righe DOPO la pulizia:  {len(df)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8520dfc9",
            "metadata": {},
            "source": [
                "**Commento:** Il conteggio delle righe prima e dopo la pulizia è identico: **nessun sample è stato eliminato**. Questo conferma quanto osservato dal `describe()`: i dati rientrano tutti in range ragionevoli e non presentano outlier significativi secondo il criterio IQR."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "257134f7",
            "metadata": {},
            "source": [
                "### 3.3 Rimozione colonne non informative e privacy\n",
                "\n",
                "- **`part_id`**: è un identificativo univoco progressivo, non porta informazione predittiva.\n",
                "- **`operator_id`**: potrebbe essere coperto da vincoli di privacy aziendale; inoltre, dal grafico di sez. 2.2 non emergeva un legame operatore↔difetto particolarmente forte. Lo rimuoviamo per cautela.\n",
                "- **`production_timestamp`**: prima di eliminarlo, estraiamo l'**ora di produzione** — potrebbe influenzare la qualità (es. turni, stanchezza)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eb7d449d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Conversione del timestamp in formato datetime\n",
                "df['production_timestamp'] = pd.to_datetime(df['production_timestamp'])\n",
                "\n",
                "# Feature Engineering: estraiamo l'ora di produzione come nuova colonna\n",
                "df['hour'] = df['production_timestamp'].dt.hour\n",
                "\n",
                "# Rimozione delle colonne non più necessarie\n",
                "df = df.drop(columns=['part_id', 'production_timestamp', 'operator_id'], errors='ignore')\n",
                "\n",
                "print(\"Colonne finali dopo la pulizia:\")\n",
                "print(list(df.columns))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b4cd5ff7",
            "metadata": {},
            "source": [
                "**Commento:** Abbiamo ridotto il dataset alle sole colonne utili e aggiunto la feature `hour`. Il DataFrame ora contiene solo variabili che porteranno informazione ai modelli, rispettando inoltre i requisiti di privacy sull'operatore."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "57fec69b",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Preparazione delle Variabili\n",
                "\n",
                "In questa sezione estraiamo informazioni dalla colonna `material_batch`, trasformiamo le variabili categoriche in formato numerico, e applichiamo lo scaling."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "002b289d",
            "metadata": {},
            "source": [
                "### 4.1 Feature Engineering: Material Batch Analysis\n",
                "\n",
                "Estraiamo informazioni utili dalla colonna `material_batch` (formato `MB-YYYYWww-Lnn-sss`) per arricchire il dataset, mantenendo comunque la colonna originale per le aggregazioni successive.\n",
                "\n",
                "**Cosa estraiamo:**\n",
                "- **Anno (`batch_year`)**: utile per identificare trend di lungo periodo (es. invecchiamento macchinari).\n",
                "- **Settimana (`batch_week`)**: convertita poi in Seno/Coseno per catturare la stagionalità (es. temperatura esterna, cicli di manutenzione).\n",
                "- **Sequenza (`batch_seq`)**: il numero progressivo del lotto, fondamentale per intercettare derive temporali rapide.\n",
                "- **Linea (`batch_line_check`)**: estratta solo per validare la coerenza con la colonna `line_id`.\n",
                "\n",
                "**Nota importante:**\n",
                "La colonna originale `material_batch` **NON viene eliminata**. La manteniamo codificata (LabelEncoder) perché è essenziale per calcolare le *deviazioni* (sezione successiva), ovvero quanto un pezzo differisce dalla media del suo specifico lotto di produzione."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8b3b565d",
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_batch_info(batch_str):\n",
                "    # Formato atteso: MB-YYYYWww-Lnn-sss\n",
                "    try:\n",
                "        parts = batch_str.split('-')\n",
                "        if len(parts) != 4:\n",
                "            return None, None, None, None\n",
                "        \n",
                "        # parts[1] is 'YYYYWww'\n",
                "        year_week = parts[1].split('W')\n",
                "        year = int(year_week[0])\n",
                "        week = int(year_week[1])\n",
                "        \n",
                "        # parts[2] is 'Lnn'\n",
                "        line_id = int(parts[2][1:]) # Rimuove 'L'\n",
                "        \n",
                "        # parts[3] is 'sss'\n",
                "        seq = int(parts[3])\n",
                "        \n",
                "        return year, week, line_id, seq\n",
                "    except:\n",
                "        return None, None, None, None\n",
                "\n",
                "# Applicazione della funzione\n",
                "batch_data = df['material_batch'].apply(extract_batch_info)\n",
                "\n",
                "# Creazione nuove colonne\n",
                "df['batch_year'] = batch_data.apply(lambda x: x[0])\n",
                "df['batch_week'] = batch_data.apply(lambda x: x[1])\n",
                "df['batch_line_check'] = batch_data.apply(lambda x: x[2])\n",
                "df['batch_seq'] = batch_data.apply(lambda x: x[3])\n",
                "\n",
                "# Verifica coerenza Line ID\n",
                "mismatches = df[df['line_id'] != df['batch_line_check']]\n",
                "print(f\"Discrepanze Line ID: {len(mismatches)}\")\n",
                "\n",
                "# Se non ci sono discrepanze, rimuoviamo la colonna di controllo, altrimenti indaghiamo\n",
                "if len(mismatches) == 0:\n",
                "    print(\"Line ID coerente. Rimuovo colonna di controllo.\")\n",
                "    df.drop(columns=['batch_line_check'], inplace=True)\n",
                "else:\n",
                "    print(\"ATTENZIONE: Discrepanze trovate! Manteniamo la colonna per indagini.\")\n",
                "\n",
                "# Encoding Ciclico per la Settimana (1-53)\n",
                "df['batch_week_sin'] = np.sin(2 * np.pi * df['batch_week'] / 53)\n",
                "df['batch_week_cos'] = np.cos(2 * np.pi * df['batch_week'] / 53)\n",
                "\n",
                "print(\"Nuove features aggiunte: batch_year, batch_week_sin, batch_week_cos, batch_seq\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b930bf8b",
            "metadata": {},
            "source": [
                "### 4.2 Encoding delle variabili categoriche (LabelEncoder)\n",
                "\n",
                "Il dataset contiene variabili categoriche di tipo stringa che i modelli non possono usare direttamente. Utilizziamo il **LabelEncoder** di scikit-learn, che assegna un numero intero univoco a ogni categoria. Per `material_batch`, che ha un'alta cardinalità (~3000 lotti diversi), il LabelEncoder è la scelta più pratica: usare `get_dummies` genererebbe migliaia di colonne."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "540176ce",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verifica della cardinalità delle colonne categoriche\n",
                "print(\"Batch unici:\", df['material_batch'].nunique())\n",
                "print(\"Line ID unici:\", df['line_id'].nunique())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b9cc4d95",
            "metadata": {},
            "source": [
                "Se avessimo usato one-hot encoding su material_batch, avremmo effettivamente creato 2997 nuove colonne (una per ogni batch unico), rendendo il dataset enorme e il modello molto più complesso. Con il LabelEncoder il numero di colonne resta invariato."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "db510f42",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Copia del DataFrame per non alterare l'originale\n",
                "df_encoded = df.copy()\n",
                "\n",
                "# Inizializzazione del LabelEncoder\n",
                "le = LabelEncoder()\n",
                "\n",
                "# Applichiamo il Label Encoding a tutte le colonne di tipo object/string\n",
                "categorical_cols = df_encoded.select_dtypes(include=['object', 'string']).columns\n",
                "\n",
                "for col in categorical_cols:\n",
                "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
                "    print(f\"Codificata: {col} → {df_encoded[col].nunique()} valori unici\")\n",
                "\n",
                "print(\"\\nEncoding completato.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6654da58",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizzazione dei valori encodati per material_batch e line_id\n",
                "df_encoded[['material_batch', 'line_id']].head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "71aa73a6",
            "metadata": {},
            "source": [
                "**Commento:** Tutte le colonne categoriche sono state trasformate in valori numerici interi. Da notare che `material_batch` ha un'alta cardinalità: il modello potrebbe tendere all'overfitting su questa variabile. Tuttavia, per gli scopi di questa esercitazione, il LabelEncoder è il compromesso più idoneo per confrontare la capacità di generalizzazione dei diversi algoritmi."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b59a9872",
            "metadata": {},
            "source": [
                "### 4.2 Feature Engineering — Deviazioni per lotto\n",
                "\n",
                "Creiamo feature derivate che catturano lo **scostamento** di una misura rispetto alla media del proprio lotto di materia prima. L'intuizione è che un pezzo con un diametro o una temperatura anomali *rispetto al proprio batch* potrebbe essere più probabile difettoso."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7e1b5389",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Scostamento del diametro dalla media del batch\n",
                "df_encoded['batch_diam_mean'] = df_encoded.groupby('material_batch')['measure_diam_mm'].transform('mean')\n",
                "df_encoded['diam_dev_from_batch'] = df_encoded['measure_diam_mm'] - df_encoded['batch_diam_mean']\n",
                "\n",
                "# 2. Scostamento della temperatura dalla media del batch\n",
                "df_encoded['batch_temp_mean'] = df_encoded.groupby('material_batch')['temp_process_C'].transform('mean')\n",
                "df_encoded['temp_dev_from_batch'] = df_encoded['temp_process_C'] - df_encoded['batch_temp_mean']\n",
                "\n",
                "print(\"Feature engineering completato — aggiunte 4 colonne (2 medie + 2 deviazioni).\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a5f17a0d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Esempio: prime 10 righe con le nuove colonne\n",
                "df_encoded[['material_batch', 'measure_diam_mm', 'batch_diam_mean', 'diam_dev_from_batch',\n",
                "            'temp_process_C', 'batch_temp_mean', 'temp_dev_from_batch']].head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eda3d4df",
            "metadata": {},
            "source": [
                "**Commento:** Le nuove feature `diam_dev_from_batch` e `temp_dev_from_batch` rappresentano quanto un singolo pezzo si discosta dalla norma del proprio lotto. In un contesto produttivo reale, con molti pezzi per lotto, queste informazioni contestuali darebbero al modello un segnale più preciso rispetto ai valori assoluti.\n",
                "\n",
                "**Osservazione importante:** Come si nota dalla tabella qui sopra, tutte le deviazioni risultano **0.0**. Questo accade perché nel nostro dataset ci sono **2997 batch unici su 3000 righe** — quasi ogni lotto contiene un solo pezzo. Quando si calcola la media di un gruppo con un solo elemento, la media coincide con il valore stesso, e la deviazione è inevitabilmente zero. Le colonne di feature engineering restano comunque nel dataset come esempio didattico dell'approccio, ma in questo caso specifico **non apportano informazione aggiuntiva** ai modelli."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "000c0ca0",
            "metadata": {},
            "source": [
                "### 4.3 Suddivisione Train / Test e Scaling\n",
                "\n",
                "Dividiamo il dataset in **Training Set (80%)** per l'addestramento e **Test Set (20%)** per la valutazione su dati non visti.  \n",
                "Successivamente applichiamo lo **StandardScaler** (standardizzazione con media=0 e deviazione standard=1), necessario per la Logistic Regression che è sensibile alle scale diverse delle variabili.  \n",
                "\n",
                "**Importante:** lo scaler viene fittato **solo sul training set** per evitare *data leakage* — il test set viene trasformato con le statistiche del train."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7d8e6638",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Separazione Feature (X) e Target (y)\n",
                "X = df_encoded.drop('defect_label', axis=1)\n",
                "y = df_encoded['defect_label']\n",
                "\n",
                "# Split 80/20 con random_state fissato per riproducibilità\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "print(f\"Training Set: {X_train.shape[0]} campioni, {X_train.shape[1]} feature\")\n",
                "print(f\"Test Set:     {X_test.shape[0]} campioni, {X_test.shape[1]} feature\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8291e455",
            "metadata": {},
            "outputs": [],
            "source": [
                "# StandardScaler: fit solo su train, transform su entrambi\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9bb034d5",
            "metadata": {},
            "source": [
                "**Commento:** Lo StandardScaler porta ogni feature ad avere media ≈ 0 e deviazione standard ≈ 1. Questo è fondamentale per la Logistic Regression (che usa la distanza tra i coefficienti), mentre i modelli ad albero (Decision Tree e Random Forest) non ne hanno bisogno — per questi ultimi useremo i dati non scalati."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "909af0e9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confronto prima/dopo lo scaling (prime 5 righe, prime 5 feature)\n",
                "import pandas as pd\n",
                "\n",
                "print(\"PRIMA dello scaling (X_train, prime 5 righe):\")\n",
                "print(pd.DataFrame(X_train).iloc[:5, :5].to_string())\n",
                "print()\n",
                "print(\"DOPO lo scaling (X_train_scaled, prime 5 righe):\")\n",
                "print(pd.DataFrame(X_train_scaled, columns=X_train.columns).iloc[:5, :5].to_string())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fbc644dd",
            "metadata": {},
            "source": [
                "**Commento**: Lo StandardScaler trasforma ogni feature in modo che abbia media ≈ 0 e deviazione standard ≈ 1 sul training set. Ad esempio, un measure_diam_mm originale di 34.316 diventa 0.36 dopo lo scaling: questo significa che il valore si trova a circa 0.36 deviazioni standard sopra la media. Valori negativi (come -0.57 per il diametro di 23.774) indicano che il valore è sotto la media. Questa normalizzazione è essenziale per la Logistic Regression, che è sensibile alla scala delle variabili — senza scaling, feature con valori grandi (es. temperature ~100°C) dominerebbero su quelle con valori piccoli (es. vibration_level 0-1). I modelli ad albero (Decision Tree, Random Forest) non ne beneficiano, ma non ne sono penalizzati."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6cf546d2",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Addestramento dei Modelli\n",
                "\n",
                "Addestriamo tre modelli di classificazione come richiesto dalla traccia:\n",
                "\n",
                "| Modello | Caratteristiche |\n",
                "|---------|----------------|\n",
                "| **Logistic Regression** | Modello lineare, veloce, buona baseline ma limitato su relazioni non lineari |\n",
                "| **Decision Tree** | Non lineare, interpretabile, rischia di fare overfitting |\n",
                "| **Random Forest** | Ensemble di alberi, più robusto e generalmente più accurato |"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bd26e7f3",
            "metadata": {},
            "source": [
                "### 5.1 Logistic Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "436852f6",
            "metadata": {},
            "outputs": [],
            "source": [
                "# La Logistic Regression usa i dati scalati\n",
                "log_reg = LogisticRegression(random_state=42)\n",
                "log_reg.fit(X_train_scaled, y_train)\n",
                "y_pred_log = log_reg.predict(X_test_scaled)\n",
                "\n",
                "print(f\"Accuracy Logistic Regression: {accuracy_score(y_test, y_pred_log):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0543f1e6",
            "metadata": {},
            "source": [
                "**Commento:** La Logistic Regression ottiene un'accuratezza intorno al 75%. Tuttavia, come vedremo nel dettaglio nella sezione di valutazione, un'accuratezza elevata può essere ingannevole in presenza di classi sbilanciate: il modello potrebbe semplicemente predire quasi sempre la classe maggioritaria."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "de0038ba",
            "metadata": {},
            "source": [
                "### 5.2 Decision Tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ee9681cc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# I modelli ad albero non richiedono lo scaling — usiamo X_train originale\n",
                "tree_clf = DecisionTreeClassifier(random_state=42)\n",
                "tree_clf.fit(X_train, y_train)\n",
                "y_pred_tree = tree_clf.predict(X_test)\n",
                "\n",
                "print(f\"Accuracy Decision Tree: {accuracy_score(y_test, y_pred_tree):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "42757f1a",
            "metadata": {},
            "source": [
                "**Commento:** Il Decision Tree scende intorno al 64%. Un singolo albero tende a fare overfitting sui dati di training e fatica a generalizzare, specialmente con molte feature e alta cardinalità come `material_batch`."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "725fd922",
            "metadata": {},
            "source": [
                "### 5.3 Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7f85be8d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Random Forest: ensemble di 100 alberi per compensare la varianza\n",
                "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf_clf.fit(X_train, y_train)\n",
                "y_pred_rf = rf_clf.predict(X_test)\n",
                "\n",
                "print(f\"Accuracy Random Forest: {accuracy_score(y_test, y_pred_rf):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e10fecfa",
            "metadata": {},
            "source": [
                "**Commento:** Il Random Forest risale sopra il 78%, confermandosi il modello più robusto. L'aggregazione di 100 alberi riduce la varianza e corregge gli errori dei singoli alberi, portando a previsioni più stabili."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "370320a7",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Gestione dello Sbilanciamento delle Classi\n",
                "\n",
                "Il dataset è sbilanciato: i pezzi difettosi sono pochi rispetto a quelli conformi. Questo porta i modelli a favorire la classe maggioritaria, ignorando spesso la classe 1 (difetti) — che è proprio quella più importante per l'azienda.\n",
                "\n",
                "Utilizziamo il parametro **`class_weight='balanced'`** che aumenta il peso degli errori commessi sulla classe minoritaria, forzando il modello a \"prestare più attenzione\" ai difetti. Riaddestriamo **tutti e tre** i modelli."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "65b16d45",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Logistic Regression bilanciata (dati scalati)\n",
                "log_reg_bal = LogisticRegression(class_weight='balanced', random_state=42)\n",
                "log_reg_bal.fit(X_train_scaled, y_train)\n",
                "y_pred_log_bal = log_reg_bal.predict(X_test_scaled)\n",
                "\n",
                "# Decision Tree bilanciato (dati non scalati)\n",
                "tree_clf_bal = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
                "tree_clf_bal.fit(X_train, y_train)\n",
                "y_pred_tree_bal = tree_clf_bal.predict(X_test)\n",
                "\n",
                "# Random Forest bilanciato (dati non scalati)\n",
                "rf_clf_bal = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
                "rf_clf_bal.fit(X_train, y_train)\n",
                "y_pred_rf_bal = rf_clf_bal.predict(X_test)\n",
                "\n",
                "print(\"Addestramento con class balancing completato per tutti e 3 i modelli.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cc978249",
            "metadata": {},
            "source": [
                "**Commento:** Ora abbiamo 6 set di predizioni in totale (3 modelli base + 3 bilanciati). Nella prossima sezione confronteremo le performance in modo sistematico per capire quale configurazione sia preferibile nel contesto produttivo di AutomaParts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f5c884f5",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
                "\n",
                "print(\"=== Risultati con Class Balancing ===\\n\")\n",
                "\n",
                "for name, y_pred in [(\"Logistic Regression (bal.)\", y_pred_log_bal),\n",
                "                      (\"Decision Tree (bal.)\",      y_pred_tree_bal),\n",
                "                      (\"Random Forest (bal.)\",      y_pred_rf_bal)]:\n",
                "    print(f\"{name}:\")\n",
                "    print(f\"  Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
                "    print(f\"  Precision: {precision_score(y_test, y_pred):.4f}\")\n",
                "    print(f\"  Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
                "    print(f\"  F1-score:  {f1_score(y_test, y_pred):.4f}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "89e89498",
            "metadata": {},
            "source": [
                "**Commento**: L'applicazione di `class_weight='balanced'` produce effetti diversi sui tre modelli:\n",
                "- **Logistic Regression**: migliora significativamente il **Recall (0.51)**, arrivando a individuare circa la metà dei pezzi difettosi. Il costo è un alto numero di falsi positivi, che fa crollare la Precision a 0.26 e l'Accuracy generale a 0.54.\n",
                "- **Decision Tree**: offre un compromesso intermedio (Recall 0.36, Precision 0.35), ma rimane un classificatore debole (Accuracy 0.68).\n",
                "- **Random Forest**: mantiene un'ottima **Precision (0.85)** (pochi falsi allarmi), ma il suo **Recall (0.12)** resta deludente: anche con il bilanciamento, fatica a generalizzare sui difetti, probabilmente per la difficoltà di separare le classi nello spazio delle feature attuali.\n",
                "\n",
                "In sintesi: nessun modello raggiunge un equilibrio ottimale (tutti gli F1-score sono sotto 0.40). Questo suggerisce che i difetti potrebbero dipendere da fattori non pienamente catturati dai sensori disponibili o che il rumore nei dati sovrasta il segnale."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "be845065",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Valutazione e Confronto\n",
                "\n",
                "Confrontiamo tutti i modelli con metriche dettagliate, prestando particolare attenzione a **Recall** e **Precision** sulla classe 1 (difetti), che sono le metriche più rilevanti dal punto di vista operativo:\n",
                "\n",
                "- **Recall (classe 1)**: capacità di intercettare i pezzi difettosi → un valore basso significa molti **falsi negativi** (difetti che sfuggono al cliente!)\n",
                "- **Precision (classe 1)**: accuratezza delle previsioni di difetto → un valore basso significa molti **falsi positivi** (pezzi buoni scartati inutilmente)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fa1feee5",
            "metadata": {},
            "source": [
                "### 7.1 Classification Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "55e9b50c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Report completo per i modelli BASE \n",
                "# Aggiungo questo: zero_division=0 per evitare errori di divisione per zero\n",
                "print(\"===== MODELLI BASE =====\")\n",
                "print(\"\\n--- Logistic Regression ---\")\n",
                "print(classification_report(y_test, y_pred_log, zero_division=0))\n",
                "\n",
                "print(\"--- Decision Tree ---\")\n",
                "print(classification_report(y_test, y_pred_tree, zero_division=0))\n",
                "\n",
                "print(\"--- Random Forest ---\")\n",
                "print(classification_report(y_test, y_pred_rf, zero_division=0))\n",
                "\n",
                "# Report completo per i modelli BILANCIATI\n",
                "print(\"\\n===== MODELLI CON CLASS BALANCING =====\")\n",
                "print(\"\\n--- Logistic Regression (Balanced) ---\")\n",
                "print(classification_report(y_test, y_pred_log_bal, zero_division=0))\n",
                "\n",
                "print(\"--- Decision Tree (Balanced) ---\")\n",
                "print(classification_report(y_test, y_pred_tree_bal, zero_division=0))\n",
                "\n",
                "print(\"--- Random Forest (Balanced) ---\")\n",
                "print(classification_report(y_test, y_pred_rf_bal, zero_division=0))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d2a92a00",
            "metadata": {},
            "source": [
                "**Commento dettagliato:**\n",
                "\n",
                "**Modelli base:**\n",
                "- La **Logistic Regression** classifica tutti i pezzi come conformi (classe 0), ottenendo un'Accuracy apparentemente alta (0.76) ma Precision, Recall e F1-score per la classe difettosa pari a zero — un classificatore completamente inutile per il nostro obiettivo.\n",
                "- Il **Decision Tree** classifica tutti i pezzi come conformi (classe 0), ottenendo un'Accuracy apparentemente alta (0.76) ma Precision, Recall e F1-score per la classe difettosa pari a zero — un classificatore completamente inutile per il nostro obiettivo.\n",
                "- Il **Random Forest** mostra Precision alta (0.79) per la classe 1: quando predice un difetto di solito ha ragione, ma ne individua solo il 15% (Recall 0.15).\n",
                "\n",
                "Questi risultati confermano il problema dello sbilanciamento delle classi: i modelli tendono a favorire la classe maggioritaria (conformi) a scapito dei difetti.\n",
                "\n",
                "\n",
                "**Modelli bilanciati:**\n",
                "- Con `class_weight='balanced'`, la **recall per la classe 1 aumenta significativamente** per tutti i modelli. Il compromesso è un leggero aumento dei falsi positivi (pezzi buoni scartati), ma dal punto di vista industriale è preferibile scartare qualche pezzo buono in più piuttosto che lasciar passare un difettoso."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4d879970",
            "metadata": {},
            "source": [
                "### 7.2 Confusion Matrices\n",
                "\n",
                "Le matrici di confusione ci mostrano in modo visuale la distribuzione di:\n",
                "- **Veri Positivi (VP)**: difetti correttamente intercettati\n",
                "- **Falsi Negativi (FN)**: difetti sfuggiti (pericolosi!)\n",
                "- **Falsi Positivi (FP)**: pezzi buoni scartati inutilmente\n",
                "- **Veri Negativi (VN)**: pezzi buoni correttamente classificati"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "14c21549",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Griglia 2x3 per visualizzare tutte le confusion matrices insieme\n",
                "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
                "\n",
                "# Riga 1: modelli BASE\n",
                "modelli_base = [\n",
                "    ('Logistic Regression', y_pred_log, 'Reds'),\n",
                "    ('Decision Tree', y_pred_tree, 'Greens'),\n",
                "    ('Random Forest', y_pred_rf, 'Blues'),\n",
                "]\n",
                "\n",
                "for i, (nome, y_pred, cmap) in enumerate(modelli_base):\n",
                "    cm = confusion_matrix(y_test, y_pred)\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, ax=axes[0, i])\n",
                "    axes[0, i].set_title(nome)\n",
                "    axes[0, i].set_xlabel('Predetto')\n",
                "    axes[0, i].set_ylabel('Reale')\n",
                "\n",
                "# Riga 2: modelli BILANCIATI\n",
                "modelli_bal = [\n",
                "    ('LR (Balanced)', y_pred_log_bal, 'Oranges'),\n",
                "    ('DT (Balanced)', y_pred_tree_bal, 'YlGn'),\n",
                "    ('RF (Balanced)', y_pred_rf_bal, 'PuBu'),\n",
                "]\n",
                "\n",
                "for i, (nome, y_pred, cmap) in enumerate(modelli_bal):\n",
                "    cm = confusion_matrix(y_test, y_pred)\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, ax=axes[1, i])\n",
                "    axes[1, i].set_title(nome)\n",
                "    axes[1, i].set_xlabel('Predetto')\n",
                "    axes[1, i].set_ylabel('Reale')\n",
                "\n",
                "plt.suptitle('Confusion Matrices — Base (sopra) vs Bilanciati (sotto)', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "00c23bf6",
            "metadata": {},
            "source": [
                "**Commento ai grafici:**\n",
                "\n",
                "Confrontando la riga superiore (modelli base) con quella inferiore (bilanciati) si nota chiaramente l'effetto del class balancing:\n",
                "\n",
                "- Nei **modelli base**, l'angolo in basso a destra (Veri Positivi — difetti intercettati) è molto piccolo, specialmente per la Logistic Regression che non ne cattura quasi nessuno.\n",
                "- Nei **modelli bilanciati**, il riquadro dei VP cresce sensibilmente, a dimostrazione che il bilanciamento permette ai modelli di intercettare molti più pezzi difettosi.\n",
                "- Il trade-off è visibile nell'aumento dei Falsi Positivi (angolo in alto a destra), ma in un contesto produttivo è un compromesso accettabile: un falso allarme costa meno di un pezzo difettoso consegnato al cliente."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "37899542",
            "metadata": {},
            "source": [
                "### 7.3 Cross-Validation (5-fold)\n",
                "\n",
                "La cross-validation ci permette di valutare la **stabilità** delle performance dividendo il dataset in 5 parti e addestrandone una diversa ogni volta. Una deviazione standard bassa indica che il modello è robusto e non dipende da un singolo split casuale."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9ab12425",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cross-validation per tutti e 3 i modelli (versione base)\n",
                "modelli_cv = {\n",
                "    'Logistic Regression': LogisticRegression(random_state=42),\n",
                "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
                "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
                "}\n",
                "\n",
                "print(\"Cross-Validation (5-fold) — Accuratezza:\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "for nome, modello in modelli_cv.items():\n",
                "    # Per la LR usiamo i dati scalati, per gli alberi quelli originali\n",
                "    if 'Logistic' in nome:\n",
                "        scores = cross_val_score(modello, scaler.fit_transform(X), y, cv=5)\n",
                "    else:\n",
                "        scores = cross_val_score(modello, X, y, cv=5)\n",
                "    print(f\"{nome:25s} | Media: {scores.mean():.4f}  |  Std: {scores.std():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b80b46d8",
            "metadata": {},
            "source": [
                "**Commento**: La cross-validation conferma la stabilità dei risultati: le deviazioni standard sono tutte cực contenute (< 0.01), il che significa che le performance non dipendono dal particolare split casuale dei dati.\n",
                "\n",
                "Tuttavia, va osservato che la metrica usata qui è l'Accuracy, che in un dataset sbilanciato (75/25) può essere fuorviante. Ad esempio, la Logistic Regression ottiene un'ottima accuratezza media (0.78) semplicemente classificando quasi tutto come \"conforme\", pur avendo Recall quasi nullo sulla classe difettosa. Per una valutazione più affidabile in contesti reali sbilanciati, sarebbe preferibile ottimizzare e valutare metriche come **F1-score** o **Recall**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5150c852",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cross-Validation (5-fold) — Recall sulla classe difettosa\n",
                "print(\"\\nCross-Validation (5-fold) — Recall (classe 1):\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "for name, model, X_cv in [(\"Logistic Regression\", log_reg_bal, X_train_scaled),\n",
                "                           (\"Decision Tree\",       tree_clf_bal, X_train),\n",
                "                           (\"Random Forest\",       rf_clf_bal,   X_train)]:\n",
                "    scores = cross_val_score(model, X_cv, y_train, cv=5, scoring='recall')\n",
                "    print(f\"{name:25s} | Media: {scores.mean():.4f}  |  Std: {scores.std():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "85376fd3",
            "metadata": {},
            "source": [
                "**Commento**: La cross-validation sul Recall offre un quadro molto diverso (e più onesto) rispetto all'Accuracy:\n",
                "\n",
                "- **Logistic Regression (bilanciata)**: Si conferma il modello più \"sensibile\", rilevando circa la metà dei difetti reali (Recall ~0.51), anche se con una certa variabilità (std 0.04).\n",
                "- **Decision Tree**: Si ferma a un Recall medio di ~0.27, individuando poco più di un difetto su quattro.\n",
                "- **Random Forest**: Nonostante l'altissima Accuracy vista prima, qui crolla a un Recall medio di appena **0.04**. Praticamente, sui dati mai visti, non riesce quasi mai a individuare i pezzi difettosi.\n",
                "\n",
                "Questo conferma definitivamente che un'alta Accuracy può mascherare un modello totalmente inefficace per l'obiettivo di business (rilevare i difetti)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2e515231",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cross-Validation (5-fold) — F1-score sulla classe difettosa\n",
                "print(\"\\nCross-Validation (5-fold) — F1-score (classe 1):\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "for name, model, X_cv in [(\"Logistic Regression\", log_reg_bal, X_train_scaled),\n",
                "                           (\"Decision Tree\",       tree_clf_bal, X_train),\n",
                "                           (\"Random Forest\",       rf_clf_bal,   X_train)]:\n",
                "    scores = cross_val_score(model, X_cv, y_train, cv=5, scoring='f1')\n",
                "    print(f\"{name:25s} | Media: {scores.mean():.4f}  |  Std: {scores.std():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5d3c66d9",
            "metadata": {},
            "source": [
                "**Commento**: L'F1-score conferma il quadro complessivo: nessun modello raggiunge un buon equilibrio tra **Precision** e **Recall** sulla classe difettosa.\n",
                "\n",
                "- **Logistic Regression (bilanciata)**: ottiene il miglior F1 medio (0.32), confermandosi il modello più equilibrato (per quanto debole).\n",
                "- **Decision Tree**: segue con 0.26.\n",
                "- **Random Forest**: crolla a **0.08**. Nonostante l'Accuracy stellare, è il peggiore nel bilanciare le due esigenze.\n",
                "\n",
                "I valori di F1 tutti sotto 0.35 indicano che le feature attuali non contengono un segnale abbastanza forte. In un contesto reale, questo suggerirebbe di:\n",
                "1.  Esplorare sensori aggiuntivi.\n",
                "2.  Raccogliere più dati sui difetti.\n",
                "3.  Provare tecniche avanzate (tuning iperparametri, modelli ensemble, soglie personalizzate)."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "99a6f92a",
            "metadata": {},
            "source": [
                "### 7.4 Feature Importance (Random Forest)\n",
                "\n",
                "Il Random Forest ci permette di estrarre l'**importanza relativa** di ogni feature nella decisione del modello. Questo è fondamentale per capire quali variabili di processo vanno monitorate con più attenzione e dove intervenire per ridurre la difettosità."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a61a0c91",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Estrazione e ordinamento delle feature importance\n",
                "importances = rf_clf.feature_importances_\n",
                "indices = np.argsort(importances)[::-1]\n",
                "\n",
                "# Grafico a barre orizzontali per leggibilità\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.title('Feature Importance — Random Forest')\n",
                "plt.bar(range(X.shape[1]), importances[indices], align='center')\n",
                "plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\n",
                "plt.ylabel('Importanza relativa')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "17e6d8c0",
            "metadata": {},
            "source": [
                "**Commento al grafico:**\n",
                "\n",
                "Il grafico mostra che le feature importance del Random Forest sono distribuite in modo abbastanza uniforme tra le variabili di processo e dimensionali — nessuna singola feature domina chiaramente la predizione. Le più rilevanti sono cycle_time_s e vibration_level (~0.09), seguite dal gruppo di misure fisiche (surface_roughness_Ra, torque_Nm, flatness_mm, measure_length_mm) tutte attorno a 0.07. Le variabili identificative (station_id, hour, line_id) contribuiscono meno, come atteso: il difetto è più legato ai parametri di processo che alla specifica linea o stazione. Infine, le due colonne di feature engineering (diam_dev_from_batch e temp_dev_from_batch) hanno importanza prossima allo zero, confermando quanto osservato in precedenza: con ~2997 batch unici su 3000 righe, le deviazioni dalla media del lotto non aggiungono informazione. La distribuzione piatta delle importance spiega anche le difficoltà dei modelli: non c'è una \"feature chiave\" che separi nettamente i pezzi difettosi da quelli conformi."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "15306962",
            "metadata": {},
            "source": [
                "### 7.5 Curva ROC e AUC (Random Forest)\n",
                "\n",
                "La **curva ROC** mostra il trade-off tra True Positive Rate (recall) e False Positive Rate al variare della soglia di decisione. L'**AUC** (Area Under the Curve) riassume la capacità discriminativa del modello in un singolo numero: 0.5 = classificatore casuale, 1.0 = classificatore perfetto."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "329791a8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Probabilità predette per la classe positiva (difettoso)\n",
                "y_prob = rf_clf.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# Calcolo della curva ROC\n",
                "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
                "roc_auc = auc(fpr, tpr)\n",
                "\n",
                "# Plot\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
                "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Random (AUC = 0.50)')\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate')\n",
                "plt.title('Curva ROC — Random Forest')\n",
                "plt.legend(loc='lower right')\n",
                "plt.grid(alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f0091062",
            "metadata": {},
            "source": [
                "**Commento:**\n",
                "\n",
                "- La linea tratteggiata grigia rappresenta il classificatore casuale (AUC = 0.50).\n",
                "- La curva arancione del nostro modello deve posizionarsi il più possibile verso l'angolo in alto a sinistra.\n",
                "- Un **AUC intorno a 0.57** è un valore basso: il modello fa fatica a distinguere nettamente i pezzi difettosi da quelli conformi. Questo è coerente con quanto osservato nella matrice di correlazione, dove nessuna variabile presa singolarmente correlava fortemente con il target.\n",
                "- Per migliorare significativamente l'AUC, servirebbero probabilmente dati più informativi (nuovi sensori, metriche aggiuntive) o un dataset con un segnale più chiaro."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "16eb782b",
            "metadata": {},
            "source": [
                "### 7.6 Tabella Riepilogativa\n",
                "\n",
                "Riepilogo finale di tutti i modelli con le metriche chiave sulla classe 1 (difetti)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2d563b3d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Costruzione della tabella riassuntiva\n",
                "tabella = pd.DataFrame({\n",
                "    'Modello': [\n",
                "        'Logistic Regression',\n",
                "        'Decision Tree',\n",
                "        'Random Forest',\n",
                "        'LR (Balanced)',\n",
                "        'DT (Balanced)',\n",
                "        'RF (Balanced)'\n",
                "    ],\n",
                "    'Accuracy': [\n",
                "        accuracy_score(y_test, y_pred_log),\n",
                "        accuracy_score(y_test, y_pred_tree),\n",
                "        accuracy_score(y_test, y_pred_rf),\n",
                "        accuracy_score(y_test, y_pred_log_bal),\n",
                "        accuracy_score(y_test, y_pred_tree_bal),\n",
                "        accuracy_score(y_test, y_pred_rf_bal)\n",
                "    ],\n",
                "    'Precision (Cl 1)': [\n",
                "        precision_score(y_test, y_pred_log, zero_division=0),\n",
                "        precision_score(y_test, y_pred_tree, zero_division=0),\n",
                "        precision_score(y_test, y_pred_rf, zero_division=0),\n",
                "        precision_score(y_test, y_pred_log_bal, zero_division=0),\n",
                "        precision_score(y_test, y_pred_tree_bal, zero_division=0),\n",
                "        precision_score(y_test, y_pred_rf_bal, zero_division=0)\n",
                "    ],\n",
                "    'Recall (Cl 1)': [\n",
                "        recall_score(y_test, y_pred_log, zero_division=0),\n",
                "        recall_score(y_test, y_pred_tree, zero_division=0),\n",
                "        recall_score(y_test, y_pred_rf, zero_division=0),\n",
                "        recall_score(y_test, y_pred_log_bal, zero_division=0),\n",
                "        recall_score(y_test, y_pred_tree_bal, zero_division=0),\n",
                "        recall_score(y_test, y_pred_rf_bal, zero_division=0)\n",
                "    ],\n",
                "    'F1 (Cl 1)': [\n",
                "        f1_score(y_test, y_pred_log, zero_division=0),\n",
                "        f1_score(y_test, y_pred_tree, zero_division=0),\n",
                "        f1_score(y_test, y_pred_rf, zero_division=0),\n",
                "        f1_score(y_test, y_pred_log_bal, zero_division=0),\n",
                "        f1_score(y_test, y_pred_tree_bal, zero_division=0),\n",
                "        f1_score(y_test, y_pred_rf_bal, zero_division=0)\n",
                "    ]\n",
                "})\n",
                "\n",
                "# Arrotondiamo a 4 decimali per leggibilità\n",
                "print(tabella.round(4).to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2a586ce6",
            "metadata": {},
            "source": [
                "**Commento:** La tabella riepilogativa evidenzia il **trade-off fondamentale** tra Accuracy e capacità di rilevare i difetti:\n",
                "\n",
                "- **Logistic Regression (base)**: è l'esempio estremo. Raggiunge 0.75 di Accuracy semplicemente *ignorando completamente* la classe difettosa (Precision, Recall e F1 tutti a zero).\n",
                "- **Random Forest (bilanciato)**: detiene la **Precision più alta (0.85)** — quasi 9 segnalazioni di difetto su 10 sono corrette — ma con un **Recall di appena 0.12** lascia sfuggire l'88% dei pezzi realmente difettosi.\n",
                "- **Logistic Regression (bilanciata)**: all'opposto, è la più sensibile ai difetti (**Recall 0.50**), ma con una Precision di solo 0.26 genera molti falsi allarmi, e la sua Accuracy (0.53) è poco meglio del caso.\n",
                "- **Decision Tree (bilanciato)**: offre il miglior **F1-score (0.35)** e il compromesso più equilibrato tra Precision e Recall, risultando il modello più pragmatico nonostante non eccella in nessuna metrica singola.\n",
                "\n",
                "**Decisione Operativa**:\n",
                "In un contesto produttivo reale, la scelta dipende dai costi:\n",
                "- Se perdere un difetto è grave (es. sicurezza), si privilegia il **Recall** (LR bilanciata).\n",
                "- Se i controlli manuali costano molto, si privilegia la **Precision** (RF bilanciato).\n",
                "- Se serve un bilanciamento, il **Decision Tree** è il compromesso migliore."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b1e77d80",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. Conclusioni e Raccomandazioni\n",
                "\n",
                "### Sintesi dei risultati\n",
                "\n",
                "L'analisi ha confrontato tre algoritmi di classificazione (Logistic Regression, Decision Tree, Random Forest) sia nella versione base che con bilanciamento delle classi. I risultati evidenziano che **nessun modello raggiunge performance pienamente soddisfacenti** nella rilevazione dei difetti:\n",
                "\n",
                "- La **Logistic Regression base** è risultata completamente inadatta: pur avendo un'accuratezza apparente del 76%, non identifica nessun pezzo difettoso (Recall = 0 per la classe 1). Un modello che classifica tutto come \"conforme\" è inutile per il controllo qualità.\n",
                "- Il **Decision Tree bilanciato** offre il miglior compromesso complessivo (F1 = 0.37), con un equilibrio tra Precision (0.36) e Recall (0.38), ma resta un rilevatore debole.\n",
                "- Il **Random Forest bilanciato** ha la Precision più alta (0.88) — quando segnala un difetto è quasi sempre corretto — ma il Recall di 0.15 significa che lascia sfuggire l'85% dei pezzi difettosi.\n",
                "- La **Logistic Regression bilanciata** è la più sensibile ai difetti (Recall = 0.51), ma con troppi falsi allarmi (Precision = 0.27).\n",
                "\n",
                "### Questo risultato è normale?\n",
                "\n",
                "**Sì, è un risultato plausibile e comune** nell'ambito del quality control industriale. Nella realtà produttiva:\n",
                "\n",
                "- I difetti sono eventi **rari** (nel nostro dataset ~24% delle osservazioni, ma in contesti reali possono essere l'1-5%), il che crea un forte sbilanciamento.\n",
                "- I difetti spesso dipendono da **combinazioni complesse** di fattori (usura utensili, variazioni nel lotto materia prima, condizioni ambientali) che i sensori disponibili possono non catturare direttamente.\n",
                "- Il segnale nel dataset è **debole e distribuito** tra molte feature, come confermato dalla Feature Importance dove nessuna variabile domina: il modello non ha una \"chiave\" chiara per separare pezzi buoni e difettosi.\n",
                "- In un caso reale con dati sintetici come questo, è normale che i modelli base non riescano a discriminare efficacemente — il valore dell'esercizio sta nel **processo di analisi** e nell'identificazione dei limiti, non nei numeri assoluti.\n",
                "\n",
                "### Analisi dei falsi negativi e falsi positivi\n",
                "\n",
                "| Tipo di errore | Impatto operativo | Costo stimato |\n",
                "|---|---|---|\n",
                "| **Falso Negativo** (difetto non intercettato) | Pezzo difettoso arriva al cliente → richiami, fermi macchina, danni reputazionali | **Alto** |\n",
                "| **Falso Positivo** (pezzo buono scartato) | Scarto inutile → costo di rilavorazione o materiale perso | **Medio-basso** |\n",
                "\n",
                "Per un fornitore OEM, il costo di un falso negativo è molto superiore a quello di un falso positivo. Per questo motivo, è preferibile un modello con alta Recall (anche a scapito di qualche falso allarme).\n",
                "\n",
                "### Raccomandazioni operative\n",
                "\n",
                "1. **Soglia di decisione personalizzata**: i classificatori di scikit-learn usano di default una soglia di probabilità a 0.50. Abbassandola (es. a 0.30-0.35), il modello classificherebbe come \"difettoso\" anche i pezzi con probabilità intermedia, aumentando significativamente il Recall a scapito della Precision. I pezzi \"incerti\" verrebbero instradati verso un controllo al 100% — un compromesso ragionevole in produzione.\n",
                "2. **Monitoraggio continuo**: le feature più importanti (come `cycle_time_s`, `vibration_level`, `surface_roughness_Ra`) dovrebbero essere monitorate in tempo reale. Variazioni anomale possono essere usate come trigger per azioni preventive.\n",
                "3. **Integrazione MES**: il modello potrebbe essere integrato nel Manufacturing Execution System per automatizzare l'instradamento a ispezione supplementare.\n",
                "4. **Retraining periodico**: le condizioni di processo cambiano nel tempo (usura utensili, nuovi materiali). Si raccomanda un retraining con dati aggiornati.\n",
                "\n",
                "### Limiti e proposte di miglioramento\n",
                "\n",
                "- **AUC basso (~0.58)**: conferma che il segnale discriminante nel dataset è debole. Nessuna singola variabile correla fortemente con il difetto.\n",
                "- **Feature engineering inefficace**: le deviazioni per lotto (`diam_dev_from_batch`, `temp_dev_from_batch`) non apportano informazione a causa della cardinalità quasi 1:1 tra batch e pezzi.\n",
                "- **Possibili miglioramenti**:\n",
                "  - Raccogliere dati da **sensori aggiuntivi** (vibrazioni multiassiali, forze di taglio, immagini di ispezione)\n",
                "  - Arricchire il dataset con informazioni sullo **stato utensile** (ore di utilizzo, ultimo cambio)\n",
                "  - Garantire **più pezzi per lotto** per rendere efficace il feature engineering sulle deviazioni\n",
                "  - Sperimentare tecniche di **oversampling** (SMOTE) per la classe minoritaria\n",
                "  - Valutare modelli più complessi (**Gradient Boosting, XGBoost**) con tuning degli iperparametri\n",
                "  - Adottare **soglie di decisione personalizzate** ottimizzate per massimizzare il Recall o l'F1-score\n",
                "\n",
                "### Riferimenti\n",
                "\n",
                "- [Documentazione scikit-learn](https://scikit-learn.org/stable/)\n",
                "- [Pandas documentation](https://pandas.pydata.org/docs/)\n",
                "- [Seaborn visualization library](https://seaborn.pydata.org/)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
