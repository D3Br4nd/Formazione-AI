{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto ML: Classificazione Pezzi Difettosi - AutomaParts S.p.A.\n",
    "\n",
    "**Obiettivo:** Creare un modello per individuare i pezzi difettosi nella linea di produzione (0 = conforme, 1 = difettoso). Permettendo: \n",
    "\n",
    "+ scarto automatico o blocco in ispezione finale;\n",
    "+ instradamento verso un controllo 100% quando la probabilità è incerta;\n",
    "+ analisi delle cause principali dei difetti per interventi di processo.\n",
    "\n",
    "Le metriche chiave saranno quelle legate alla capacità di trovare i difetti (Recall) senza scartare troppi pezzi buoni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1270932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo tutte le librerie\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced2554",
   "metadata": {},
   "source": [
    "## 1. Caricamento Dati\n",
    "Carico il dataset e do un'occhiata veloce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('parts_production_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b759a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2afcb0",
   "metadata": {},
   "source": [
    "Nota: `production_timestamp` è object, dovrò convertirlo. Anche `material_batch` è una stringa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d667693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "# Qui do un occhiata ai dati per medie e outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4263655",
   "metadata": {},
   "source": [
    "## 2. Analisi Esplorativa (EDA)\n",
    "Controllo quanti difetti ci sono rispetto ai pezzi ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['defect_label'].value_counts())\n",
    "\n",
    "sns.countplot(x='defect_label', data=df)\n",
    "plt.title('Distribuzione Classi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e856204d",
   "metadata": {},
   "source": [
    "C'è un evidente sbilanciamento. I difetti sono molti meno dei pezzi conformi, il che è normale, ma dovrò tenerne conto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b049717f",
   "metadata": {},
   "source": [
    "Vediamo se i difetti dipendono dalla linea o dalla stazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8829a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione Difetti per Linea e Stazione (uso queste perché hanno dati fissi, bassa cardinalità)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=\"line_id\", hue=\"defect_label\", data=df)\n",
    "plt.title(\"Difetti per Linea\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "sns.countplot(x=\"station_id\", hue=\"defect_label\", data=df)\n",
    "plt.title(\"Difetti per Stazione\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48802e41",
   "metadata": {},
   "source": [
    "Sembra tutto abbastanza uniforme, non vedo picchi strani su linee specifiche."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97719f9",
   "metadata": {},
   "source": [
    "### Correlazioni\n",
    "La Matrice di correlazione mostra subito se ci sono correlazioni tra le features e la variabile target (difettosità)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee5ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1cfcec",
   "metadata": {},
   "source": [
    "## 3. Pulizia e Feature Engineering\n",
    "Controllo valori nulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c65916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e030f",
   "metadata": {},
   "source": [
    "Nessun valore nullo, ottimo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85134bd0",
   "metadata": {},
   "source": [
    "### Gestione Outlier\n",
    "Provo a togliere gli outlier estremi con IQR sulle misure principali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7c34af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_outliers(df, col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    return df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "cols = ['measure_diam_mm', 'measure_length_mm', 'temp_process_C', 'vibration_level']\n",
    "print(f\"Righe iniziali: {len(df)}\")\n",
    "\n",
    "for c in cols:\n",
    "    df = clean_outliers(df, c)\n",
    "\n",
    "print(f\"Righe finali: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257134f7",
   "metadata": {},
   "source": [
    "Nessun outlier rimosso. Procedo con la pulizia dei dati (drop variabili inutili) e feature engineering.\n",
    "\n",
    "Droppo  e  (inutili/rumore). Estraggo l'ora dal timestamp e poi rimuovo l'originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droppo le colonne inutili o che non servono al modello\n",
    "df = df.drop(columns=['part_id', 'operator_id'], errors='ignore')\n",
    "\n",
    "if 'production_timestamp' in df.columns:\n",
    "    df['production_timestamp'] = pd.to_datetime(df['production_timestamp'])\n",
    "    df['hour'] = df['production_timestamp'].dt.hour\n",
    "    df = df.drop(columns=['production_timestamp'], errors='ignore')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b289d",
   "metadata": {},
   "source": [
    "### Material Batch\n",
    "Cerco di estrarre informazioni utili dal codice `material_batch` (Anno, Settimana, Sequenza)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_batch(s):\n",
    "    # es. MB-2024W24-L02-575\n",
    "    try:\n",
    "        parts = s.split('-')\n",
    "        year_wk = parts[1].split('W')\n",
    "        return int(year_wk[0]), int(year_wk[1]), int(parts[3]) # Anno, Week, Seq\n",
    "    except:\n",
    "        return None, None, None\n",
    "\n",
    "batch_infos = df['material_batch'].apply(parse_batch)\n",
    "\n",
    "df['batch_year'] = batch_infos.apply(lambda x: x[0])\n",
    "df['batch_week'] = batch_infos.apply(lambda x: x[1])\n",
    "df['batch_seq'] = batch_infos.apply(lambda x: x[2])\n",
    "\n",
    "# Trasformazione ciclica per la settimana, così il modello capisce che la settimana 1 è vicina alla settimana 52 ecc.\n",
    "df['batch_week_sin'] = np.sin(2 * np.pi * df['batch_week'] / 53)\n",
    "df['batch_week_cos'] = np.cos(2 * np.pi * df['batch_week'] / 53)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b930bf8b",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "Uso LabelEncoder per le variabili categoriche rimaste (`material_batch`, `line_id`...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db510f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "cat_cols = df.select_dtypes(include=['object', 'string']).columns\n",
    "\n",
    "for c in cat_cols:\n",
    "    df[c] = le.fit_transform(df[c].astype(str))\n",
    "    print(f\"Encoded {c}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59a9872",
   "metadata": {},
   "source": [
    "Aggiungo feature sulle deviazioni dalla media del lotto (magari aiuta a trovare anomalie locali)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1b5389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scostamento dal diametro medio del batch\n",
    "df['batch_diam_mean'] = df.groupby('material_batch')['measure_diam_mm'].transform('mean')\n",
    "df['diam_dev'] = df['measure_diam_mm'] - df['batch_diam_mean']\n",
    "\n",
    "# Scostamento dalla temperatura media del batch\n",
    "df['batch_temp_mean'] = df.groupby('material_batch')['temp_process_C'].transform('mean')\n",
    "df['temp_dev'] = df['temp_process_C'] - df['batch_temp_mean']\n",
    "\n",
    "df[['material_batch', 'diam_dev', 'temp_dev']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28965b87",
   "metadata": {},
   "source": [
    "Nota: vedo molti zeri, probabilmente i batch sono molto piccoli o quasi unici. Comunque le lascio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c0ca0",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split e Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('defect_label', axis=1)\n",
    "y = df['defect_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creaiamo un dataset per la LR con i dati scalati altrimenti il modello non lavora bene, per gli altri lascio i dati senza scalare\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf546d2",
   "metadata": {},
   "source": [
    "## 5. Modelli (Baseline)\n",
    "Provo 3 modelli: Logistic Regression, Decision Tree, Random Forest.\n",
    "Uso i dati scalati per la LR, gli originali per gli alberi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436852f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "print(f\"LR Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "print(f\"DT Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}\")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(f\"RF Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fecfa",
   "metadata": {},
   "source": [
    "La Random Forest sembra la migliore come accuracy, ma attenzione allo sbilanciamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370320a7",
   "metadata": {},
   "source": [
    "## 6. Modelli Bilanciati (Class Weight)\n",
    "Provo a usare `class_weight='balanced'` per aiutare i modelli a vedere meglio la classe minoritaria (i difetti)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b16d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bal = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "lr_bal.fit(X_train_scaled, y_train)\n",
    "\n",
    "dt_bal = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "dt_bal.fit(X_train, y_train)\n",
    "\n",
    "rf_bal = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "rf_bal.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training completato con class_weight='balanced'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1feee5",
   "metadata": {},
   "source": [
    "## 7. Valutazione e Confronto\n",
    "Confronto le metriche. Mi interessa soprattutto la **Recall** (non voglio perdermi pezzi difettosi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e9b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {\n",
    "    'LR Base': y_pred_lr,\n",
    "    'DT Base': y_pred_dt,\n",
    "    'RF Base': y_pred_rf,\n",
    "    'LR Balanced': lr_bal.predict(X_test_scaled),\n",
    "    'DT Balanced': dt_bal.predict(X_test),\n",
    "    'RF Balanced': rf_bal.predict(X_test)\n",
    "}\n",
    "\n",
    "for name, p in preds.items():\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(classification_report(y_test, p, zero_division=0))\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a92a00",
   "metadata": {},
   "source": [
    "**Osservazioni:**\n",
    "Industialmente è più importante trovare i difetti (Recall) che avere una buona precisione. \n",
    "- I modelli base faticano molto sulla classe 1 (difetti).\n",
    "- `LR Balanced` ha la Recall migliore (trova circa metà dei difetti), ma paga molto in precisione.\n",
    "- `RF Balanced` è molto precisa ma ha una Recall bassa (troppo prudente).\n",
    "- `DT Balanced` è un buon compromesso intermedio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d879970",
   "metadata": {},
   "source": [
    "### Matrici di Confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c21549",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, p) in enumerate(preds.items()):\n",
    "    cm = confusion_matrix(y_test, p)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=axes[i], cmap='Blues')\n",
    "    axes[i].set_title(name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a3677",
   "metadata": {},
   "source": [
    "Praticamente i modelli \"base\" sono inutili: dicono sempre che il pezzo è buono per andare sul sicuro e si perdono quasi tutti i difetti.\n",
    "\n",
    "Quelli \"balanced\" ci provano di più: la Logistic Regression ne becca la metà (74), ma vede difetti ovunque e dà un sacco di falsi allarmi. La Random Forest invece resta troppo \"timida\" e non si sbilancia mai. Mi sa che con questi dati è un bel casino distinguerli!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37899542",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "Verifico che i risultati siano stabili con una 5-fold CV: è un trucco per capire se il modello funziona davvero o se ha avuto solo \"fortuna\" con la divisione dei dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab12425",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CV su Modelli Bilanciati (Metric: Recall)\")\n",
    "print(\"LR Balanced:\", cross_val_score(lr_bal, X_train_scaled, y_train, cv=5, scoring='recall').mean())\n",
    "print(\"DT Balanced:\", cross_val_score(dt_bal, X_train, y_train, cv=5, scoring='recall').mean())\n",
    "print(\"RF Balanced:\", cross_val_score(rf_bal, X_train, y_train, cv=5, scoring='recall').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad5f8b",
   "metadata": {},
   "source": [
    "La Logistic Regression è l'unica che ci sta provando davvero, beccando almeno la metà dei difetti (51%). Il Decision Tree cala brutto e la Random Forest è un disastro: con un 4% di recall vuol dire che si perde praticamente tutto.\n",
    "\n",
    "Morale: qui il modello più semplice macina meglio di quelli complessi, che probabilmente non trovano un pattern chiaro e restano troppo cauti!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6f92a",
   "metadata": {},
   "source": [
    "### Feature Importance (Random Forest)\n",
    "Vediamo quali sono le variabili che il modello ritiene più utili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61a0c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "imps = rf_bal.feature_importances_\n",
    "indices = np.argsort(imps)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(X.shape[1]), imps[indices])\n",
    "plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\n",
    "plt.title(\"Feature Importance (RF Balanced)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473ca1c",
   "metadata": {},
   "source": [
    "Il tempo di ciclo e le vibrazioni sono le variabili che \"pesano\" di più per il modello. Invece quelle feature sulle deviazioni che abbiamo aggiunto noi sono in fondo alla classifica: non contano praticamente nulla, un flop totale!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eb782b",
   "metadata": {},
   "source": [
    "## Conclusioni\n",
    "\n",
    "Il problema principale è la scarsa capacità dei modelli di separare nettamente le classi, probabilmente perché i difetti non dipendono in modo semplice dalle misure disponibili.\n",
    "\n",
    "1. **Se la priorità è non far passare difetti**: Usare **Logistic Regression Balanced** (Recall ~50%), mettendo in conto molto scarto di pezzi buoni da ricontrollare.\n",
    "2. **Se si cerca un equilibrio**: Il **Decision Tree Balanced** offre un compromesso ragionevole.\n",
    "3. **Random Forest** è troppo conservativa in questo caso specifico, tende a non segnalare difetti se non è sicura.\n",
    "\n",
    "**Next steps:**\n",
    "- Raccogliere più dati sui difetti.\n",
    "- Indagare nuove feature (magari dati grezzi dai sensori invece che medie)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
